{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Packages <- c(\"dplyr\",  \"nleqslv\", \"broom\",\"cubature\", \"geosphere\", \"data.table\",  \"ggplot2\", \"bbmle\", \"stringr\",  \"lubridate\", \"RColorBrewer\")\n",
    "\n",
    "invisible(suppressPackageStartupMessages(lapply(Packages, library, character.only = TRUE)))\n",
    "\n",
    "setwd('/local/home/katrinac/oceanography')\n",
    "\"%!in%\" <- function(x,table) match(x,table, nomatch = 0) == 0\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/ll_kt_both_bbmle.R\")\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/ll_kt_both_grid_search.R\")\n",
    "source(\"~/oceanography/scripts/neg_LL_biophys.R\")\n",
    "#source(\"~/oceanography/scripts/PredictedProportions.R\")\n",
    "\n",
    "#read in the kernel fitting summary\n",
    "kernels <- fread(file=\"~/parentage/kernel_fitting/1340_loci/final_results/tables/kernel_fitting_summary.csv\")\n",
    "kernel2012_14 <- fread(file=\"~/oceanography/empirical_data/genetics/GenKernelsForROMSComp2012-14.csv\")\n",
    "\n",
    "#read in the centroids adjusted for the simulation, so the Magbangons combined \n",
    "#centroids <- fread(file=\"~/oceanography/script_output/SurveyData/SimulationCentroids.csv\")\n",
    "Centroids <- fread(file=\"~/oceanography/empirical_data/site_centroids_SimTest.csv\")\n",
    "setorder(Centroids, site)\n",
    "#read in the table with number of recruits sampled at each site for each year\n",
    "AnnualRecsSamp <- fread(file=\"~/oceanography/script_output/SurveyData/AnnualRecruitsSampled.csv\")\n",
    "#read in the table of the proportion of anemones sampled at each site for each year\n",
    "PropSamp <- fread(file=\"~/oceanography/script_output/SurveyData/ProportionHabitatSampled.csv\")\n",
    "setnames(PropSamp, c(\"PropAnemSamp\", \"TotalAnems\"), c(\"prop_anem_samp\", \"total_anems\"))\n",
    "#read in the ROMS simulation connectivity table with metadata, not yet subsetted (*but check this)\n",
    "#SimConn <- fread(file=\"~/oceanography/script_output/ROMSDataTables/SimConnectivityTableWithMetaLongForm.csv\")\n",
    "\n",
    "#add in the numbers of particles seeded at each site\n",
    "SeededParticles <- fread(\"~/oceanography/ROMS/data/Particles_Per_Release_Site_Renamed.csv\")\n",
    "setnames(SeededParticles,c(\"source\", \"daily_particles_released\")) \n",
    "#DateJoin <- SeededParticles[DateJoin, on=\"source\"][, particles_released_daily := as.numeric(particles_released_daily)] \n",
    "\n",
    "#make vectors defining sites we didn't sample, but that are in the model, and the sandflats specifically \n",
    "unsampled_sites <- c(\"SF1\", \"SF2\", \"SF3\", \"SF4\", \"SF5\", \"SF6\", \"Pangasugan\", \"Other\", \"CAI\") \n",
    "sand_flats <- c(\"SF1\", \"SF2\", \"SF3\", \"SF4\", \"SF5\", \"SF6\") \n",
    "unrealistic_sources <- c(\"SF1\", \"SF2\", \"SF3\", \"SF4\", \"SF5\", \"SF6\", \"Pangasugan\") \n",
    "#make the constant inputs for the kernel fitting function\n",
    "#distance matrix using the centroids with combined Magbangon\n",
    "### List of source locations\n",
    "SitesSource <- Centroids\n",
    "\n",
    "### List of destination locations\n",
    "SitesDest <- Centroids\n",
    "\n",
    "DistMatm <- distm(SitesSource[,c('lon','lat')], SitesSource[,c('lon','lat')], fun=distVincentyEllipsoid)\n",
    "Distances <- DistMatm*10^-3\n",
    "#read in the reef areas for the kernel fitting\n",
    "Area <- fread(\"~/oceanography/empirical_data/site_area_header_nonsurveyed_simulation_kernels_test.csv\") %>%\n",
    "    arrange(site) %>%\n",
    "    filter(site %!in% c(\"near_north_full1\", \"near_north_full2\", \"near_north_full3\", \"near_south_full1\", \"near_south_full2\", \"near_south_full3\")) %>%\n",
    "    mutate(kmsq=msq*10^-6)# %>%\n",
    "    #select(kmsq) #need to uncomment for functions to work\n",
    "setorder(Area, site)\n",
    "reef_sizes <- as.matrix(Area$kmsq)\n",
    "\n",
    "#make a site index table, use this for Sampled_reefs input in kernel fitting\n",
    "SiteIndex <- unique(Centroids, by=\"site\")[, index := .I] #add the row number as the unique site index, leave CAI in if fitting a kernel \n",
    "SiteIndexBioPhys <- unique(Centroids, by=\"site\")[site != \"CAI\"][, index := .I] #add the row number as the unique site index, take CAI out for biophysical likelihood function\n",
    "\n",
    "#make a table with the survey information for each site (how many fish sampled, prop anems sampled, total number of anems at site)\n",
    "SurveyData <- AnnualRecsSamp[PropSamp, on=.(year=end_year, site)][#join the sampling tables together\n",
    "    is.na(n_offs_gen), n_offs_gen := 0][,#change NA's to 0\n",
    "    -\"time_frame\"]#drop the time_frame column, we can key with end_year\n",
    "#setnames(SurveyData, c(\"PropAnemSamp\", \"TotalAnems\"), c(\"prop_anem_samp\", \"total_anems\"))\n",
    "#setkey(SurveyData, site)\n",
    "#check all sites are represented in centroids and area (and indirectly distances, which comes from centroids)\n",
    "#Area[site %!in% centroids$site] #should be nothing\n",
    "\n",
    "#Allison's abundance time series data \n",
    "#download.file(url = \"https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Script_outputs/females_df_F.RData?raw=true\", destfile = \"~/oceanography/empirical_data/genetics/females_df_F.RData\")\n",
    "load(\"~/oceanography/empirical_data/genetics/females_df_F.RData\")\n",
    "Abundance <- as.data.table(females_df_F)\n",
    "setnames(Abundance, \"nF\", \"num_females\")\n",
    "Abundance <- unique(Abundance[site %like% \"Magbangon\", site := \"Magbangon\"][ #collapse Magbangon values\n",
    "            , num_females := sum(num_females), by=c(\"site\", \"year\")], by=c(\"site\", \"year\"))\n",
    "#join the survey sampling tables together\n",
    "SurveyData <- AnnualRecsSamp[PropSamp, on=.(year=end_year, site)][\n",
    "    is.na(n_offs_gen), n_offs_gen := 0][,#change NA's to 0\n",
    "    -\"time_frame\"]#drop the time_frame\n",
    "\n",
    "SurveyData <- Abundance[, c(\"year\", \"site\", \"num_females\")][SurveyData, on=.(year, site)]#join in Allison's estimate of female abundance. There are NA values, but that's okay we can figure those out when we start thinking about incorporating uncertainty in this\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "687"
      ],
      "text/latex": [
       "687"
      ],
      "text/markdown": [
       "687"
      ],
      "text/plain": [
       "[1] 687"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make a table of the dates of release for simulations, for calculating the number of particles released in each time frame\n",
    "season1 <- data.table(date=seq(as.Date(\"2010-10-01\"), as.Date(\"2011-05-31\"), by=\"days\"))\n",
    "\n",
    "season2 <- data.table(date=seq(as.Date(\"2011-10-01\"), as.Date(\"2012-05-31\"), by=\"days\"))\n",
    "\n",
    "season3 <- data.table(date=seq(as.Date(\"2012-10-01\"), as.Date(\"2013-05-31\"), by=\"days\"))\n",
    "\n",
    "season4 <- data.table(date=seq(as.Date(\"2013-10-01\"), as.Date(\"2014-04-18\"), by=\"days\"))\n",
    "\n",
    "AllDates <- rbind(season1, season2, season3, season4)\n",
    "\n",
    "#mark the monsoon seasons, based on the same criteria I used for the parentage indirectly through the growth estimates\n",
    "NEM <- c(11, 12, 1, 2, 3, 4, 5, 6)\n",
    "SWM <- c(7, 8, 9, 10)\n",
    "\n",
    "AllDates[,date := ymd(date)][, #format as ymd\n",
    "             sim_monsoon := ifelse(month(date) %in% NEM, \"NEM\", \"SWM\")][,#mark monsoon season based on month\n",
    "             sim_year:=year(date)][,#add year column\n",
    "            year_sampled:= ifelse(date %in% season1$date, 2011, ifelse(date %in% season2$date, 2012, ifelse(date %in% season3$date, 2013, 2014)))]#and then add a year_sampled for the empircal sampling season of that particle\n",
    "\n",
    "ReleaseDays <- AllDates[, .(num_release_days_seasonal=.N), by=c(\"year_sampled\", \"sim_monsoon\")][, num_release_days_annual:= sum(num_release_days_seasonal), by=year_sampled]\n",
    "\n",
    "total_release_days <- AllDates[year_sampled %in% c(2012, 2013, 2014), .N]#for the all year kernel- how many days of the simulation conincide with our particle sampling?\n",
    "total_release_days #should be 687\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "##prep biophysical connectivity matrix\n",
    "##outside of the loop, trim this to only be the destinations we sampled\n",
    "#SourceJoin <- SurveyData[SimConn, on = .(site = source, year=year_sampled)]\n",
    "#setnames(SourceJoin, skip_absent=TRUE, c(\"site\", \"n_offs_gen\", \"prop_anem_samp\", \"total_anems\", \"num_females\"), c(\"source\", \"source_num_rec_sampled_annual\",  \"source_prop_anem_samp\", \"source_total_anems\", \"source_num_females\"))\n",
    "#DestJoin <- SurveyData[SourceJoin, on = .(site = dest, year)]\n",
    "#setnames(DestJoin, skip_absent=TRUE, c(\"site\", \"n_offs_gen\", \"prop_anem_samp\", \"total_anems\", \"num_females\"), c(\"dest\", \"dest_num_rec_sampled_annual\",  \"dest_prop_samp\", \"dest_total_anems\", \"dest_num_females\"))\n",
    "#\n",
    "#SimConn <- DestJoin[source %!in% unrealistic_sources & dest %!in% unrealistic_sources & year %in% c(2012, 2013, 2014)][#sand flats and Pangasugan are not realistic source or destination sites because there's almost no habitat. Safe to drop, but keep the rest of the possibilities so we can subsample iteratively all possibilities.\n",
    "#    , daily_particles_released := as.numeric(daily_particles_released)] #change from integer to numeric\n",
    "#SimConn <- ReleaseDays[SimConn, on=.(year_sampled=year, sim_monsoon)]#join in the info for number of release days in the time frame\n",
    "#SimConn <- kernels[Year %in% c(\"2012\", \"2013\", \"2014\")][, year:=as.integer(Year)][,c(\"year\", \"NumParentageMatches\")][SimConn, on=.(year=year_sampled)]#add in a column for the observed number of parentage matches\n",
    "##rename the monsoon column in the full table for consistency\n",
    "#setnames(SimConn, c(\"sim_monsoon\", \"NumParentageMatches\"), c(\"monsoon\", \"num_route_parentage_matches\")) #get rid of upper case and inconsistent naming\n",
    "#setcolorder(SimConn, c(\"particle_id\", \"source\", \"dest\", \"year\", \"monsoon\", \"date\"))\n",
    "#\n",
    "##at this point, we can make the raw number assignment matrix, but we want to make a normalized version that is num assigned from a source to a destination/ num released from that source\n",
    "##fwrite(SimConn, file=\"~/oceanography/script_output/ROMSDataTables/SimConnectivityTableCompleteMetaLongForm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "__Skip the joining of tables that takes forever and read in the__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimConn <- fread(file=\"~/oceanography/script_output/ROMSDataTables/SimConnectivityTableCompleteMetaLongForm.csv\")[dest != \"CAI\"] #filter out CAI as a destination for now, not very well spatially defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each year will require a different set of survey data, so make a list of each and index by site for fast look up\n",
    "SampledTable <- SurveyData[prop_anem_samp >0, c(\"year\", \"site\")]#previously named PropSampTable\n",
    "\n",
    "#make sure all sampled sites are represented when joining the survey data to the sampled simulation- this chunk has the tables to add to a subsampled particle table. no need for the full\n",
    "SampTable <- rbind(SurveyData[prop_anem_samp >0 & year %in% c(2012, 2013, 2014), c(\"year\", \"site\")][, .(source=site, dest=site, year=year)][, #will join to the simulated sampling table by source and dest, so make those each a column from site and preserve the year variable as a key\n",
    "     c(\"year\", \"source\", \"dest\")][, monsoon := \"NEM\"], SurveyData[prop_anem_samp >0 & year %in% c(2012, 2013, 2014), c(\"year\", \"site\")][, .(source=site, dest=site, year=year)][, #will join to the simulated sampling table by source and dest, so make those each a column from site and preserve the year variable as a key\n",
    "     c(\"year\", \"source\", \"dest\")][, monsoon := \"SWM\"])\n",
    "\n",
    "UnqSurvey <- unique(SampTable, by=c(\"source\", \"dest\", \"year\", \"monsoon\"))#add in the diff Monsoon seasons so there are complete parentage matrices later\n",
    "\n",
    "AddDestSim <- rbind(rbindlist(list(unique(SimConn[, .(source, dest)], by=c(\"source\", \"dest\"))[, year := 2012],\n",
    "        unique(SimConn[, .(source, dest)], by=c(\"source\", \"dest\"))[, year := 2013], \n",
    "        unique(SimConn[, .(source, dest)], by=c(\"source\", \"dest\"))[, year := 2014]))[, monsoon := \"NEM\"],\n",
    "    rbindlist(list(unique(SimConn[, .(source, dest)], by=c(\"source\", \"dest\"))[, year := 2012],\n",
    "        unique(SimConn[, .(source, dest)], by=c(\"source\", \"dest\"))[, year := 2013], \n",
    "        unique(SimConn[, .(source, dest)], by=c(\"source\", \"dest\"))[, year := 2014]))[, monsoon := \"SWM\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>19</li>\n",
       "\t<li>18</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 19\n",
       "\\item 18\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 19\n",
       "2. 18\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 19 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make a parentage matrix for the whole biophysical results- CAI included with Other as \"unknown\", use this to fit a kernel\n",
    "FullBiophysMat <- as.matrix(rbind(dcast(SimConn[source != \"Other\" & source != \"CAI\" , .(source, dest)][ #for assigned particles (not from \"Other\") keep the source/dest columns that will be expanded into wide form to become the connectivity matrix. Filtering for time period etc can be done in i here.\n",
    "    , parentage :=1][ #mark each row as a parentage match, because at this point I'm using all particles as matches for the simulations\n",
    "    order(source, dest)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , source ~ dest, value.var=\"parentage\", fun.aggregate = sum)[#use sum to count the matches for each id variable combo, that populated the cells of the matrix\n",
    "    ,-\"source\"], #remove the source column after casting\n",
    "      dcast(SimConn[source == \"Other\" | source == \"CAI\", .(source, dest)][ #this is to cast the \"unassigned row for the model parentage, which is anyting from \"Other\"\n",
    "          , parentage :=1][order(source, dest)][, source := \"unknown\"], source ~ dest, value.var=\"parentage\", fun.aggregate = sum)[,-\"source\"]))#bind these two cast wide form data tables (assigned and unassigned particles) and then turn into a matrix to be used in the likelihood functions\n",
    "dim(FullBiophysMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "mle2(minuslogl = LL_kt_bbmle, start = list(k = -3, theta = 1), \n",
       "    method = \"L-BFGS-B\", data = x, lower = c(-10, 0.15), upper = c(10, \n",
       "        8), control = list(maxit = 500))\n",
       "\n",
       "Coefficients:\n",
       "         k      theta \n",
       "-0.3123332  0.6214954 \n",
       "\n",
       "Log-likelihood: -2021634 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x <- list(Distances=Distances, Assignments=FullBiophysMat, Sampled_reefs=t(SiteIndex[site %in% SurveyData[, site], index]), #if CAI is it's own site- site %in% AllYearsRec[, dest]\n",
    "                  Reef_sizes=reef_sizes, Adult_sample_proportions=matrix(nrow=ncol(FullBiophysMat), ncol=1, 1)) #put inputs into a list because that's the bbmle format\n",
    "Sim2012_4Fit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "Sim2012_4Fit\n",
    "#Next, do grid search to get the likelihood profile to compare to genetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "21408598.053702"
      ],
      "text/latex": [
       "21408598.053702"
      ],
      "text/markdown": [
       "21408598.053702"
      ],
      "text/plain": [
       "[1] 21408598"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2021656.22065593"
      ],
      "text/latex": [
       "2021656.22065593"
      ],
      "text/markdown": [
       "2021656.22065593"
      ],
      "text/plain": [
       "[1] 2021656"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>-0.299999999999999</li>\n",
       "\t<li>0.62</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.299999999999999\n",
       "\\item 0.62\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.299999999999999\n",
       "2. 0.62\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.30  0.62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use a grid search to find k that minimizes the log likelihood\n",
    "k_eval <- c(seq(from=-10, to=10, by=0.01))\n",
    "theta_eval <- c(seq(from=0.1, to=5, by=.01))\n",
    "nll_matrix <- matrix(data=NA, nrow=length(k_eval), ncol=length(theta_eval), \n",
    "                     dimnames=list(k_eval, theta_eval))\n",
    "pb <- txtProgressBar(min = 0, max = length(k_eval), style = 3)#7 years in each interation\n",
    "\n",
    "#Begin grid search: i <- 1; j <- 1\n",
    "for(i in 1:length(k_eval)){\n",
    "  k <- k_eval[i]\n",
    "  for(j in 1:length(theta_eval)){\n",
    "    theta <- theta_eval[j]\n",
    "    nll_matrix[i,j] <- LL_kt_grid(k=k, theta=theta, Distances=x$Distances, Assignments=x$Assignments, Sampled_reefs=x$Sampled_reefs, Reef_sizes=x$Reef_sizes, Adult_sample_proportions=x$Adult_sample_proportions)\n",
    "  }\n",
    "    setTxtProgressBar(pb, i)\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "close(pb)\n",
    "\n",
    "max(nll_matrix, na.rm = T)\n",
    "min(nll_matrix, na.rm = T)\n",
    "\n",
    "sum(is.na(nll_matrix)==T)\n",
    "best_params_index <- which(nll_matrix == min(nll_matrix, na.rm = T), arr.ind=TRUE)\n",
    "best_params <- c(k_eval[best_params_index[1]], theta_eval[best_params_index[2]])\n",
    "best_params\n",
    "\n",
    "\n",
    "#write profile results\n",
    "#write.csv(nll_matrix, file=\"~/oceanography/script_output/KernelFits/LikelihoodProfileBiophysical2012-4.csv\", row.names=T, quote=FALSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>19</li>\n",
       "\t<li>18</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 19\n",
       "\\item 18\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 19\n",
       "2. 18\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 19 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#at this point, we can make the raw number assignment matrix, but we want to make a normalized version that is num assigned from a source to a destination/ num released from that source\n",
    "total_release_days <- 687\n",
    "\n",
    "AllYearsRec <- SimConn[ , .(total_particles_rec = .N), by= c(\"source\",\"dest\")] #all particles recruiting along each route FILTER HERE FOR TIME PERIOD***\n",
    "AllYearsRelease <- unique(SimConn[, .(total_particles_released = as.numeric(daily_particles_released)*as.numeric(total_release_days)), by= c(\"source\")], by=\"source\") #calculate the number of particles released over the time frame by multiplyig the release days by the number of particles released daily. fread() converts big numbers to integers so specify as numeric to avoid integer overflow NAs\n",
    "\n",
    "#make sure all possible routes are represented\n",
    "AddDestAllYearsSim <- unique(AddDestSim, by=c(\"source\",\"dest\"))[, -c(\"year\",\"monsoon\")] \n",
    "\n",
    "AllYearsRecInt <- rbind(AddDestAllYearsSim[!AllYearsRec, on =.(source, dest)][ #what combos are not appearing because we didn't sample particles, but the route is possible based on our survey sampling\n",
    "    , total_particles_rec:=0 ], AllYearsRec) \n",
    "\n",
    "AllYearsReleaseInt <- rbind(AddDestAllYearsSim[!AllYearsRelease, on =.(source)][ #what combos are not appearing because we didn't sample particles, but the route is possible based on our survey sampling\n",
    "    , total_particles_released:=0 ][, -\"dest\"], AllYearsRelease) \n",
    "\n",
    "#collapse CAI and \"Other\" together into \"unknown\" before making the normalized matrices\n",
    "AllYearsRec <- unique(AllYearsRecInt[source== \"Other\" | source == \"CAI\", source := \"unknown\"][\n",
    "    , total_particles_rec := sum(total_particles_rec),  by=c(\"source\", \"dest\")], by=c(\"source\", \"dest\"))\n",
    "AllYearsRelease <- unique(AllYearsReleaseInt[source== \"Other\" | source == \"CAI\", source := \"unknown\"][\n",
    "    , total_particles_released := sum(total_particles_released), by=\"source\"], by=\"source\")\n",
    "\n",
    "#join recruited and released tables together and make a column for the normalized values\n",
    "AllYearsNormConn <-  AllYearsRelease[AllYearsRec, on=\"source\"][\n",
    "    , source_norm_rec := total_particles_rec/total_particles_released]\n",
    "\n",
    "#check that they sum to =< 1\n",
    "#AllYearsNormConn[,sum(source_norm_rec), by=\"source\"]#nothing should be greater than 1. It isn't- great\n",
    "\n",
    "#make sure all possible routes are represented!!*\n",
    "#cast into wide format\n",
    "FullBiophysMatNorm <- as.matrix(rbind(dcast(AllYearsNormConn[source !=\"unknown\", .(source, dest, source_norm_rec)][ #for assigned particles (not from \"Other\") keep the source/dest columns that will be expanded into wide form to become the connectivity matrix. Filtering for time period etc can be done in i here.\n",
    "    order(source, dest)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , source ~ dest, value.var=\"source_norm_rec\")[\n",
    "    ,-\"source\"], #remove the source column after casting\n",
    "      dcast(AllYearsNormConn[source == \"unknown\", .(source, dest, source_norm_rec)][ #this is to cast the \"unassigned row for the model parentage, which is anyting from \"Other\"\n",
    "          order(source, dest)], source ~ dest, value.var=\"source_norm_rec\")[,-\"source\"]))#bind these two cast wide form data tables (assigned and unassigned particles) and then turn into a matrix to be used in the likelihood functions\n",
    "dim(FullBiophysMatNorm )\n",
    "FullBiophysMatNorm[is.na(FullBiophysMatNorm)] <- 0 #change NAs to zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>19</li>\n",
       "\t<li>18</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 19\n",
       "\\item 18\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 19\n",
       "2. 18\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 19 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>19</li>\n",
       "\t<li>18</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 19\n",
       "\\item 18\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 19\n",
       "2. 18\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 19 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>19</li>\n",
       "\t<li>18</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 19\n",
       "\\item 18\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 19\n",
       "2. 18\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 19 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make annual matrices with all of the particle data\n",
    "AnnualRec <- SimConn[ , .(annual_particles_rec = .N), by= c(\"source\",\"dest\", \"year\")] #all particles recruiting along each route FILTER HERE FOR TIME PERIOD***\n",
    "AnnualRelease <- unique(SimConn[, .(annual_particles_released = as.numeric(daily_particles_released)*as.numeric(num_release_days_annual)), by= c(\"source\", \"year\")], by= c(\"source\", \"year\")) #calculate the number of particles released over the time frame by multiplyig the release days by the number of particles released daily. fread() converts big numbers to integers so specify as numeric to avoid integer overflow NAs\n",
    "\n",
    "#make sure all possible routes are represented\n",
    "AddDestAnnualSim <- unique(AddDestSim, by=c(\"source\",\"dest\", \"year\"))[, -\"monsoon\"] \n",
    "\n",
    "AnnualRecInt <- rbind(AddDestAnnualSim[!AnnualRec, on =.(source, dest, year)][ #what combos are not appearing because we didn't sample particles, but the route is possible based on our survey sampling\n",
    "    , annual_particles_rec:=0 ], AnnualRec) \n",
    "\n",
    "AnnualReleaseInt <- rbind(AddDestAnnualSim[!AnnualRelease, on =.(source, year)][ #what combos are not appearing because we didn't sample particles, but the route is possible based on our survey sampling\n",
    "    , annual_particles_released:=0 ][, -\"dest\"], AnnualRelease) \n",
    "\n",
    "#collapse CAI and \"Other\" together into \"unknown\" before making the normalized matrices\n",
    "AnnualRec <- unique(AnnualRecInt[source== \"Other\" | source == \"CAI\", source := \"unknown\"][\n",
    "    , annual_particles_rec := sum(annual_particles_rec), by=c(\"source\", \"dest\", \"year\")], by=c(\"source\", \"dest\", \"year\"))\n",
    "AnnualRelease <- unique(AnnualReleaseInt[source== \"Other\" | source == \"CAI\", source := \"unknown\"][\n",
    "    , annual_particles_released := sum(annual_particles_released), by=c(\"source\", \"year\")], by=c(\"source\", \"year\"))\n",
    "\n",
    "#join recruited and released tables together and make a column for the normalized values\n",
    "AnnualNormConn <-  AnnualRelease[AnnualRec, on=c(\"source\", \"year\")][\n",
    "    , source_norm_rec := annual_particles_rec/annual_particles_released]\n",
    "#check that they sum to =< 1\n",
    "#summary(AnnualNormConn[, .(sum=sum(source_norm_rec)), by=c(\"year\", \"source\")][, sum])#nothing should exceed 1, it doesn't- great\n",
    "\n",
    "#cast into wide format for each year\n",
    "\n",
    "AnnualBiophysMatNorm2012 <- as.matrix(rbind(dcast(AnnualNormConn[year==2012 & source != \"unknown\", .(source, dest, source_norm_rec)][ #for assigned particles (not from \"Other\") keep the source/dest columns that will be expanded into wide form to become the connectivity matrix. Filtering for time period etc can be done in i here.\n",
    "    order(source, dest)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , source ~ dest, value.var=\"source_norm_rec\")[\n",
    "    ,-\"source\"], #remove the source column after casting\n",
    "      dcast(AnnualNormConn[year==2012][source == \"unknown\", .(source, dest, source_norm_rec)][ #this is to cast the \"unassigned row for the model parentage, which is anyting from \"Other\"\n",
    "          order(source, dest)], source ~ dest, value.var=\"source_norm_rec\")[,-\"source\"]))#bind these two cast wide form data tables (assigned and unassigned particles) and then turn into a matrix to be used in the likelihood functions\n",
    "dim(AnnualBiophysMatNorm2012)\n",
    "AnnualBiophysMatNorm2012[is.na(AnnualBiophysMatNorm2012)] <- 0 #change NAs to zeros\n",
    "\n",
    "AnnualBiophysMatNorm2013 <- as.matrix(rbind(dcast(AnnualNormConn[year==2013 & source != \"unknown\", .(source, dest, source_norm_rec)][ #for assigned particles (not from \"Other\") keep the source/dest columns that will be expanded into wide form to become the connectivity matrix. Filtering for time period etc can be done in i here.\n",
    "    order(source, dest)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , source ~ dest, value.var=\"source_norm_rec\")[\n",
    "    ,-\"source\"], #remove the source column after casting\n",
    "      dcast(AnnualNormConn[year==2013][source == \"unknown\", .(source, dest, source_norm_rec)][ #this is to cast the \"unassigned row for the model parentage, which is anyting from \"Other\"\n",
    "          order(source, dest)], source ~ dest, value.var=\"source_norm_rec\")[,-\"source\"]))#bind these two cast wide form data tables (assigned and unassigned particles) and then turn into a matrix to be used in the likelihood functions\n",
    "dim(AnnualBiophysMatNorm2013)\n",
    "AnnualBiophysMatNorm2013[is.na(AnnualBiophysMatNorm2013)] <- 0 #change NAs to zeros\n",
    "\n",
    "AnnualBiophysMatNorm2014 <- as.matrix(rbind(dcast(AnnualNormConn[year==2014 & source != \"unknown\", .(source, dest, source_norm_rec)][ #for assigned particles (not from \"Other\") keep the source/dest columns that will be expanded into wide form to become the connectivity matrix. Filtering for time period etc can be done in i here.\n",
    "    order(source, dest)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , source ~ dest, value.var=\"source_norm_rec\")[\n",
    "    ,-\"source\"], #remove the source column after casting\n",
    "      dcast(AnnualNormConn[year==2014][source == \"unknown\", .(source, dest, source_norm_rec)][ #this is to cast the \"unassigned row for the model parentage, which is anyting from \"Other\"\n",
    "          order(source, dest)], source ~ dest, value.var=\"source_norm_rec\")[,-\"source\"]))#bind these two cast wide form data tables (assigned and unassigned particles) and then turn into a matrix to be used in the likelihood functions\n",
    "dim(AnnualBiophysMatNorm2014)\n",
    "AnnualBiophysMatNorm2014[is.na(AnnualBiophysMatNorm2014)] <- 0 #change NAs to zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>19</li>\n",
       "\t<li>18</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 19\n",
       "\\item 18\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 19\n",
       "2. 18\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 19 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make monsoon matrices with all of the particle data\n",
    "MonsoonRec <- SimConn[ , .(monsoon_particles_rec = .N), by= c(\"source\",\"dest\", \"monsoon\")] #all particles recruiting along each route FILTER HERE FOR TIME PERIOD***\n",
    "MonsoonRelease <- unique(SimConn[, .(monsoon_particles_released = as.numeric(daily_particles_released)*as.numeric(num_release_days_seasonal)), by= c(\"source\", \"monsoon\")], by= c(\"source\", \"monsoon\")) #calculate the number of particles released over the time frame by multiplyig the release days by the number of particles released daily. fread() converts big numbers to integers so specify as numeric to avoid integer overflow NAs\n",
    "\n",
    "#make sure all possible routes are represented\n",
    "\n",
    "AddDestMonsoonSim <- unique(AddDestSim[, -\"year\"], by=c(\"source\", \"dest\", \"monsoon\"))\n",
    "MonsoonRec <- SimConn[ , .(monsoon_particles_rec = .N), by= c(\"source\",\"dest\", \"monsoon\")] #all particles recruiting along each route FILTER HERE FOR TIME PERIOD***\n",
    "MonsoonRelease <- unique(SimConn[, .(monsoon_particles_released = as.numeric(daily_particles_released)*as.numeric(num_release_days_seasonal)), by= c(\"source\", \"monsoon\")], by= c(\"source\", \"monsoon\")) #calculate the number of particles released over the time frame by multiplyig the release days by the number of particles released daily. fread() converts big numbers to integers so specify as numeric to avoid integer overflow NAs\n",
    "\n",
    "MonsoonRecInt <- rbind(AddDestMonsoonSim[!MonsoonRec, on =.(source, dest, monsoon)][ #what combos are not appearing because we didn't sample particles, but the route is possible based on our survey sampling\n",
    "    , monsoon_particles_rec:=0 ], MonsoonRec) \n",
    "\n",
    "MonsoonReleaseInt <- rbind(AddDestMonsoonSim[!MonsoonRelease, on =.(source, monsoon)][ #what combos are not appearing because we didn't sample particles, but the route is possible based on our survey sampling\n",
    "    , monsoon_particles_released:=0 ][, -\"dest\"], MonsoonRelease) \n",
    "\n",
    "#collapse CAI and \"Other\" together into \"unknown\" before making the normalized matrices\n",
    "MonsoonRec <- unique(MonsoonRecInt[source== \"Other\" | source == \"CAI\", source := \"unknown\"][\n",
    "    , monsoon_particles_rec := sum(monsoon_particles_rec), by=c(\"source\", \"dest\", \"monsoon\")], by=c(\"source\", \"dest\", \"monsoon\"))\n",
    "MonsoonRelease <- unique(MonsoonReleaseInt[source== \"Other\" | source == \"CAI\", source := \"unknown\"][\n",
    "    , monsoon_particles_released := sum(monsoon_particles_released), by=c(\"source\", \"monsoon\")], by=c(\"source\", \"monsoon\"))\n",
    "\n",
    "#join recruited and released tables together and make a column for the normalized values\n",
    "MonsoonNormConn <-  MonsoonRelease[MonsoonRec, on=c(\"source\", \"monsoon\")][\n",
    "    , source_norm_rec := monsoon_particles_rec/monsoon_particles_released]\n",
    "#check that they sum to =< 1\n",
    "#summary(MonsoonNormConn[, .(sum=sum(source_norm_rec)), by=c(\"monsoon\", \"source\")][, sum])#nothing should exceed 1, it doesn't- great\n",
    "\n",
    "MonsoonBiophysMatNormNEM <- as.matrix(rbind(dcast(MonsoonNormConn[monsoon==\"NEM\" & source != \"unknown\", .(source, dest, source_norm_rec)][ #for assigned particles (not from \"Other\") keep the source/dest columns that will be expanded into wide form to become the connectivity matrix. Filtering for time period etc can be done in i here.\n",
    "    order(source, dest)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , source ~ dest, value.var=\"source_norm_rec\")[\n",
    "    ,-\"source\"], #remove the source column after casting\n",
    "      dcast(MonsoonNormConn[monsoon==\"NEM\"][source == \"unknown\", .(source, dest, source_norm_rec)][ #this is to cast the \"unassigned row for the model parentage, which is anyting from \"Other\"\n",
    "          order(source, dest)], source ~ dest, value.var=\"source_norm_rec\")[,-\"source\"]))#bind these two cast wide form data tables (assigned and unassigned particles) and then turn into a matrix to be used in the likelihood functions\n",
    "dim(MonsoonBiophysMatNormNEM)\n",
    "MonsoonBiophysMatNormNEM[is.na(MonsoonBiophysMatNormNEM)] <- 0 #change NAs to zeros\n",
    "\n",
    "MonsoonBiophysMatNormSWM <- as.matrix(rbind(dcast(MonsoonNormConn[monsoon==\"SWM\" & source != \"unknown\", .(source, dest, source_norm_rec)][ #for assigned particles (not from \"Other\") keep the source/dest columns that will be expanded into wide form to become the connectivity matrix. Filtering for time period etc can be done in i here.\n",
    "    order(source, dest)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , source ~ dest, value.var=\"source_norm_rec\")[\n",
    "    ,-\"source\"], #remove the source column after casting\n",
    "      dcast(MonsoonNormConn[monsoon==\"SWM\"][source == \"unknown\", .(source, dest, source_norm_rec)][ #this is to cast the \"unassigned row for the model parentage, which is anyting from \"Other\"\n",
    "          order(source, dest)], source ~ dest, value.var=\"source_norm_rec\")[,-\"source\"]))#bind these two cast wide form data tables (assigned and unassigned particles) and then turn into a matrix to be used in the likelihood functions\n",
    "dim(MonsoonBiophysMatNormSWM)\n",
    "MonsoonBiophysMatNormSWM[is.na(MonsoonBiophysMatNormSWM)] <- 0 #change NAs to zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x being coerced from class: matrix to data.table\n",
      "x being coerced from class: matrix to data.table\n",
      "x being coerced from class: matrix to data.table\n",
      "x being coerced from class: matrix to data.table\n"
     ]
    }
   ],
   "source": [
    "#read in the genetic parentage data and format for comparison\n",
    "TotalPar2012_4 <- fread(file=\"~/oceanography/empirical_data/genetics/parentage_table_2012-14.csv\")\n",
    "TotalPar2012_4 <- unique(TotalPar2012_4[offs_site %like% \"Magbangon\", offs_site := \"Magbangon\"][par_site %like% \"Magbangon\", par_site := \"Magbangon\"][ #collapse Magbangon values\n",
    "            , n_matches := sum(n_matches), by=c(\"offs_site\", \"par_site\", \"year\")], by=c(\"offs_site\", \"par_site\", \"year\"))\n",
    "\n",
    "#add in all the sampled sites and numbers of recruits sampled at each site\n",
    "TotalParInt <- unique(TotalPar2012_4[, num_matches := sum(n_matches), by=c(\"year\", \"offs_site\")][, -\"par_site\"], by=c(\"year\", \"offs_site\"))[, -\"n_matches\"]\n",
    "#sum(TotalParInt$num_matches) #should be 37\n",
    "\n",
    "TotalUnassigned2012_4 <- TotalParInt[SurveyData[year %in% c(2012, 2013, 2014)], on=.(offs_site=site, year)]\n",
    "TotalUnassigned2012_4 [is.na(TotalUnassigned2012_4 )] <- 0\n",
    "\n",
    "#sum(TotalUnassigned2012_4 $n_offs_gen) #should be 394\n",
    "#sum(TotalUnassigned2012_4 $num_matches) #should be 37\n",
    "#nrow(unique(TotalUnassigned2012_4 , by=\"offs_site\"))#should be 18, so that every site is represented so that the years are all 18*18 sites\n",
    "TotalUnassigned2012_4 <- TotalUnassigned2012_4[, num_unassigned := n_offs_gen-num_matches, by=c(\"year\", \"offs_site\")][\n",
    "    , .(offs_site, year, num_unassigned)]\n",
    "#sum(TotalUnassigned2012_4$num_unassigned) #should be 357\n",
    "\n",
    "#add in sites that aren't represented in every year\n",
    "AddDestGen <- rbindlist(list(unique(cbind(SurveyData[year %in% c(2012, 2013, 2014) ][, .(offs_site=site)], \n",
    "                  SurveyData[year %in% c(2012, 2013, 2014)][ , .(par_site=site)]), by=c(\"offs_site\", \"par_site\"))[, year := 2012],  #what destinations were sampled, for use with unassigned table\n",
    "unique(cbind(SurveyData[year %in% c(2012, 2013, 2014) ][, .(offs_site=site)], \n",
    "                  SurveyData[year %in% c(2012, 2013, 2014)][ , .(par_site=site)]), by=c(\"offs_site\", \"par_site\"))[, year := 2013],\n",
    "unique(cbind(SurveyData[year %in% c(2012, 2013, 2014) ][, .(offs_site=site)], \n",
    "                  SurveyData[year %in% c(2012, 2013, 2014)][ , .(par_site=site)]), by=c(\"offs_site\", \"par_site\"))[, year := 2014]))\n",
    "\n",
    "TotalPar2012_4 <- rbind(AddDestGen[!TotalPar2012_4, on =.(par_site, offs_site, year)][ #what combos are not appearing because we didn't sample particles, but the route is possible based on our survey sampling\n",
    "    , n_matches:=0 ], TotalPar2012_4[,-\"num_matches\"])  #add the parentage column, add back into the parentage table but drop the num_matches column that's a summary column I used to make the unassigned table \n",
    "#sum(TotalPar2012_4$n_matches)#should be 37 still\n",
    "\n",
    "#format genetic parentage matrices for each year and all years combined\n",
    "GenMat2012 <- as.matrix(rbind(dcast(TotalPar2012_4[year==2012, .(par_site, offs_site, n_matches)][ #for assigned particles (not from \"Other\") keep the source/dest columns that will be expanded into wide form to become the connectivity matrix. Filtering for time period etc can be done in i here.\n",
    "    order(par_site, offs_site)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , par_site ~ offs_site, value.var=\"n_matches\")[\n",
    "    ,-\"par_site\"], #remove the source column after casting\n",
    "      t(as.matrix(TotalUnassigned2012_4[year==2012][order(offs_site)][, .(num_unassigned)])), use.names=FALSE))\n",
    "GenMat2012[is.na(GenMat2012)] <- 0\n",
    "\n",
    "GenMat2013 <- as.matrix(rbind(dcast(TotalPar2012_4[year==2013, .(par_site, offs_site, n_matches)][ #for assigned particles (not from \"Other\") keep the source/dest columns that will be expanded into wide form to become the connectivity matrix. Filtering for time period etc can be done in i here.\n",
    "    order(par_site, offs_site)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , par_site ~ offs_site, value.var=\"n_matches\")[\n",
    "    ,-\"par_site\"], #remove the source column after casting\n",
    "      t(as.matrix(TotalUnassigned2012_4[year==2013][order(offs_site)][, .(num_unassigned)])), use.names=FALSE))\n",
    "GenMat2013[is.na(GenMat2013)] <- 0\n",
    "\n",
    "GenMat2014 <- as.matrix(rbind(dcast(TotalPar2012_4[year==2014, .(par_site, offs_site, n_matches)][ #for assigned particles (not from \"Other\") keep the source/dest columns that will be expanded into wide form to become the connectivity matrix. Filtering for time period etc can be done in i here.\n",
    "    order(par_site, offs_site)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , par_site ~ offs_site, value.var=\"n_matches\")[\n",
    "    ,-\"par_site\"], #remove the source column after casting\n",
    "      t(as.matrix(TotalUnassigned2012_4[year==2014][order(offs_site)][, .(num_unassigned)])), use.names=FALSE))\n",
    "GenMat2014[is.na(GenMat2014)] <- 0\n",
    "\n",
    "GenMat2012_4 <- as.matrix(rbind(dcast(TotalPar2012_4[, .(par_site, offs_site, n_matches)][ #for assigned particles (not from \"Other\") keep the source/dest columns that will be expanded into wide form to become the connectivity matrix. Filtering for time period etc can be done in i here.\n",
    "    order(par_site, offs_site)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , par_site ~ offs_site, value.var=\"n_matches\", fun.aggregate = sum)[\n",
    "    ,-\"par_site\"], #remove the source column after casting\n",
    "      t(as.matrix(TotalUnassigned2012_4[, .(num_unassigned=sum(num_unassigned)), by=\"offs_site\"][order(offs_site)][, .(num_unassigned)])), use.names=FALSE))\n",
    "GenMat2012_4[is.na(GenMat2012_4)] <- 0\n",
    "\n",
    "#format seasonal genetic parentage\n",
    "NEMParentageMat <- fread(file=\"~/parentage/kernel_fitting/1340_loci/input/20200624_parentage_matrix_NEM2012-14ForROMSComp.csv\")\n",
    "NEMParentageMat[, par_site := c(as.character(colnames(NEMParentageMat)), \"unassigned\")]\n",
    "\n",
    "#make into a table format to make sure Magbangon names get corrected and all routes are represented\n",
    "NEMParentage <- melt(NEMParentageMat, id.vars=\"par_site\",  variable.name=\"offs_site\", value.name=\"n_matches\")[, offs_site := as.character(offs_site)]\n",
    "NEMParentage <- unique(NEMParentage[offs_site %like% \"Magbangon\", offs_site := \"Magbangon\"][par_site %like% \"Magbangon\", par_site := \"Magbangon\"][ #collapse Magbangon values\n",
    "            , n_matches := sum(n_matches), by=c(\"offs_site\", \"par_site\")], by=c(\"offs_site\", \"par_site\"))\n",
    "\n",
    "#turn back into a matrix format\n",
    "GenMatNEM <- rbind(dcast(NEMParentage[par_site != \"unassigned\"][order(offs_site, par_site)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , par_site ~ offs_site, value.var=\"n_matches\", fun.aggregate= sum)[\n",
    "    ,-\"par_site\"],\n",
    "t(as.matrix(NEMParentage[par_site ==\"unassigned\"][order(offs_site)][, .(n_matches)])), use.names=FALSE)\n",
    "\n",
    "SWMParentageMat <- fread(file=\"~/parentage/kernel_fitting/1340_loci/input/20200624_parentage_matrix_SWM2012-14ForROMSComp.csv\")\n",
    "SWMParentageMat[, par_site := c(as.character(colnames(SWMParentageMat)), \"unassigned\")]\n",
    "\n",
    "#make into a table format to make sure Magbangon names get corrected and all routes are represented\n",
    "SWMParentage <- melt(SWMParentageMat, id.vars=\"par_site\",  variable.name=\"offs_site\", value.name=\"n_matches\")[, offs_site := as.character(offs_site)]\n",
    "SWMParentage <- unique(SWMParentage[offs_site %like% \"Magbangon\", offs_site := \"Magbangon\"][par_site %like% \"Magbangon\", par_site := \"Magbangon\"][ #collapse Magbangon values\n",
    "            , n_matches := sum(n_matches), by=c(\"offs_site\", \"par_site\")], by=c(\"offs_site\", \"par_site\"))\n",
    "\n",
    "#turn back into a matrix format\n",
    "GenMatSWM <- rbind(dcast(SWMParentage[par_site != \"unassigned\"][order(offs_site, par_site)] #keep sites in alphabetical order so the matrix is correctly formatted!\n",
    "        , par_site ~ offs_site, value.var=\"n_matches\", fun.aggregate= sum)[\n",
    "    ,-\"par_site\"],\n",
    "t(as.matrix(SWMParentage[par_site ==\"unassigned\"][order(offs_site)][, .(n_matches)])), use.names=FALSE)\n",
    "\n",
    "fwrite(GenMat2012_4, file=\"~/oceanography/script_output/SurveyData/20210625_ParentageMatrix2012-14ForROMSComp.csv\")\n",
    "fwrite(GenMat2012, file=\"~/oceanography/script_output/SurveyData/20210625_ParentageMatrix2012ForROMSComp.csv\")\n",
    "fwrite(GenMat2013, file=\"~/oceanography/script_output/SurveyData/20210625_ParentageMatrix2013ForROMSComp.csv\")\n",
    "fwrite(GenMat2014, file=\"~/oceanography/script_output/SurveyData/20210625_ParentageMatrix2014ForROMSComp.csv\")\n",
    "fwrite(GenMatNEM, file=\"~/oceanography/script_output/SurveyData/20210625_ParentageMatrixNEM2012-14ForROMSComp.csv\")\n",
    "fwrite(GenMatSWM, file=\"~/oceanography/script_output/SurveyData/20210625_ParentageMatrixSWM2012-14ForROMSComp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "-28545.9549380734"
      ],
      "text/latex": [
       "-28545.9549380734"
      ],
      "text/markdown": [
       "-28545.9549380734"
      ],
      "text/plain": [
       "[1] -28545.95"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lay out all the pieces\n",
    "sampled_reefs_vec <- as.matrix(SiteIndexBioPhys[site %in% SurveyData[, site], .(index)])\n",
    "pop_size_vec <- as.matrix(SurveyData[,.(avg_num_females=mean(num_females, na.rm = TRUE)), by=site][order(site)][, .(avg_num_females)]) #vector of pop sizes for all reefs (a). This term is also used in parentage kernel fitting, but reef sizes are substituted as a proxy for pop size. This is should be bootstrapped to account for uncertainty.\n",
    "BioPhysMat <- as.matrix(FullBiophysMatNorm[1:nrow(sampled_reefs_vec),]) #source normalized biophysical connectivity matrix. In Eqn. S3.4, this is m ajt/r a (*should it be r at? As in all particles released in time period t?)\n",
    "prop_samp_vec <- as.matrix(SurveyData[year == 2014,  .(prop_anem_samp)])#vector of proportion of habitat sampled for all reefs in time period t- I think that I should be coming up with a different value for this, but for now this will help me code the function\n",
    "unassigned_vec <- as.matrix(GenMat2012_4[nrow(GenMat2012_4),])#from genetic parentage data- a vector of the number of unassigned recruits at each destination reef in the system- we only have this for all sampled reefs.... what should the dimensions be?*\n",
    "Assignments <- GenMat2012_4[1:nrow(GenMat2012_4)-1,]\n",
    "\n",
    "data <- list(BioPhysMat=BioPhysMat, Assignments=Assignments, pop_size_vec=pop_size_vec, sampled_reefs_vec=sampled_reefs_vec, prop_samp_vec=prop_samp_vec, unassigned_vec=unassigned_vec)\n",
    "neg_LL_biophys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mike Bode said I should be less aggressively subsampling the biophysical data, but how should I do that? The kernel fitting still requires that I have a prop samp vector... but when I tried putting 1's in that vector and using all of the particles for fitting I got crazy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample the particle data\n",
    "SimSample <- DestSampled[, .SD[sample(.N, dest_n_rec_annual)], by = c(\"year\", \"dest\")] #, prob=surv_weight #randomly sample rows (particles) from the table according to the survival weighting, based on the number we sampled at each site in each year of surveys\n",
    "check1 <- nrow(SimSample)\n",
    "\n",
    "#assign parentage\n",
    "SimParentage <- SimSample[source_prop_samp > 0][, .SD[sample(.N, num_parentage_matches)], by = .(year)][#Prob=SurvWeight, #now randomly assign parentage or not parentage, based on how well we sampled the source and the number of parentage matches we had in that year\n",
    "                , parentage := 1]\n",
    "#for faster searching, set keys\n",
    "setkey(SimParentage, particle_id)\n",
    "setkey(SimSample, particle_id)\n",
    "\n",
    "l <- list(SimSample[particle_id %!in% SimParentage$particle_id][, parentage := 0], SimParentage)\n",
    "SimSample <- rbindlist(l, use.names = TRUE, fill=TRUE, idcol = NULL)[, c(\"year\", \"source\", \"dest\", \"parentage\", \"monsoon\")] #add back in to the unassigned particles, select only the columns necessary\n",
    "\n",
    "#check results, for testing loop only\n",
    "#nrow(SimSample)==check1 #should be TRUE\n",
    "#sum(SimSample$parentage) #should be 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(SimSample$parentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calculate the unassigned row\n",
    "Unassigned <- unique(SimSample[parentage==0][#not counting parentage!\n",
    "    , num_sampled := .(.N), by= c(\"dest\", \"year\", \"monsoon\")], by=c(\"dest\", \"year\", \"monsoon\"))[, -\"source\"]\n",
    "#add destinations not sampled in loop iteration to unassigned \n",
    "Unassigned <- Unassigned[AddDest, on=.(year=year, dest=site, monsoon)]\n",
    "Unassigned$num_sampled[is.na(Unassigned$num_sampled)] <- 0\n",
    "#sum(Unassigned$num_sampled, na.rm=T)==check1-37 #total should be the total sampled particles minus the total assigned\n",
    "setorder(Unassigned, year, dest)\n",
    "\n",
    "##adding in the possible sampled routes needs to happen AFTER calculating unassigned because unassigned is calculated from row counts\n",
    "SimSample <- PropSampTable[SimSample, on=.(year, source, dest, monsoon)]\n",
    "#check all is well- for testing loop only\n",
    "#sum(SimSample$parentage) #should be 37\n",
    "\n",
    "#add in the routes we could have assigned given our sampling so the parentage matrix is complete\n",
    "UnqSimSample <- unique(SimSample, by=c(\"source\", \"dest\", \"year\", \"monsoon\"))\n",
    "\n",
    "AddRoutes <- UnqSurvey[!UnqSimSample, on = names(UnqSurvey)][ #what combos are not appearing because we didn't sample particles, but the route is possible based on our survey sampling\n",
    "    , `:=`(parentage= 0, num_sampled = 0) ] #add the parentage column \n",
    "\n",
    "#add back into the sampled simulation data\n",
    "l <- list(SimSample, AddRoutes[,-\"num_sampled\"])\n",
    "SimSample <- rbindlist(l, use.names = TRUE, fill=TRUE, idcol = NULL)\n",
    "setorder(SimSample, year, source, dest)\n",
    "\n",
    "#make summary tables for each time frame, to be used for making parentage matrix\n",
    "SimSampleByYear <- SimSample[,  .(total_parentage =sum(parentage)), by=c(\"year\", \"source\", \"dest\")]\n",
    "#sum(SimSampleByYear$total_parentage)\n",
    "UnassignedByYear <- Unassigned[, .(total_sampled = sum(num_sampled)), by=c(\"year\", \"dest\")]\n",
    "\n",
    "\n",
    "SimSampleInterannual <- SimSample[,  .(total_parentage =sum(parentage)), by=c(\"source\", \"dest\")]\n",
    "#sum(SimSampleInterannual$total_parentage)\n",
    "UnassignedInterannual <- Unassigned[, .(total_sampled = sum(num_sampled)), by=c(\"dest\")]\n",
    "\n",
    "\n",
    "SimSampleMonsoon <- SimSample[,  .(total_parentage =sum(parentage)), by=c(\"monsoon\", \"source\", \"dest\")]\n",
    "sum(SimSampleMonsoon$total_parentage)\n",
    "UnassignedMonsoon <- Unassigned[, .(total_sampled = sum(num_sampled)), by=c(\"monsoon\", \"dest\")]\n",
    "\n",
    "#make a parentage matrix for each year\n",
    "mat2012 <- dcast(SimSampleByYear[year==2012], source ~ dest, value.var=\"total_parentage\", fun.aggregate = sum)[source %in% SurveyData[year==2012 & prop_anem_samp >0, site]][, -\"source\"] \n",
    "mat2012 <- as.matrix(rbind(mat2012, t(UnassignedByYear[year==2012][, total_sampled]), use.names=F))\n",
    "\n",
    "mat2013 <- dcast(SimSampleByYear[year==2013], source ~ dest, value.var=\"total_parentage\", fun.aggregate = sum)[source %in% SurveyData[year==2013 & prop_anem_samp >0, site]][, -\"source\"] \n",
    "mat2013 <- as.matrix(rbind(mat2013, t(UnassignedByYear[year==2013][, total_sampled]), use.names=F))\n",
    "\n",
    "mat2014 <- dcast(SimSampleByYear[year==2014], source ~ dest, value.var=\"total_parentage\", fun.aggregate = sum)[source %in% SurveyData[year==2014 & prop_anem_samp >0, site]][, -\"source\"] \n",
    "mat2014 <- as.matrix(rbind(mat2014, t(UnassignedByYear[year==2014][, total_sampled]), use.names=F))\n",
    "\n",
    "mat2012_4 <- dcast(SimSampleInterannual, source ~ dest, value.var=\"total_parentage\", fun.aggregate = sum)[source %in% SurveyData[year %in% c(2012, 2013, 2014) & prop_anem_samp >0, site]][, -\"source\"] \n",
    "mat2012_4 <- as.matrix(rbind(mat2012_4, t(UnassignedInterannual[, total_sampled]), use.names=F))\n",
    "\n",
    "matNEM <- dcast(SimSampleMonsoon[monsoon==\"NEM\"], source ~ dest, value.var=\"total_parentage\", fun.aggregate = sum)[source %in% SurveyData[year %in% c(2012, 2013, 2014) & prop_anem_samp >0, site]][, -\"source\"] \n",
    "matNEM <- as.matrix(rbind(matNEM, t(UnassignedMonsoon[monsoon==\"NEM\"][, total_sampled]), use.names=F))\n",
    "\n",
    "matSWM <- dcast(SimSampleMonsoon[monsoon==\"SWM\"], source ~ dest, value.var=\"total_parentage\", fun.aggregate = sum)[source %in% SurveyData[year %in% c(2012, 2013, 2014) & prop_anem_samp >0, site]][, -\"source\"] \n",
    "matSWM <- as.matrix(rbind(matSWM, t(UnassignedMonsoon[monsoon==\"SWM\"][, total_sampled]), use.names=F))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matSWM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biophysical source normalized matrix\n",
    "#for each source, what is the normalized recruitment at each destination? \n",
    "GenSimConn[, annual_source_normalized_recruitment := sum(daily_particles_recruited)/sum(daily_particles_released), by=c(\"source\", \"destination\",\"year_sampled\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for(i in 1:NumSampledReefs){\n",
    "   This_SS_A = Adult_sample_proportions[i]#same\n",
    "   for(j in 1:NumSampledReefs){\n",
    "    SettlersFromAssignedReefs = Settlers[Sampled_reefs[i],Sampled_reefs[j]]#same\n",
    "    #Not all settlers from assigned reefs will be assigned, because not all adults were sampled\n",
    "    AssignedSettlers[i,j] = SettlersFromAssignedReefs*(This_SS_A^2 + 2*This_SS_A*(1 - This_SS_A))\n",
    "    AssignedSettlers[NumSampledReefs+1,j] = AssignedSettlers[NumSampledReefs+1,j] + SettlersFromAssignedReefs*(1-This_SS_A)^2 #The three dots '...' tell matlab that the code on a given line continues on the next line.\n",
    "   }\n",
    "}\n",
    "Unsampled = as.matrix(setdiff(1:NumReefs,Sampled_reefs))\n",
    "\n",
    "\n",
    "for(j in 1:NumSampledReefs){\n",
    "   AssignedSettlers[NumSampledReefs+1,j] = AssignedSettlers[NumSampledReefs+1,j] + sum(Settlers[Unsampled,Sampled_reefs[,j]]) \n",
    "}\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loop through sampling different proportions of other and CAI source particles and compare the unassigned proportions of total sample particles to the genetic observations from survey data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PropAssignedTable <- rbind(kernels[Year %in% c(\"2012\", \"2013\", \"2014\")][\n",
    "    , PropAssigned := PercentAssigned/100][ #change to proportion note percent\n",
    "    , c(\"Year\", \"NumParentageMatches\", \"NumOffsSampled\", \"PropAssigned\")],                      \n",
    "    unique(kernels[Year %in% c(\"2012\", \"2013\", \"2014\")][ #only the years coinciding with the models\n",
    "    , `:=` (NumParentageMatches=sum(NumParentageMatches), NumOffsSampled=sum(NumOffsSampled), PropAssigned = NumParentageMatches/NumOffsSampled, Year = \"2012-4\")][ #summarise across the 3 years\n",
    "    , c(\"Year\",\"NumParentageMatches\", \"NumOffsSampled\", \"PropAssigned\")], by=\"Year\"))\n",
    "    \n",
    "\n",
    "PropAssignedTable[]\n",
    "\n",
    "#add in the average sampled proportion of anemones\n",
    "AvgPropSamp <- SurveyData[PropAnemSamp >0, .(PropAnemSamp = mean(PropAnemSamp)), by=\"year\"][ #average for each site we sampled, how well we sampled\n",
    "    year %in% c(\"2012\", \"2013\", \"2014\")][\n",
    "    , year :=as.character(year)]\n",
    "\n",
    "ExpectedPropAssigned <- AvgPropSamp[PropAssignedTable, on=.(year=Year)]\n",
    "ExpectedPropAssigned$PropAnemSamp[is.na(ExpectedPropAssigned$PropAnemSamp)] <- mean(ExpectedPropAssigned$PropAnemSamp, na.rm = T) #replace the 2012-4 NA with the average from the 3 years\n",
    "\n",
    "#what's the normalized self recruitment proportion back to the population\n",
    "ExpectedPropAssigned[, ExpAssigned := NumParentageMatches/(NumOffsSampled*PropAnemSamp)][] #this is the expected assignment for the whole surveyed population if we had sampled all adults (which we kind of do when we use the simulation results)\n",
    "#at some point... maybe it would be better to compare on a site to site level? idk that's pretty fine scale, I don't know that our ROMS model can be expected to compare so well with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For the expected values of recruits from outside of our sampled region, I'm using the intermediate \"PredictedProportions\" matrix from the Bode kernel fitting script (https://github.com/MikeBode/Parentage_kernel_fitting/blob/master/Kernel_Fitting_Function.m) because it accounts for how well sites were sampled when estimating proportions of recruits from unsampled sites__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####outside of the loop*****\n",
    "\n",
    "PropSampTable <- SurveyData[PropAnemSamp >0, c(\"year\", \"site\")]\n",
    "\n",
    "#make sure all sampled sites are represented by joining the survey data to the sampled simulation\n",
    "PropSampTable <- rbind(SurveyData[PropAnemSamp >0 & year %in% c(2012, 2013, 2014), c(\"year\", \"site\")][, .(Source=site, Dest=site, Year=year)][ #will join to the simulated sampling table by source and dest, so make those each a column from site and preserve the year variable as a key\n",
    "    , c(\"Year\", \"Source\", \"Dest\")][, Monsoon := \"NEM\"], SurveyData[PropAnemSamp >0 & year %in% c(2012, 2013, 2014), c(\"year\", \"site\")][, .(Source=site, Dest=site, Year=year)][ #will join to the simulated sampling table by source and dest, so make those each a column from site and preserve the year variable as a key\n",
    "    , c(\"Year\", \"Source\", \"Dest\")][, Monsoon := \"SWM\"])\n",
    "#unq_survey <- unique(PropSampTable, by=c(\"Source\", \"Dest\", \"Year\", \"Monsoon\"))#, unique(PropSampTable, by=c(\"Source\", \"Dest\", \"Year\"))[, Monsoon := \"SWM\"]) #add in the diff Monsoon seasons so there are complete parentage matrices later\n",
    "#add_dest <- rbind(SurveyData[year %in% c(2012, 2013, 2014) & PropAnemSamp >0][, c(\"year\", \"site\")][, Monsoon := \"NEM\"], SurveyData[year %in% c(2012, 2013, 2014) & PropAnemSamp >0][, c(\"year\", \"site\")][, Monsoon := \"SWM\"])  #what destinations were sampled, for use with unassigned table\n",
    "\n",
    "###outside of the loop\n",
    "PropToEval <- seq(0.1, 1, 0.1) #make a vector of proportions to sample iterativaley and compare\n",
    "#empty table to hold results\n",
    "PropSampOtherCAI <- data.table(TimeScale=character(), TimeID=character(), PropUnassigned=numeric(), ExpUnassigned=numeric(),  PropSampEval=numeric(), Check1=character(), Check2=character(), NrowSimConn=numeric())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb <- txtProgressBar(min = 0, max =length(PropToEval), style = 3)\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "for(i in 1:length(PropToEval)){\n",
    "\n",
    "PropSampOtherCAI_int <- data.table(TimeScale=character(), TimeID=character(), PropUnassigned=numeric(), ExpUnassigned=numeric(),  PropSampEval=numeric(), Check1=character(), Check2=character(), NrowSimConn=numeric())[1:4]\n",
    "\n",
    "dest_sampled <- date_join[DestPropSamp >0]\n",
    "check1 <- nrow(dest_sampled)\n",
    "dest_sampled <- dest_sampled[c(dest_sampled[, .I[Source != \"Other\"]], sample(dest_sampled[, .I[Source == \"Other\"]], length(dest_sampled[, .I[Source == \"Other\"]])*PropToEval[i]))]\n",
    "check2 <- nrow(dest_sampled)\n",
    "dest_sampled <- dest_sampled[c(dest_sampled[, .I[Source != \"CAI\"]], sample(dest_sampled[, .I[Source == \"CAI\"]], length(dest_sampled[, .I[Source == \"CAI\"]])*PropToEval[i]))]\n",
    "check3 <- nrow(dest_sampled)\n",
    "\n",
    "#check that we have less rows, should both be TRUE\n",
    "test1 <- check1 > check2\n",
    "test2 <- check2 > check3\n",
    "#check1 > check2\n",
    "#check2 > check3\n",
    "\n",
    "\n",
    "#join in the number of parentage matches observed by year\n",
    "dest_sampled <- kernels[Year %in% c(\"2012\", \"2013\", \"2014\")][, Year:=as.integer(Year)][,c(\"Year\", \"NumParentageMatches\")][dest_sampled, on=.(Year=YearSampled)]#[\n",
    "\n",
    "#randomly subsample the sampled particle data\n",
    "sim_sample <- dest_sampled[, .SD[sample(.N, DestNOffsAnnual, prob=SurvWeight)], by = c(\"Year\", \"Dest\")] #randomly sample rows (particles) from the table according to the survival weighting, based on the number we sampled at each site in each year of surveys\n",
    "\n",
    "PropUnassignedByYear <- (sim_sample[Source == \"CAI\"| Source == \"Other\", .(.N), by=\"Year\"][, N]/#total particales sampled from other/CAI sources\n",
    "sim_sample[, .(.N), by=\"Year\"][, N]) #total particles sampled\n",
    "\n",
    "PropSampOtherCAI_int$TimeScale[1] <- \"annual\"\n",
    "PropSampOtherCAI_int$TimeID[1] <- \"2012\"\n",
    "PropSampOtherCAI_int$PropUnassigned[1] <- PropUnassignedByYear[1]\n",
    "PropSampOtherCAI_int$ExpUnassigned[1] <- 1-(ExpectedPropAssigned[1, ExpAssigned])\n",
    "PropSampOtherCAI_int$PropSampEval[1] <- PropToEval[i]\n",
    "PropSampOtherCAI_int$Check1[1] <- test1\n",
    "PropSampOtherCAI_int$Check2[1] <- test2\n",
    "PropSampOtherCAI_int$NrowSimConn[1] <- nrow(dest_sampled)\n",
    "    \n",
    "PropSampOtherCAI_int$TimeScale[2] <- \"annual\"\n",
    "PropSampOtherCAI_int$TimeID[2] <- \"2013\"\n",
    "PropSampOtherCAI_int$PropUnassigned[2] <- PropUnassignedByYear[2]\n",
    "PropSampOtherCAI_int$ExpUnassigned[2] <- 1-(ExpectedPropAssigned[2, ExpAssigned])\n",
    "PropSampOtherCAI_int$PropSampEval[2] <- PropToEval[i]\n",
    "PropSampOtherCAI_int$Check1[2] <- test1\n",
    "PropSampOtherCAI_int$Check2[2] <- test2\n",
    "PropSampOtherCAI_int$NrowSimConn[2] <- nrow(dest_sampled)\n",
    "    \n",
    "PropSampOtherCAI_int$TimeScale[3] <- \"annual\"\n",
    "PropSampOtherCAI_int$TimeID[3] <- \"2014\"\n",
    "PropSampOtherCAI_int$PropUnassigned[3] <- PropUnassignedByYear[3]\n",
    "PropSampOtherCAI_int$ExpUnassigned[3] <- 1-(ExpectedPropAssigned[3, ExpAssigned])\n",
    "PropSampOtherCAI_int$PropSampEval[3] <- PropToEval[i]\n",
    "PropSampOtherCAI_int$Check1[3] <- test1\n",
    "PropSampOtherCAI_int$Check2[3] <- test2\n",
    "PropSampOtherCAI_int$NrowSimConn[3] <- nrow(dest_sampled)\n",
    "    \n",
    "PropSampOtherCAI_int$TimeScale[4] <- \"interannual\"\n",
    "PropSampOtherCAI_int$TimeID[4] <- \"2012_4\"\n",
    "PropSampOtherCAI_int$PropUnassigned[4] <- nrow(sim_sample[Source == \"CAI\"| Source == \"Other\"])/nrow(sim_sample)\n",
    "PropSampOtherCAI_int$ExpUnassigned[4] <- 1-(ExpectedPropAssigned[4, ExpAssigned])\n",
    "PropSampOtherCAI_int$PropSampEval[4] <- PropToEval[i]\n",
    "PropSampOtherCAI_int$Check1[4] <- test1\n",
    "PropSampOtherCAI_int$Check2[4] <- test2\n",
    "PropSampOtherCAI_int$NrowSimConn[4] <- nrow(dest_sampled)\n",
    "\n",
    "l <- list(PropSampOtherCAI, PropSampOtherCAI_int)\n",
    "PropSampOtherCAI <- rbindlist(l, use.names = TRUE, fill=TRUE, idcol = FALSE)\n",
    "setTxtProgressBar(pb, i)\n",
    "    \n",
    "}\n",
    "\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "\n",
    "fwrite(PropSampOtherCAI, file=\"~/oceanography/script_output/SimulationSummaryTables/PropSampOtherCAIEvaluation.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PropSampOtherCAI[order(-PropUnassigned)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Seems like good justification to not subsample the ROMS particles from other/Camotes Islands__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(dest_sampled)\n",
    "nrow(SimConn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#save inter file\n",
    "#fwrite(dest_sampled, file=\"~/oceanography/script_output/LongFormConnWithProbsTest.csv\")\n",
    "#see if I can write as a compressed file so it can be stored on github\n",
    "#https://stackoverflow.com/questions/42788401/is-possible-to-use-fwrite-from-data-table-with-gzfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
