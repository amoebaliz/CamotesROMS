{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "Packages <- c(\"dplyr\",\"broom\",\"cubature\", \"geosphere\", \"data.table\",  \"ggplot2\", \"bbmle\", \"dplyr\",\"tidyr\", \"stringr\", \"tidyverse\", \"lubridate\", \"RColorBrewer\")\n",
    "\n",
    "invisible(suppressPackageStartupMessages(lapply(Packages, library, character.only = TRUE)))\n",
    "\n",
    "setwd('/local/home/katrinac/oceanography')\n",
    "\"%!in%\" <- function(x,table) match(x,table, nomatch = 0) == 0\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/ll_kt_both_bbmle.R\")\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/GenGausKernInt_sum0.5.R\") #integrate_kernel_sum1\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/GenGausKernInt_sum1.R\") #integrate_kernel_sum0.5\n",
    "\n",
    "\n",
    "#clownfish metadata\n",
    "load(\"~/parentage/r_data/total_sampling_across_years.RData\")\n",
    "load(\"~/parentage/r_data/sampled_area_each_year.RData\")\n",
    "#https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Script_outputs/cumulative_prop_hab_sampled_by_site.RData)\n",
    "load(\"~/parentage/r_data/cumulative_prop_hab_sampled_by_site.RData\")\n",
    "#download.file(url = \"https://github.com/pinskylab/genomics/blob/master/data/fish-obs.RData?raw=true\", destfile = \"~/parentage/r_data/fish-obs.RData\")\n",
    "fish_obs <- readRDS(\"~/parentage/r_data/fish-obs.RData\") \n",
    "load(\"~/parentage/r_data/site_dist_info.RData\")\n",
    "#download.file(url = \"https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Data_from_database/anem_db.RData?raw=true\", destfile = \"~/parentage/r_data/anem_db.RData\")\n",
    "load(\"~/parentage/r_data/anem_db.RData\")\n",
    "#download.file(url = \"https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Data_from_database/dives_db.RData?raw=true\", destfile = \"~/parentage/r_data/dives_db.RData\")\n",
    "load(\"~/parentage/r_data/dives_db.RData\")\n",
    "#download.file(url = \"https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Data_from_database/fish_db.RData?raw=true\", destfile = \"~/parentage/r_data/dives_db.RData\")\n",
    "load(\"~/parentage/r_data/fish_db.RData\")\n",
    "load(\"~/parentage/r_data/gps_db.RData\")\n",
    "\n",
    "#stop dplyr's courtesy warnings about grouping variables and summarise()\n",
    "options(dplyr.summarise.inform=F) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnsampledSites <- c(\"SF1\", \"SF2\", \"SF3\", \"SF4\", \"SF5\", \"SF6\", \"Pangasugan\", \"CAI\", \"Other\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in the df where each particle is an observation\n",
    "#Simulation2012 <- fread(file=\"~/oceanography/script_output/SimConnLongForm2012YearSampled.csv\", showProgress = T)\n",
    "Simulation2013 <- fread(file=\"~/oceanography/script_output/SimConnLongForm2013YearSampled.csv\", showProgress = T)\n",
    "Simulation2014 <- fread(file=\"~/oceanography/script_output/SimConnLongForm2014YearSampled.csv\", showProgress = T)\n",
    "\n",
    "#this is about 3 GB so fread is fastest, but consider these options for dealing with a large csv\n",
    "#https://inbo.github.io/tutorials/tutorials/r_large_data_files_handling/\n",
    "\n",
    "#head(Simulation2012 %>% group_by(date, source, destination) %>% summarise(Check=n()))\n",
    "#CAI should be 201718, it is, all good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read in the centroids adjusted for the simulation, so the Magbangons combined \n",
    "centroids <- read.csv(file=\"~/oceanography/script_output/SurveyData/SimulationCentroids.csv\", header=T, stringsAsFactors = F)\n",
    "#read in the distance matrix adjusted for the simulation\n",
    "distances <- read.csv(file=\"~/oceanography/script_output/SurveyData/SimulationAllDistances.csv\", header=T, stringsAsFactors = F)\n",
    "\n",
    "\n",
    "#proportion sampled\n",
    "#add how well we sampled sites- proportion of habitat sampled\n",
    "load(\"~/parentage/r_data/cumulative_prop_hab_sampled_by_site.RData\")\n",
    "PropSamp <- cumulative_prop_hab_sampled_by_site %>%\n",
    "    mutate(total_possible_sample_anems = ifelse(site==\"Caridad Proper\", 4, total_possible_sample_anems) ) %>%\n",
    "    mutate(total_prop_hab_sampled_anems_tidied= ifelse(site==\"Caridad Proper\" & total_anems_sampled==4, 1, total_prop_hab_sampled_anems_tidied) ) %>%\n",
    "    mutate(total_possible_sample_anems = ifelse(site==\"Sitio Lonas\", total_anems_sampled, total_possible_sample_anems) ) %>%\n",
    "    mutate(total_prop_hab_sampled_anems_tidied= ifelse(site==\"Sitio Lonas\", 1, total_prop_hab_sampled_anems_tidied) )%>%\n",
    "    mutate(total_prop_hab_sampled_anems_tidied= ifelse(is.nan(total_prop_hab_sampled_anems_tidied), 0, total_prop_hab_sampled_anems_tidied) ) %>%\n",
    "    dplyr::select(site, time_frame, end_year, total_prop_hab_sampled_anems_tidied) \n",
    "\n",
    "PropSamp$site <- gsub(\". \", \".\", PropSamp$site, fixed=TRUE) #fix spaces in Magbangon names\n",
    "\n",
    "S.Mag <- PropSamp %>%#make a table for all of the S. Mabangon years/prop sampled. Then join to the DF, make a column adding S.Magbangon values to all rows of prop sampled, but only sub that value in for PropSamp in N.Magbangon rows, then rename N.Magbangon as Magbangon\n",
    "    filter(site==\"S.Magbangon\") %>%\n",
    "    dplyr::select(site, end_year, total_prop_hab_sampled_anems_tidied) %>%\n",
    "    rename(S.MagVal=\"total_prop_hab_sampled_anems_tidied\", extra=\"site\")\n",
    "\n",
    "PropSamp <- left_join(PropSamp, S.Mag, by=c(\"end_year\")) %>%\n",
    "    mutate(S.MagSum=total_prop_hab_sampled_anems_tidied+S.MagVal) %>% #create col adding the S.Mag values to prop hab - keep in mind values could be greater than 1- if so change them to 1\n",
    "    mutate(total_prop_hab_sampled_anems_tidied= ifelse(site==\"N.Magbangon\", S.MagSum, total_prop_hab_sampled_anems_tidied)) %>%#sub this value in for only N.Mag\n",
    "    mutate(site=ifelse(site==\"N.Magbangon\", \"Magbangon\", site)) %>%#change N.Mag name to generic Mag\n",
    "    filter(site !=\"S.Magbangon\") %>%#eliminate the S.Mag rows, they are now repeats\n",
    "    dplyr::select(-S.MagVal,-extra, -S.MagSum, -time_frame) %>%\n",
    "    rename(PropSamp=\"total_prop_hab_sampled_anems_tidied\")\n",
    "\n",
    "\n",
    "#check if there are values>1, should be none\n",
    "sum(which(PropSamp$total_prop_hab_sampled_anems_tidied >1)) #zero, that's good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "791"
      ],
      "text/latex": [
       "791"
      ],
      "text/markdown": [
       "791"
      ],
      "text/plain": [
       "[1] 791"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load data from the genetic sampling in each year\n",
    "#read in the kernel fitting summary\n",
    "kernels <- read.csv(file=\"~/parentage/kernel_fitting/1340_loci/final_results/tables/kernel_fitting_summary.csv\", header=T, stringsAsFactors = F)\n",
    "\n",
    "##read in the sites that we sampled each year\n",
    "N_gen_par <- read.table(file=\"~/parentage/colony2/20190523_1340loci/input/all_parents_corrected.txt\", header = TRUE, stringsAsFactors = F) %>%#not sure that I need the parents here\n",
    "    mutate(fish_indiv=as.character(fish_indiv))\n",
    "N_gen_offs <- read.table(file=\"~/parentage/colony2/20190523_1340loci/input/all_offspring_corrected.txt\", header=T, stringsAsFactors = F) %>%\n",
    "    mutate(fish_indiv=as.character(fish_indiv))\n",
    "\n",
    "\n",
    "\n",
    "#gather the summary of total offspring sampled\n",
    "#from Allison, putting all the meta data together (Constants_database_common_functions.R)\n",
    "##### Match up other relevant info (site, date, fish_indiv, etc.) to fish in the clownfish table\n",
    "# Pull out year and month into a separate column in dives_db\n",
    "dives_db_processed <- dives_db %>%\n",
    "  mutate(year = as.integer(substring(date,1,4))) %>%\n",
    "  mutate(month = as.integer(substring(date,6,7))) %>%\n",
    "  mutate(dive_date = date(date))\n",
    "\n",
    "# Pull all APCL caught or otherwise in the clownfish table\n",
    "allfish_fish <- fish_db %>%\n",
    "  select(fish_table_id, anem_table_id, fish_spp, sample_id, anem_table_id, recap, tag_id, color, sex, size, fish_obs_time, fish_notes) %>%\n",
    "  filter(fish_spp == 'APCL') %>%\n",
    "  mutate(size = as.numeric(size))  # make the size numeric (rather than chr) so can do means and such\n",
    "\n",
    "# and their corresponding anemones\n",
    "allfish_anems <- anem_db %>%\n",
    "  select(anem_table_id, dive_table_id, anem_obs, anem_id, old_anem_id, anem_notes) %>%\n",
    "  filter(anem_table_id %in% allfish_fish$anem_table_id)\n",
    "\n",
    "# and the corresponding dive info\n",
    "allfish_dives <- dives_db_processed %>%\n",
    "  select(dive_table_id, dive_type, date, year, month, site, gps, dive_notes) %>%\n",
    "  filter(dive_table_id %in% allfish_anems$dive_table_id) \n",
    "\n",
    "# join together\n",
    "allfish_caught <- left_join(allfish_fish, allfish_anems, by=\"anem_table_id\")\n",
    "allfish_caught <- left_join(allfish_caught, allfish_dives, by=\"dive_table_id\")\n",
    "\n",
    "# add in the gen_ids and fish_indiv (now in a separate gen_id table) - gen_id only comes in the time the fish was sequenced, not at all captures\n",
    "allfish_caught <- left_join(allfish_caught, (fish_obs %>% select(fish_table_id, gen_id, fish_indiv)), by = \"fish_table_id\") %>%\n",
    "    select(fish_indiv, sample_id, site) %>%\n",
    "    mutate()\n",
    "\n",
    "N_gen_offs_annual  <- left_join(N_gen_offs, allfish_caught, by=c(\"fish_indiv\", \"sample_id\")) %>% \n",
    "    group_by(year, site) %>%\n",
    "    summarise(n_offs_gen=n()) %>%\n",
    "    ungroup()\n",
    "\n",
    "N_gen_offs_annual$site <- gsub(\". \", \".\", N_gen_offs_annual$site, fixed=TRUE)\n",
    "\n",
    "##for all years\n",
    "NGenOffsAll <- N_gen_offs_annual %>% \n",
    "    group_by(site) %>% \n",
    "    summarise(n_offs_gen=sum(n_offs_gen, na.rm=T))\n",
    "\n",
    "sum(NGenOffsAll$n_offs_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "791"
      ],
      "text/latex": [
       "791"
      ],
      "text/markdown": [
       "791"
      ],
      "text/plain": [
       "[1] 791"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#combine N/S Magbangon in the genetic sampling data\n",
    "\n",
    "AnnualRecsSamp <- bind_rows(N_gen_offs_annual %>%\n",
    "                        filter(site !=\"N.Magbangon\" & site!=\"S.Magbangon\"),\n",
    "                    N_gen_offs_annual %>%\n",
    "                        mutate(Magbangon=ifelse(site==\"N.Magbangon\" | site==\"S.Magbangon\", \"Magbangon\", \"no\")) %>%\n",
    "                        filter(Magbangon==\"Magbangon\") %>%\n",
    "                        group_by(year, Magbangon) %>%\n",
    "                        summarise(sum_offs=sum(n_offs_gen)) %>%\n",
    "                        rename(site=\"Magbangon\", n_offs_gen=\"sum_offs\")) %>%\n",
    "                        mutate(year=as.character(year)) %>%\n",
    "                        ungroup()\n",
    "sum(AnnualRecsSamp$n_offs_gen) #should be 791\n",
    "\n",
    "#add in ALL sites that we sampled, even though we didn't find recruits there\n",
    "AnnualRecsSamp <- left_join(PropSamp %>%  #add in all sampled sites as possible offs sites\n",
    "                            filter(PropSamp > 0),\n",
    "                          AnnualRecsSamp, \n",
    "                              by=c(\"site\", end_year=\"year\")) %>%\n",
    "                        rename(year=\"end_year\")  %>%\n",
    "                        mutate(n_offs_gen=ifelse(is.na(n_offs_gen), 0, n_offs_gen)) %>%#if we didn't sample a recruit at a site that we still visited, put a 0 in place of the NA\n",
    "                        filter(year %in% c(\"2012\", \"2013\", \"2014\")) %>%  #* restrict to what we can pick up combining all years of simulation data\n",
    "                        group_by(site) %>% #*\n",
    "                        mutate(n_offs_gen_all_years=sum(n_offs_gen)) #*\n",
    "###STARTING HERE*** post- 03/15/2021, COMBINE MAGBANGON FOR ALL YEARS TOO? I start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Narrow down data to the year of interests__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "181"
      ],
      "text/latex": [
       "181"
      ],
      "text/markdown": [
       "181"
      ],
      "text/plain": [
       "[1] 181"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "13"
      ],
      "text/latex": [
       "13"
      ],
      "text/markdown": [
       "13"
      ],
      "text/plain": [
       "[1] 13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sample the simulation results according to how many offspring we sampled at that site in real life, each row is a column\n",
    "NGenOffs2014 <- AnnualRecsSamp %>%\n",
    "    filter(year==\"2014\")\n",
    "\n",
    "nrow(NGenOffs2014) #should be 9 sites sampled for 2014\n",
    "\n",
    "#make an empty dataframe with the same columns as original, this will be sampled particles\n",
    "SimulatedSampling2014 = Simulation2014[FALSE,]\n",
    "\n",
    "for(i in 1:nrow(NGenOffs2014)){ \n",
    "    \n",
    "    destination_eval <- as.character(NGenOffs2014$site[i]) #pick out a destination site\n",
    "    \n",
    "    SimSampDestination <- Simulation2014 %>%\n",
    "                                filter(destination==destination_eval) %>%\n",
    "                                sample_n(as.numeric(NGenOffs2014$n_offs_gen[i]), replace=F) #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "    \n",
    "    SimulatedSampling2014 <- bind_rows(SimulatedSampling2014, SimSampDestination) #build into a sampled particle df\n",
    "}\n",
    "\n",
    "#assign a numeric ID for each row (which is a sampled particle)\n",
    "SimulatedSampling2014 <- SimulatedSampling2014 %>%\n",
    "    mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "\n",
    "nrow(SimulatedSampling2014)==sum(NGenOffs2014$n_offs_gen) #should be TRUE\n",
    "\n",
    "#now randomly assign parentage match status to some of these rows\n",
    "NumPar <- as.numeric(kernels %>%\n",
    "    filter(Year==\"2014\") %>%\n",
    "    select(NumParentageMatches))\n",
    "\n",
    "SimulatedSampling2014Par <- SimulatedSampling2014 %>%\n",
    "    ungroup() %>%\n",
    "    filter(source %in% NGenOffs2014$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "    sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "    mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "    #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "    #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "\n",
    "#find the rows that haven't been assigned parentage\n",
    "SimulatedSampling2014_2 <- anti_join((SimulatedSampling2014 %>% ungroup()), SimulatedSampling2014Par, by=c(\"ParticleSampID\")) \n",
    "\n",
    "SimulatedSampling2014_2$Parentage <- 0 #add in the column for parentage\n",
    "\n",
    "#combine parentage and non-parentage dfs\n",
    "SimulatedSampling2014Par3 <- bind_rows(SimulatedSampling2014Par, SimulatedSampling2014_2) %>%\n",
    "    mutate(YearSampled=as.character(YearSampled))\n",
    "\n",
    "nrow(SimulatedSampling2014Par3) #for 2014 it should be 63, and it is yay\n",
    "nrow(SimulatedSampling2014Par3 %>% filter(Parentage==1)) #for 2014 should be 3, and it is yay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct carry over of sampled particles in TotalSimSamp\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct carry over of sampled particles in TotalSimSamp2\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of parentage matches in TotalSimPar\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of destination sites, corresponding to number of surveyed sites in SimSampSummary2014, which is used for unassigned row\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of destination sites, corresponding to number of surveyed sites in TotalSimPar2, which will be spread into parentage matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of parentage matches in TotalSimPar2, which will be spread into parentage matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of source sites in final matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of destination sites in final matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of parentage matches in final matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "13"
      ],
      "text/latex": [
       "13"
      ],
      "text/markdown": [
       "13"
      ],
      "text/plain": [
       "[1] 13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of unassigned recruits in final matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "168"
      ],
      "text/latex": [
       "168"
      ],
      "text/markdown": [
       "168"
      ],
      "text/plain": [
       "[1] 168"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"dimensions of simulated and empirical parentage matrix are the same\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] TRUE TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PropSamp2014 <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "                #rename(source=\"site\") %>%\n",
    "                select(-end_year, -PropSamp)\n",
    "\n",
    "#PropSamp2014$destination <- PropSamp2014$source #make another column for destination\n",
    "\n",
    "#make a table with the total number of particles sampled at each site\n",
    "TotalSimSamp <- SimulatedSampling2014Par3 %>% \n",
    "            select(source, destination) %>%\n",
    "            group_by(destination) %>%\n",
    "            summarise(NumSimSampRec=n()) %>%\n",
    "            ungroup()\n",
    "print(\"correct carry over of sampled particles in TotalSimSamp\")\n",
    "sum(TotalSimSamp$NumSimSampRec)==sum(NGenOffs2014$n_offs_gen) #should be true\n",
    "\n",
    "#add in all surveyed sites\n",
    "TotalSimSamp2 <- left_join(PropSamp2014, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "    rename(destination=\"site\")#rename sites to destination after joining\n",
    "\n",
    "print(\"correct carry over of sampled particles in TotalSimSamp2\")\n",
    "sum(TotalSimSamp$NumSimSampRec)==sum(TotalSimSamp2$NumSimSampRec) #should be TRUE\n",
    "\n",
    "#make a table with the total number of parentage matches found in the simulated loop\n",
    "TotalSimPar <- SimulatedSampling2014Par3 %>% \n",
    "            select(source, destination, Parentage) %>%\n",
    "            group_by(source,destination) %>%\n",
    "            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "            select(-Parentage) %>%\n",
    "            ungroup() %>%\n",
    "            distinct(source, destination, .keep_all = T)\n",
    "\n",
    "print(\"correct number of parentage matches in TotalSimPar\")\n",
    "sum(TotalSimPar$NumPar)==NumPar #should be TRUE\n",
    "\n",
    "#combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "SimSampSummary2014 <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "    distinct(source, destination, .keep_all = T) %>%\n",
    "    group_by(destination) %>%\n",
    "    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "    distinct(destination, .keep_all = T) %>%\n",
    "    select(-source) %>%\n",
    "    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "\n",
    "print(\"correct number of destination sites, corresponding to number of surveyed sites in SimSampSummary2014, which is used for unassigned row\")\n",
    "nrow(SimSampSummary2014 %>% distinct(destination, .keep_all = T))==nrow(PropSamp2014) #should be TRUE, 9 possible destinations for 2014\n",
    "\n",
    "\n",
    "#finally, join all of the sites surveyed for a complete parentage matrix\n",
    "#for this, need to have a source/destination column for all sites\n",
    "PropSamp2014 <- PropSamp2014 %>%\n",
    "                rename(source=\"site\")\n",
    "\n",
    "PropSamp2014$destination <- PropSamp2014$source #make another column for destination\n",
    "\n",
    "#this below will become parentage matrix! \n",
    "TotalSimPar2 <- full_join(TotalSimPar,PropSamp2014, by=c(\"source\", \"destination\")) %>%\n",
    "    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "\n",
    "print(\"correct number of destination sites, corresponding to number of surveyed sites in TotalSimPar2, which will be spread into parentage matrix\")\n",
    "nrow(TotalSimPar2 %>% distinct(destination, .keep_all = T))==nrow(PropSamp2014) #should be TRUE, 9 possible destinations for 2014\n",
    "\n",
    "#check that the number of matches is still correct\n",
    "print(\"correct number of parentage matches in TotalSimPar2, which will be spread into parentage matrix\")\n",
    "sum(TotalSimPar2$NumPar)==NumPar\n",
    "\n",
    "#spread into matrix format\n",
    "SimDispMat <- TotalSimPar2 %>%\n",
    "    filter(source %in% NGenOffs2014$site) %>%\n",
    "    arrange(source, destination)  %>%\n",
    "    spread(destination, NumPar) %>%\n",
    "    select(-source)\n",
    "SimDispMat[is.na(SimDispMat)] <- 0\n",
    "\n",
    "#add in unassigned row\n",
    "unassigned <- t(as.matrix(SimSampSummary2014 %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "rownames(unassigned)<-NULL\n",
    "colnames(unassigned)<-names(SimDispMat)\n",
    "\n",
    "SimDispMatFull2014 <- rbind(SimDispMat, unassigned)\n",
    "colnames(SimDispMatFull2014) <- NULL\n",
    "\n",
    "#error check final matrix \n",
    "print(\"correct number of source sites in final matrix\")\n",
    "nrow(SimDispMatFull2014)==nrow(PropSamp2014)+1\n",
    "\n",
    "print(\"correct number of destination sites in final matrix\")\n",
    "ncol(SimDispMatFull2014)==nrow(PropSamp2014)\n",
    "\n",
    "print(\"correct number of parentage matches in final matrix\")\n",
    "sum(SimDispMatFull2014[1:nrow(PropSamp2014),])==NumPar\n",
    "NumPar\n",
    "\n",
    "print(\"correct number of unassigned recruits in final matrix\")\n",
    "sum(SimDispMatFull2014[nrow(PropSamp2014)+1,])==sum(NGenOffs2014$n_offs_gen)-NumPar\n",
    "sum(NGenOffs2014$n_offs_gen)-NumPar\n",
    "\n",
    "#finally- make sure dimensions of simulated parentage matrix match that of the genetic kernel fits. we should be totally replicating the genetic kernel fitting here\n",
    "#EXCEPT! Remember that in the genetic data Magbangon was separated into two sites, but in the simulated data it's not\n",
    "EmpiricalAssignments <- read.csv(\"~/parentage/kernel_fitting/1340_loci/input/parentage_matrix13_corrected.csv\", header=F)\n",
    "\n",
    "print(\"dimensions of simulated and empirical parentage matrix are the same\")\n",
    "(dim(EmpiricalAssignments)-1)==dim(SimDispMatFull2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "34"
      ],
      "text/latex": [
       "34"
      ],
      "text/markdown": [
       "34"
      ],
      "text/plain": [
       "[1] 34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#assemble all of the components for annual kernel fitting\n",
    "centroids <- read.csv(\"~/oceanography/empirical_data/site_centroids_simulation_kernels.csv\", header=TRUE)\n",
    "\n",
    "Area <- read.csv(\"~/oceanography/empirical_data/site_area_header_nonsurveyed_simulation_kernels.csv\", header=TRUE) %>%\n",
    "    arrange(site) %>%\n",
    "    filter(site %!in% c(\"near_north_full1\", \"near_north_full2\", \"near_north_full3\", \"near_south_full1\", \"near_south_full2\", \"near_south_full3\")) %>%\n",
    "    mutate(kmsq=msq*10^-6) %>%\n",
    "    select(kmsq)\n",
    "Reef_sizes <- as.matrix(Area)\n",
    "\n",
    "#give every site in the distance matrix of the simulation (even if we didn't sample there) an index number\n",
    "AllSites <- centroids %>%\n",
    "    select(site) %>%\n",
    "    arrange(site)\n",
    "nrow(AllSites) #should be 34x1\n",
    "AllSites$index <- seq(from=1, to=34, by=1)\n",
    "\n",
    "SampledSites2014 <- inner_join(PropSamp2014 %>% select(source), AllSites, by=c(source=\"site\")) \n",
    "\n",
    "#check for correct number of rows\n",
    "nrow(SampledSites2014)==nrow(PropSamp2014) #should be true\n",
    "SampledSites2014Index <- t(as.matrix(SampledSites2014$index))\n",
    "ncol(SampledSites2014Index)\n",
    "\n",
    "Sampled_reefs <- SampledSites2014Index\n",
    "\n",
    "#proportion sampled matrix for kernel fitting\n",
    "Adult_sample_proportions <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                filter(end_year ==\"2014\" & PropSamp > 0) \n",
    "\n",
    "Adult_sample_proportions <- as.matrix(Adult_sample_proportions$PropSamp)\n",
    "nrow(Adult_sample_proportions) #should be 9 for 2014\n",
    "\n",
    "#distance matrix using the centroids with combined Magbangon\n",
    "### List of source locations\n",
    "sites_source <- centroids\n",
    "\n",
    "### List of destination locations\n",
    "sites_dest <- centroids\n",
    "\n",
    "dist_mat_m <- distm(sites_source[,c('lon','lat')], sites_source[,c('lon','lat')], fun=distVincentyEllipsoid)\n",
    "Distances <- dist_mat_m*10^-3\n",
    "\n",
    "Centroids <- centroids %>%\n",
    "    select(-site)\n",
    "\n",
    "Assignments <- SimDispMatFull2014\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "mle2(minuslogl = LL_kt_bbmle, start = list(k = -3, theta = 1), \n",
       "    method = \"L-BFGS-B\", data = x, lower = c(-10, 0.15), upper = c(10, \n",
       "        8), control = list(maxit = 500))\n",
       "\n",
       "Coefficients:\n",
       "      k   theta \n",
       "-3.3292  8.0000 \n",
       "\n",
       "Log-likelihood: -91.65 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a=-10\n",
    "b=10\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "Sim2014Fit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "Sim2014Fit\n",
    "\n",
    "BestK2014 <- as.numeric(coef(Sim2014Fit)[1])\n",
    "BestTheta2014 <- as.numeric(coef(Sim2014Fit)[2])\n",
    "\n",
    "SimMDD2014 <- cubintegrate(integrate_kernel_sum1, lower = 0, upper = Inf, k=BestK2014, theta=BestTheta2014, , method = \"pcubature\")$integral\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "9.96323319428805"
      ],
      "text/latex": [
       "9.96323319428805"
      ],
      "text/markdown": [
       "9.96323319428805"
      ],
      "text/plain": [
       "[1] 9.963233"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Year</th><th scope=col>best_k</th><th scope=col>best_theta</th><th scope=col>k_CI95_lower</th><th scope=col>k_CI95_upper</th><th scope=col>theta_CI95_lower</th><th scope=col>theta_CI95_upper</th><th scope=col>MeanDispDist</th><th scope=col>MeanDispDist_CI95_lower</th><th scope=col>MeanDispDist_CI95_upper</th><th scope=col>NumParentageMatches</th><th scope=col>NumOffsSampled</th><th scope=col>PercentAssigned</th><th scope=col>MedianDispDist</th><th scope=col>Dist90Retained</th><th scope=col>MedianDispDist_CI95_lower</th><th scope=col>MedianDispDist_CI95_upper</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2012        </td><td>-2.36       </td><td>1.03        </td><td>-7.22       </td><td>-1.90       </td><td>0.48        </td><td>1.10        </td><td>10.165094   </td><td>0.000000    </td><td>1.367946e+26</td><td> 3          </td><td> 63         </td><td> 4.76       </td><td> 7.13       </td><td> 23.29      </td><td>3.19        </td><td>1.530115e+13</td></tr>\n",
       "\t<tr><td>2013        </td><td> 4.04       </td><td>0.22        </td><td> 3.59       </td><td> 4.06       </td><td>0.20        </td><td>0.24        </td><td>69.586280   </td><td>7.978681    </td><td>1.233879e+05</td><td>21          </td><td>150         </td><td>14.00       </td><td>12.20       </td><td>157.36      </td><td>2.57        </td><td>2.061640e+03</td></tr>\n",
       "\t<tr><td>2014        </td><td> 0.49       </td><td>0.38        </td><td>-0.26       </td><td> 0.81       </td><td>0.37        </td><td>0.40        </td><td>15.037515   </td><td>5.646667    </td><td>2.204186e+05</td><td>13          </td><td>181         </td><td> 7.18       </td><td> 5.53       </td><td> 38.13      </td><td>3.02        </td><td>2.984700e+03</td></tr>\n",
       "\t<tr><td>2015        </td><td>-1.52       </td><td>0.67        </td><td>-2.08       </td><td>-1.13       </td><td>0.56        </td><td>0.70        </td><td>10.180222   </td><td>6.149556    </td><td>2.404633e+02</td><td>11          </td><td>111         </td><td> 9.91       </td><td> 5.82       </td><td> 24.91      </td><td>2.31        </td><td>1.118000e+01</td></tr>\n",
       "\t<tr><td>2016        </td><td>-3.04       </td><td>5.00        </td><td>-3.07       </td><td>-2.88       </td><td>2.16        </td><td>5.00        </td><td>10.100794   </td><td>7.600055    </td><td>1.311733e+01</td><td> 6          </td><td>111         </td><td> 5.41       </td><td> 9.63       </td><td> 18.91      </td><td>5.85        </td><td>4.458000e+01</td></tr>\n",
       "\t<tr><td>2017        </td><td> 2.94       </td><td>0.26        </td><td> 2.66       </td><td> 3.64       </td><td>0.23        </td><td>0.26        </td><td>29.062101   </td><td>5.920487    </td><td>1.172967e+04</td><td>13          </td><td>130         </td><td>10.00       </td><td> 6.68       </td><td> 69.72      </td><td>3.03        </td><td>5.452225e+05</td></tr>\n",
       "\t<tr><td>2018        </td><td>-2.32       </td><td>1.37        </td><td>-2.93       </td><td>-2.15       </td><td>1.36        </td><td>1.61        </td><td> 7.191634   </td><td>4.507346    </td><td>5.079209e+01</td><td> 4          </td><td> 45         </td><td> 8.89       </td><td> 5.55       </td><td> 15.72      </td><td>2.58        </td><td>1.276000e+01</td></tr>\n",
       "\t<tr><td>2012-18     </td><td>-2.51       </td><td>1.49        </td><td>-2.51       </td><td>-2.48       </td><td>1.32        </td><td>1.60        </td><td> 8.153016   </td><td>7.132250    </td><td>9.403629e+00</td><td>71          </td><td>791         </td><td> 8.98       </td><td> 6.44       </td><td> 17.58      </td><td>4.94        </td><td>8.130000e+00</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllll}\n",
       " Year & best\\_k & best\\_theta & k\\_CI95\\_lower & k\\_CI95\\_upper & theta\\_CI95\\_lower & theta\\_CI95\\_upper & MeanDispDist & MeanDispDist\\_CI95\\_lower & MeanDispDist\\_CI95\\_upper & NumParentageMatches & NumOffsSampled & PercentAssigned & MedianDispDist & Dist90Retained & MedianDispDist\\_CI95\\_lower & MedianDispDist\\_CI95\\_upper\\\\\n",
       "\\hline\n",
       "\t 2012         & -2.36        & 1.03         & -7.22        & -1.90        & 0.48         & 1.10         & 10.165094    & 0.000000     & 1.367946e+26 &  3           &  63          &  4.76        &  7.13        &  23.29       & 3.19         & 1.530115e+13\\\\\n",
       "\t 2013         &  4.04        & 0.22         &  3.59        &  4.06        & 0.20         & 0.24         & 69.586280    & 7.978681     & 1.233879e+05 & 21           & 150          & 14.00        & 12.20        & 157.36       & 2.57         & 2.061640e+03\\\\\n",
       "\t 2014         &  0.49        & 0.38         & -0.26        &  0.81        & 0.37         & 0.40         & 15.037515    & 5.646667     & 2.204186e+05 & 13           & 181          &  7.18        &  5.53        &  38.13       & 3.02         & 2.984700e+03\\\\\n",
       "\t 2015         & -1.52        & 0.67         & -2.08        & -1.13        & 0.56         & 0.70         & 10.180222    & 6.149556     & 2.404633e+02 & 11           & 111          &  9.91        &  5.82        &  24.91       & 2.31         & 1.118000e+01\\\\\n",
       "\t 2016         & -3.04        & 5.00         & -3.07        & -2.88        & 2.16         & 5.00         & 10.100794    & 7.600055     & 1.311733e+01 &  6           & 111          &  5.41        &  9.63        &  18.91       & 5.85         & 4.458000e+01\\\\\n",
       "\t 2017         &  2.94        & 0.26         &  2.66        &  3.64        & 0.23         & 0.26         & 29.062101    & 5.920487     & 1.172967e+04 & 13           & 130          & 10.00        &  6.68        &  69.72       & 3.03         & 5.452225e+05\\\\\n",
       "\t 2018         & -2.32        & 1.37         & -2.93        & -2.15        & 1.36         & 1.61         &  7.191634    & 4.507346     & 5.079209e+01 &  4           &  45          &  8.89        &  5.55        &  15.72       & 2.58         & 1.276000e+01\\\\\n",
       "\t 2012-18      & -2.51        & 1.49         & -2.51        & -2.48        & 1.32         & 1.60         &  8.153016    & 7.132250     & 9.403629e+00 & 71           & 791          &  8.98        &  6.44        &  17.58       & 4.94         & 8.130000e+00\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Year | best_k | best_theta | k_CI95_lower | k_CI95_upper | theta_CI95_lower | theta_CI95_upper | MeanDispDist | MeanDispDist_CI95_lower | MeanDispDist_CI95_upper | NumParentageMatches | NumOffsSampled | PercentAssigned | MedianDispDist | Dist90Retained | MedianDispDist_CI95_lower | MedianDispDist_CI95_upper |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 2012         | -2.36        | 1.03         | -7.22        | -1.90        | 0.48         | 1.10         | 10.165094    | 0.000000     | 1.367946e+26 |  3           |  63          |  4.76        |  7.13        |  23.29       | 3.19         | 1.530115e+13 |\n",
       "| 2013         |  4.04        | 0.22         |  3.59        |  4.06        | 0.20         | 0.24         | 69.586280    | 7.978681     | 1.233879e+05 | 21           | 150          | 14.00        | 12.20        | 157.36       | 2.57         | 2.061640e+03 |\n",
       "| 2014         |  0.49        | 0.38         | -0.26        |  0.81        | 0.37         | 0.40         | 15.037515    | 5.646667     | 2.204186e+05 | 13           | 181          |  7.18        |  5.53        |  38.13       | 3.02         | 2.984700e+03 |\n",
       "| 2015         | -1.52        | 0.67         | -2.08        | -1.13        | 0.56         | 0.70         | 10.180222    | 6.149556     | 2.404633e+02 | 11           | 111          |  9.91        |  5.82        |  24.91       | 2.31         | 1.118000e+01 |\n",
       "| 2016         | -3.04        | 5.00         | -3.07        | -2.88        | 2.16         | 5.00         | 10.100794    | 7.600055     | 1.311733e+01 |  6           | 111          |  5.41        |  9.63        |  18.91       | 5.85         | 4.458000e+01 |\n",
       "| 2017         |  2.94        | 0.26         |  2.66        |  3.64        | 0.23         | 0.26         | 29.062101    | 5.920487     | 1.172967e+04 | 13           | 130          | 10.00        |  6.68        |  69.72       | 3.03         | 5.452225e+05 |\n",
       "| 2018         | -2.32        | 1.37         | -2.93        | -2.15        | 1.36         | 1.61         |  7.191634    | 4.507346     | 5.079209e+01 |  4           |  45          |  8.89        |  5.55        |  15.72       | 2.58         | 1.276000e+01 |\n",
       "| 2012-18      | -2.51        | 1.49         | -2.51        | -2.48        | 1.32         | 1.60         |  8.153016    | 7.132250     | 9.403629e+00 | 71           | 791          |  8.98        |  6.44        |  17.58       | 4.94         | 8.130000e+00 |\n",
       "\n"
      ],
      "text/plain": [
       "  Year    best_k best_theta k_CI95_lower k_CI95_upper theta_CI95_lower\n",
       "1 2012    -2.36  1.03       -7.22        -1.90        0.48            \n",
       "2 2013     4.04  0.22        3.59         4.06        0.20            \n",
       "3 2014     0.49  0.38       -0.26         0.81        0.37            \n",
       "4 2015    -1.52  0.67       -2.08        -1.13        0.56            \n",
       "5 2016    -3.04  5.00       -3.07        -2.88        2.16            \n",
       "6 2017     2.94  0.26        2.66         3.64        0.23            \n",
       "7 2018    -2.32  1.37       -2.93        -2.15        1.36            \n",
       "8 2012-18 -2.51  1.49       -2.51        -2.48        1.32            \n",
       "  theta_CI95_upper MeanDispDist MeanDispDist_CI95_lower MeanDispDist_CI95_upper\n",
       "1 1.10             10.165094    0.000000                1.367946e+26           \n",
       "2 0.24             69.586280    7.978681                1.233879e+05           \n",
       "3 0.40             15.037515    5.646667                2.204186e+05           \n",
       "4 0.70             10.180222    6.149556                2.404633e+02           \n",
       "5 5.00             10.100794    7.600055                1.311733e+01           \n",
       "6 0.26             29.062101    5.920487                1.172967e+04           \n",
       "7 1.61              7.191634    4.507346                5.079209e+01           \n",
       "8 1.60              8.153016    7.132250                9.403629e+00           \n",
       "  NumParentageMatches NumOffsSampled PercentAssigned MedianDispDist\n",
       "1  3                   63             4.76            7.13         \n",
       "2 21                  150            14.00           12.20         \n",
       "3 13                  181             7.18            5.53         \n",
       "4 11                  111             9.91            5.82         \n",
       "5  6                  111             5.41            9.63         \n",
       "6 13                  130            10.00            6.68         \n",
       "7  4                   45             8.89            5.55         \n",
       "8 71                  791             8.98            6.44         \n",
       "  Dist90Retained MedianDispDist_CI95_lower MedianDispDist_CI95_upper\n",
       "1  23.29         3.19                      1.530115e+13             \n",
       "2 157.36         2.57                      2.061640e+03             \n",
       "3  38.13         3.02                      2.984700e+03             \n",
       "4  24.91         2.31                      1.118000e+01             \n",
       "5  18.91         5.85                      4.458000e+01             \n",
       "6  69.72         3.03                      5.452225e+05             \n",
       "7  15.72         2.58                      1.276000e+01             \n",
       "8  17.58         4.94                      8.130000e+00             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SimMDD2012\n",
    "kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 17.08725 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#awesome! it works! let's rip with a 100 iteration for loop\n",
    "col <- c(\"year\", \"k\", \"theta\", \"iteration\")\n",
    "SimulatedKernels2014 <- as.data.frame(matrix(nrow=0, ncol=4), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernels2014) <- col\n",
    "\n",
    "#don't print warnings for this loop, they are only for setting row names in a tibble which is depracated. But it works. \n",
    "options(warn=-1)\n",
    "\n",
    "pb <- txtProgressBar(min = 0, max = 100, style = 3)#7 years in each interation\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "#define the bounds to search over for the MLE\n",
    "a=-10\n",
    "b=10\n",
    "\n",
    "for(n in 1:100){\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    #make an empty dataframe with the same columns as original, this will be sampled particles\n",
    "    SimulatedSampling2014 = Simulation2014[FALSE,]\n",
    "    \n",
    "    for(i in 1:nrow(NGenOffs2014)){ \n",
    "        \n",
    "        destination_eval <- as.character(NGenOffs2014$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- Simulation2014 %>%\n",
    "                                    filter(destination==destination_eval) %>%\n",
    "                                    sample_n(as.numeric(NGenOffs2014$n_offs_gen[i]), replace=F) #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "        \n",
    "        SimulatedSampling2014 <- bind_rows(SimulatedSampling2014, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "    \n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSampling2014 <- SimulatedSampling2014 %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSampling2014)==sum(NGenOffs2014$n_offs_gen) #should be TRUE\n",
    "    \n",
    "    #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>%\n",
    "        filter(Year==\"2014\") %>%\n",
    "        select(NumParentageMatches))\n",
    "    \n",
    "    SimulatedSampling2014Par <- SimulatedSampling2014 %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% NGenOffs2014$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSampling2014_2 <- anti_join((SimulatedSampling2014 %>% ungroup()), SimulatedSampling2014Par, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSampling2014_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSampling2014Par3 <- bind_rows(SimulatedSampling2014Par, SimulatedSampling2014_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSamp2014 <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSamp2014$destination <- PropSamp2014$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSampling2014Par3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in all surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSamp2014, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSampling2014Par3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummary2014 <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finally, join all of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for all sites\n",
    "                PropSamp2014 <- PropSamp2014 %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSamp2014$destination <- PropSamp2014$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSamp2014, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% NGenOffs2014$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummary2014 %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFull2014 <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFull2014) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFull2014\n",
    "    \n",
    "    #NOW FIT THE KERNEL\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "Sim2014Fit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "\n",
    "BestK2014 <- as.numeric(coef(Sim2014Fit)[1])\n",
    "BestTheta2014 <- as.numeric(coef(Sim2014Fit)[2])\n",
    "\n",
    "    #store the info in this df\n",
    "    SimulatedKernels2014_beta <- as.data.frame(matrix(nrow=1, ncol=4), stringsAsFactors = FALSE)\n",
    "    colnames(SimulatedKernels2014_beta) <- col\n",
    "    \n",
    "    SimulatedKernels2014_beta$year <- 2014\n",
    "    SimulatedKernels2014_beta$k <- BestK2014\n",
    "    SimulatedKernels2014_beta$theta <- BestTheta2014\n",
    "    SimulatedKernels2014_beta$iteration <- n\n",
    "    \n",
    "    \n",
    "#join results into larger df\n",
    "SimulatedKernels2014 <- bind_rows(SimulatedKernels2014, SimulatedKernels2014_beta)\n",
    "    \n",
    "setTxtProgressBar(pb, n)\n",
    "\n",
    "\n",
    "}\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "options(warn=0) #turn warnings back on\n",
    "\n",
    "\n",
    "#write.csv(SimulatedKernels2014, file=\"~/oceanography/script_output/KernelFits/100SimulatedKernels2014.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine simulations\n",
    "SimulationAll <- bind_rows(Simulation2012, Simulation2013, Simulation2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 50.58508 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#All of the corresponding simulation years combined (2011-All)\n",
    "\n",
    "col <- c(\"year\", \"k\", \"theta\", \"iteration\")\n",
    "SimulatedKernelsAll <- as.data.frame(matrix(nrow=0, ncol=4), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernelsAll) <- col\n",
    "\n",
    "#don't print warnings for this loop, they are only for setting row names in a tibble which is depracated. But it works. \n",
    "options(warn=-1)\n",
    "\n",
    "pb <- txtProgressBar(min = 0, max = 100, style = 3)#7 years in each interation\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "#define the bounds to search over for the MLE\n",
    "a=-10\n",
    "b=10\n",
    "\n",
    "for(n in 1:100){\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    SimulatedSamplingAll = SimulationAll[FALSE,]\n",
    "    \n",
    "    for(i in 1:nrow(AllYearsRecruits)){ \n",
    "        \n",
    "        destination_eval <- as.character(AllYearsRecruits$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- SimulationAll %>%\n",
    "                                    filter(destination==destination_eval) %>%\n",
    "                                    sample_n(as.numeric(AllYearsRecruits$n_offs_gen_all_years[i]), replace=F) #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "        \n",
    "        SimulatedSamplingAll <- bind_rows(SimulatedSamplingAll, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "\n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSamplingAll <- SimulatedSamplingAll %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSamplingAll)==sum(NGenOffsAll$n_offs_gen) #should be TRUE\n",
    "    \n",
    "    #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>%\n",
    "        filter(Year==\"2012-18\") %>%\n",
    "        select(NumParentageMatches))\n",
    "    \n",
    "    SimulatedSamplingAllPar <- SimulatedSamplingAll %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% NGenOffsAll$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSamplingAll_2 <- anti_join((SimulatedSamplingAll %>% ungroup()), SimulatedSamplingAllPar, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSamplingAll_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSamplingAllPar3 <- bind_rows(SimulatedSamplingAllPar, SimulatedSamplingAll_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSampAll <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSampAll$destination <- PropSampAll$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSamplingAllPar3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in all surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSampAll, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSamplingAllPar3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummaryAll <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finally, join all of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for all sites\n",
    "                PropSampAll <- PropSampAll %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSampAll$destination <- PropSampAll$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSampAll, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% NGenOffsAll$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummaryAll %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFullAll <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFullAll) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFullAll\n",
    "    \n",
    "    #NOW FIT THE KERNEL\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "SimAllFit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "\n",
    "BestKAll <- as.numeric(coef(SimAllFit)[1])\n",
    "BestThetaAll <- as.numeric(coef(SimAllFit)[2])\n",
    "\n",
    "    #store the info in this df\n",
    "    SimulatedKernelsAll_beta <- as.data.frame(matrix(nrow=1, ncol=4), stringsAsFactors = FALSE)\n",
    "    colnames(SimulatedKernelsAll_beta) <- col\n",
    "    \n",
    "    SimulatedKernelsAll_beta$year <- NA\n",
    "    SimulatedKernelsAll_beta$k <- BestKAll\n",
    "    SimulatedKernelsAll_beta$theta <- BestThetaAll\n",
    "    SimulatedKernelsAll_beta$iteration <- n\n",
    "    \n",
    "    \n",
    "#join results into larger df\n",
    "SimulatedKernelsAll <- bind_rows(SimulatedKernelsAll, SimulatedKernelsAll_beta)\n",
    "    \n",
    "setTxtProgressBar(pb, n)\n",
    "\n",
    "\n",
    "}\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "options(warn=0) #turn warnings back on\n",
    "\n",
    "\n",
    "#write.csv(SimulatedKernelsAll, file=\"~/oceanography/script_output/KernelFits/100SimulatedKernelsAll.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "mle2(minuslogl = LL_kt_bbmle, start = list(k = -3, theta = 1), \n",
       "    method = \"L-BFGS-B\", data = x, lower = c(-10, 0.15), upper = c(10, \n",
       "        8), control = list(maxit = 500))\n",
       "\n",
       "Coefficients:\n",
       "         k      theta \n",
       "-1.6150404  0.8034533 \n",
       "\n",
       "Log-likelihood: -459.94 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SimAllFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimulatedKernels2012_beta <- as.data.frame(matrix(nrow=1, ncol=4), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernels2012_beta) <- col\n",
    "\n",
    "    SimulatedKernels2012_beta$year <- 2012\n",
    "    SimulatedKernels2012_beta$k <- BestK2012\n",
    "    SimulatedKernels2012_beta$theta <- BestTheta2012\n",
    "    SimulatedKernels2012_beta$iteration <- n\n",
    "SimulatedKernels2012 <- bind_rows(SimulatedKernels2012, SimulatedKernels2012_beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monsoon season prep\n",
    "NEM_months <- c(11, 12, 1, 2, 3, 4)\n",
    "SWM_months <- c(5, 6, 7, 8, 9, 10)\n",
    "\n",
    "NEM <- conn_mat_full4 %>%\n",
    "    filter(month %in% NEM_months) %>%\n",
    "    group_by(source, destination) %>%\n",
    "    summarise(conn=max(fraction))\n",
    "\n",
    "SWM <- conn_mat_full4 %>%\n",
    "    filter(month %in% SWM_months) %>%\n",
    "    group_by(source, destination) %>%\n",
    "    summarise(conn=max(fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CELL BELOW IS WORKING FOR GLM OF OBSERVED DATA BY SIMULATED DATA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(GenSimConn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(is.na(GenSimConn)==T) #should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__run GLM observed genetic dispersal predicted by simulations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(GenSimConn$obs_disp) #should be 0.024\n",
    "var(GenSimConn$obs_disp) #should be 0.054\n",
    "#overdispersion?\n",
    "#no, because residual deviance of the model is not greater than the df\n",
    "#Residual deviance:  38.221  on 948  degrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plan:\n",
    "#fit 3 successive log-linear models starting with main efects only(fit1), main effects plus all 2-way interactions (fit2), and added in all 3 way interactions (fit3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NullMod <- glm(obs_disp ~ dist_km , data=GenSimConn, family=\"poisson\")\n",
    "summary(NullMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObsModExpYearFit1 <- glm(obs_disp ~ AnnRecPart + YearSampled + direction + dist_km +SourcePropSamp +DestPropSamp, data=GenSimConn, family=\"poisson\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(ObsModExpYearFit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#only main effects, first find worthwhile predictors with AIC\n",
    "#the intercept is very significant but I think that just means 0s are more common in the data. totally true!\n",
    "\n",
    "ObsModExpYearFit1 <- glm(obs_disp ~ AnnRecPart + YearSampled + direction + dist_km +SourcePropSamp +DestPropSamp, data=GenSimConn, family=\"poisson\")\n",
    "MainEff_AnnRecPart <- update(ObsModExpYearFit1, . ~ . -AnnRecPart)\n",
    "MainEff_YearSampled <- update(ObsModExpYearFit1, . ~ . -YearSampled)\n",
    "MainEff_direction <- update(ObsModExpYearFit1, . ~ . -direction)\n",
    "MainEff_dist_km <- update(ObsModExpYearFit1, . ~ . -dist_km)\n",
    "MainEff_SourcePropSamp <- update(ObsModExpYearFit1, . ~ . -SourcePropSamp)\n",
    "MainEff_DestPropSamp <- update(ObsModExpYearFit1, . ~ . -DestPropSamp)\n",
    "#drop the 3 terms AIC doesn't support? maybe not though, because when there's an interaction that's the best model\n",
    "MainEff_ARP_DPrp_Dist <- glm(obs_disp ~ YearSampled + direction +SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "#add the interaction between year and simulations\n",
    "ObsModExpYearFit2IntYear <- glm(obs_disp ~ AnnRecPart*YearSampled + direction+SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "ObsModExpYearFit2IntDir <- glm(obs_disp ~ AnnRecPart*YearSampled + direction+SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "ObsModExpYearFit2IntDirNoROMS <- glm(obs_disp ~ AnnRecPart+YearSampled*direction+SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "ObsModExpYearFit3Int <- glm(obs_disp ~ AnnRecPart*YearSampled*direction+SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "\n",
    "FullModNoROMSDestPropSamp <- glm(obs_disp ~  YearSampled + direction + dist_km +SourcePropSamp , data=GenSimConn, family=\"poisson\")\n",
    "FullModNoROMSDestPropSampInt <- glm(obs_disp ~  YearSampled* direction + dist_km +SourcePropSamp , data=GenSimConn, family=\"poisson\")\n",
    "\n",
    "MainEffAIC <- as.data.frame(AIC(NullMod, FullModNoROMSDestPropSampInt, FullModNoROMSDestPropSamp, ObsModExpYearFit1, MainEff_AnnRecPart, MainEff_YearSampled, MainEff_direction, MainEff_dist_km, MainEff_SourcePropSamp, MainEff_DestPropSamp, ObsModExpYearFit2IntDir, ObsModExpYearFit2IntYear, ObsModExpYearFit2IntDirNoROMS, ObsModExpYearFit3Int))\n",
    "MainEffAIC$model <- row.names(MainEffAIC)\n",
    "MainEffAIC <- MainEffAIC %>% arrange(AIC)\n",
    "MainEffAIC\n",
    "#/write.csv(MainEffAIC, file=\"~/oceanography/script_output/GLM/GLMObsDispAIC.csv\",row.names=F,  quote=F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullModNoROMSDestPropSampInt <- glm(obs_disp ~  YearSampled* direction+direction+YearSampled + dist_km +SourcePropSamp , data=GenSimConn, family=\"poisson\")\n",
    "\n",
    "summary(FullModNoROMSDestPropSampInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC(test, MainEff_AnnRecPart,MainEff_DestPropSamp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(ObsModExpYearFit2Int ) #judging by the significant intercept (which should be AnnRecPart:Year2012?) when there's more particles expected from the ROMS model, there's actually less in the observed data.\n",
    "ObsModExpYearFit2Int_Sum <- tidy(ObsModExpYearFit2Int)\n",
    "#write.csv(ObsModExpYearFit2Int_Sum, file=\"~/oceanography/script_output/GLM/YearDispIntBestModSum.csv\",row.names=F,  quote=F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROMSFull <- glm(AnnRecPart ~ as.factor(SimYear) + direction + dist_km + source + destination, data=GenSimConn, family=\"poisson\")\n",
    "#MainEff_AnnRecPart <- update(ObsModExpYearFit1, . ~ . -AnnRecPart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary(ROMSFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(SimConnDFDir$NormSourceMonsoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what are the routes that create these peaks in direction annually?\n",
    "\n",
    "#are there similar patterns seasonally?\n",
    "\n",
    "#plot the connectivity matrix with of the roms model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head(SimConnDFMeta %>% dplyr::select(AnnRecPart, direction, SimYear, source, destination))\n",
    "SimConnDFMeta %>%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(SimConnDFMeta$direction, breaks=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(SimConnDFMeta$direction)\n",
    "(SimConnDFMeta$direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this isn't significant, which means the residual difference is small enough here to say the model fits reasonably well\n",
    "with(test_mod, cbind(res.deviance = deviance, df = df.residual,\n",
    "  p = pchisq(deviance, df.residual, lower.tail=FALSE)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how much devience is explained here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(obs_disp ~ ExpDisp, data=SimPlusGenWithDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot(test_mod_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot predicted model\n",
    "range(SimPlusGenWithDist$ExpDisp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_disp_range <- seq(0, 66114, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_disp_pred <- predict(test_mod_int,type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot( SimPlusGenWithDist$ExpDisp, SimPlusGenWithDist$obs_disp, pch = 16)#, xlab = \"WEIGHT (g)\", ylab = \"VS\")\n",
    "\n",
    "lines(obs_disp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
