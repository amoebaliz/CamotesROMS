{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Packages <- c(\"dplyr\",\"nleqslv\", \"broom\",\"cubature\", \"geosphere\", \"data.table\",  \"ggplot2\", \"bbmle\", \"dplyr\",\"tidyr\", \"stringr\", \"tidyverse\", \"lubridate\", \"RColorBrewer\")\n",
    "\n",
    "invisible(suppressPackageStartupMessages(lapply(Packages, library, character.only = TRUE)))\n",
    "\n",
    "setwd('/local/home/katrinac/oceanography')\n",
    "\"%!in%\" <- function(x,table) match(x,table, nomatch = 0) == 0\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/ll_kt_both_bbmle.R\")\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/GenGausKernInt_sum0.5.R\") #integrate_kernel_sum1\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/GenGausKernInt_sum1.R\") #integrate_kernel_sum0.5\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/cdf_solve.R\") #median\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/cdf_solve90.R\") #dist 90% retained\n",
    "\n",
    "#clownfish metadata\n",
    "load(\"~/parentage/r_data/total_sampling_across_years.RData\")\n",
    "load(\"~/parentage/r_data/sampled_area_each_year.RData\")\n",
    "#https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Script_outputs/cumulative_prop_hab_sampled_by_site.RData)\n",
    "load(\"~/parentage/r_data/cumulative_prop_hab_sampled_by_site.RData\")\n",
    "#download.file(url = \"https://github.com/pinskylab/genomics/blob/master/data/fish-obs.RData?raw=true\", destfile = \"~/parentage/r_data/fish-obs.RData\")\n",
    "fish_obs <- readRDS(\"~/parentage/r_data/fish-obs.RData\") \n",
    "load(\"~/parentage/r_data/site_dist_info.RData\")\n",
    "#download.file(url = \"https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Data_from_database/anem_db.RData?raw=true\", destfile = \"~/parentage/r_data/anem_db.RData\")\n",
    "load(\"~/parentage/r_data/anem_db.RData\")\n",
    "#download.file(url = \"https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Data_from_database/dives_db.RData?raw=true\", destfile = \"~/parentage/r_data/dives_db.RData\")\n",
    "load(\"~/parentage/r_data/dives_db.RData\")\n",
    "#download.file(url = \"https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Data_from_database/fish_db.RData?raw=true\", destfile = \"~/parentage/r_data/dives_db.RData\")\n",
    "load(\"~/parentage/r_data/fish_db.RData\")\n",
    "load(\"~/parentage/r_data/gps_db.RData\")\n",
    "\n",
    "#stop dplyr's courtesy warnings about grouping variables and summarise()\n",
    "options(dplyr.summarise.inform=F) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnsampledSites <- c(\"SF1\", \"SF2\", \"SF3\", \"SF4\", \"SF5\", \"SF6\", \"Pangasugan\", \"CAI\", \"Other\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in the df where each particle is an observation\n",
    "Simulation2012 <- fread(file=\"~/oceanography/script_output/SimulationSummaryTables/SimConnLongForm2012YearSampled.csv\", showProgress = T)\n",
    "Simulation2013 <- fread(file=\"~/oceanography/script_output/SimulationSummaryTables/SimConnLongForm2013YearSampled.csv\", showProgress = T)\n",
    "Simulation2014 <- fread(file=\"~/oceanography/script_output/SimulationSummaryTables/SimConnLongForm2014YearSampled.csv\", showProgress = T)\n",
    "\n",
    "#this is about 3 GB so fread is fastest, but consider these options for dealing with a large csv\n",
    "#https://inbo.github.io/tutorials/tutorials/r_large_data_files_handling/\n",
    "\n",
    "#head(Simulation2012 %>% group_by(date, source, destination) %>% summarise(Check=n()))\n",
    "#CAI should be 201718, it is, all good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read in the centroids adjusted for the simulation, so the Magbangons combined \n",
    "centroids <- read.csv(file=\"~/oceanography/script_output/SurveyData/SimulationCentroids.csv\", header=T, stringsAsFactors = F)\n",
    "#read in the distance matrix adjusted for the simulation\n",
    "distances <- read.csv(file=\"~/oceanography/script_output/SurveyData/SimulationAllDistances.csv\", header=T, stringsAsFactors = F)\n",
    "\n",
    "\n",
    "#proportion sampled\n",
    "#add how well we sampled sites- proportion of habitat sampled\n",
    "load(\"~/parentage/r_data/cumulative_prop_hab_sampled_by_site.RData\")\n",
    "PropSamp <- cumulative_prop_hab_sampled_by_site %>%\n",
    "    mutate(total_possible_sample_anems = ifelse(site==\"Caridad Proper\", 4, total_possible_sample_anems) ) %>%\n",
    "    mutate(total_prop_hab_sampled_anems_tidied= ifelse(site==\"Caridad Proper\" & total_anems_sampled==4, 1, total_prop_hab_sampled_anems_tidied) ) %>%\n",
    "    mutate(total_possible_sample_anems = ifelse(site==\"Sitio Lonas\", total_anems_sampled, total_possible_sample_anems) ) %>%\n",
    "    mutate(total_prop_hab_sampled_anems_tidied= ifelse(site==\"Sitio Lonas\", 1, total_prop_hab_sampled_anems_tidied) )%>%\n",
    "    mutate(total_prop_hab_sampled_anems_tidied= ifelse(is.nan(total_prop_hab_sampled_anems_tidied), 0, total_prop_hab_sampled_anems_tidied) ) %>%\n",
    "    dplyr::select(site, time_frame, end_year, total_prop_hab_sampled_anems_tidied) \n",
    "\n",
    "PropSamp$site <- gsub(\". \", \".\", PropSamp$site, fixed=TRUE) #fix spaces in Magbangon names\n",
    "\n",
    "S.Mag <- PropSamp %>%#make a table for all of the S. Mabangon years/prop sampled. Then join to the DF, make a column adding S.Magbangon values to all rows of prop sampled, but only sub that value in for PropSamp in N.Magbangon rows, then rename N.Magbangon as Magbangon\n",
    "    filter(site==\"S.Magbangon\") %>%\n",
    "    dplyr::select(site, end_year, total_prop_hab_sampled_anems_tidied) %>%\n",
    "    rename(S.MagVal=\"total_prop_hab_sampled_anems_tidied\", extra=\"site\")\n",
    "\n",
    "PropSamp <- left_join(PropSamp, S.Mag, by=c(\"end_year\")) %>%\n",
    "    mutate(S.MagSum=total_prop_hab_sampled_anems_tidied+S.MagVal) %>% #create col adding the S.Mag values to prop hab - keep in mind values could be greater than 1- if so change them to 1\n",
    "    mutate(total_prop_hab_sampled_anems_tidied= ifelse(site==\"N.Magbangon\", S.MagSum, total_prop_hab_sampled_anems_tidied)) %>%#sub this value in for only N.Mag\n",
    "    mutate(site=ifelse(site==\"N.Magbangon\", \"Magbangon\", site)) %>%#change N.Mag name to generic Mag\n",
    "    filter(site !=\"S.Magbangon\") %>%#eliminate the S.Mag rows, they are now repeats\n",
    "    dplyr::select(-S.MagVal,-extra, -S.MagSum, -time_frame) %>%\n",
    "    rename(PropSamp=\"total_prop_hab_sampled_anems_tidied\")\n",
    "\n",
    "\n",
    "#check if there are values>1, should be none\n",
    "sum(which(PropSamp$total_prop_hab_sampled_anems_tidied >1)) #zero, that's good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "791"
      ],
      "text/latex": [
       "791"
      ],
      "text/markdown": [
       "791"
      ],
      "text/plain": [
       "[1] 791"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load data from the genetic sampling in each year\n",
    "#read in the kernel fitting summary\n",
    "kernels <- read.csv(file=\"~/parentage/kernel_fitting/1340_loci/final_results/tables/kernel_fitting_summary.csv\", header=T, stringsAsFactors = F)\n",
    "\n",
    "##read in the sites that we sampled each year\n",
    "N_gen_par <- read.table(file=\"~/parentage/colony2/20190523_1340loci/input/all_parents_corrected.txt\", header = TRUE, stringsAsFactors = F) %>%#not sure that I need the parents here\n",
    "    mutate(fish_indiv=as.character(fish_indiv))\n",
    "N_gen_offs <- read.table(file=\"~/parentage/colony2/20190523_1340loci/input/all_offspring_corrected.txt\", header=T, stringsAsFactors = F) %>%\n",
    "    mutate(fish_indiv=as.character(fish_indiv))\n",
    "\n",
    "\n",
    "\n",
    "#gather the summary of total offspring sampled\n",
    "#from Allison, putting all the meta data together (Constants_database_common_functions.R)\n",
    "##### Match up other relevant info (site, date, fish_indiv, etc.) to fish in the clownfish table\n",
    "# Pull out year and month into a separate column in dives_db\n",
    "dives_db_processed <- dives_db %>%\n",
    "  mutate(year = as.integer(substring(date,1,4))) %>%\n",
    "  mutate(month = as.integer(substring(date,6,7))) %>%\n",
    "  mutate(dive_date = date(date))\n",
    "\n",
    "# Pull all APCL caught or otherwise in the clownfish table\n",
    "allfish_fish <- fish_db %>%\n",
    "  select(fish_table_id, anem_table_id, fish_spp, sample_id, anem_table_id, recap, tag_id, color, sex, size, fish_obs_time, fish_notes) %>%\n",
    "  filter(fish_spp == 'APCL') %>%\n",
    "  mutate(size = as.numeric(size))  # make the size numeric (rather than chr) so can do means and such\n",
    "\n",
    "# and their corresponding anemones\n",
    "allfish_anems <- anem_db %>%\n",
    "  select(anem_table_id, dive_table_id, anem_obs, anem_id, old_anem_id, anem_notes) %>%\n",
    "  filter(anem_table_id %in% allfish_fish$anem_table_id)\n",
    "\n",
    "# and the corresponding dive info\n",
    "allfish_dives <- dives_db_processed %>%\n",
    "  select(dive_table_id, dive_type, date, year, month, site, gps, dive_notes) %>%\n",
    "  filter(dive_table_id %in% allfish_anems$dive_table_id) \n",
    "\n",
    "# join together\n",
    "allfish_caught <- left_join(allfish_fish, allfish_anems, by=\"anem_table_id\")\n",
    "allfish_caught <- left_join(allfish_caught, allfish_dives, by=\"dive_table_id\")\n",
    "\n",
    "# add in the gen_ids and fish_indiv (now in a separate gen_id table) - gen_id only comes in the time the fish was sequenced, not at all captures\n",
    "allfish_caught <- left_join(allfish_caught, (fish_obs %>% select(fish_table_id, gen_id, fish_indiv)), by = \"fish_table_id\") %>%\n",
    "    select(fish_indiv, sample_id, site) %>%\n",
    "    mutate()\n",
    "\n",
    "N_gen_offs_annual  <- left_join(N_gen_offs, allfish_caught, by=c(\"fish_indiv\", \"sample_id\")) %>% \n",
    "    group_by(year, site) %>%\n",
    "    summarise(n_offs_gen=n()) %>%\n",
    "    ungroup()\n",
    "\n",
    "N_gen_offs_annual$site <- gsub(\". \", \".\", N_gen_offs_annual$site, fixed=TRUE)\n",
    "\n",
    "##for all years\n",
    "NGenOffsAll <- N_gen_offs_annual %>% \n",
    "    group_by(site) %>% \n",
    "    summarise(n_offs_gen=sum(n_offs_gen, na.rm=T))\n",
    "\n",
    "sum(NGenOffsAll$n_offs_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "791"
      ],
      "text/latex": [
       "791"
      ],
      "text/markdown": [
       "791"
      ],
      "text/plain": [
       "[1] 791"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#combine N/S Magbangon in the genetic sampling data\n",
    "\n",
    "AnnualRecsSamp <- bind_rows(N_gen_offs_annual %>%\n",
    "                        filter(site !=\"N.Magbangon\" & site!=\"S.Magbangon\"),\n",
    "                    N_gen_offs_annual %>%\n",
    "                        mutate(Magbangon=ifelse(site==\"N.Magbangon\" | site==\"S.Magbangon\", \"Magbangon\", \"no\")) %>%\n",
    "                        filter(Magbangon==\"Magbangon\") %>%\n",
    "                        group_by(year, Magbangon) %>%\n",
    "                        summarise(sum_offs=sum(n_offs_gen)) %>%\n",
    "                        rename(site=\"Magbangon\", n_offs_gen=\"sum_offs\")) %>%\n",
    "                        mutate(year=as.character(year)) %>%\n",
    "                        ungroup()\n",
    "sum(AnnualRecsSamp$n_offs_gen) #should be 791\n",
    "\n",
    "#add in ALL sites that we sampled, even though we didn't find recruits there\n",
    "AnnualRecsSamp <- left_join(PropSamp %>%  #add in all sampled sites as possible offs sites\n",
    "                            filter(PropSamp > 0),\n",
    "                          AnnualRecsSamp, \n",
    "                              by=c(\"site\", end_year=\"year\")) %>%\n",
    "                        rename(year=\"end_year\")  %>%\n",
    "                        mutate(n_offs_gen=ifelse(is.na(n_offs_gen), 0, n_offs_gen)) %>%#if we didn't sample a recruit at a site that we still visited, put a 0 in place of the NA\n",
    "                        filter(year %in% c(\"2012\", \"2013\", \"2014\")) %>%  #* restrict to what we can pick up combining all years of simulation data\n",
    "                        group_by(site) %>% #*\n",
    "                        mutate(n_offs_gen_all_years=sum(n_offs_gen)) #*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(i in 1:nrow(NGenOffs2014)){ \n",
    "    \n",
    "    destination_eval <- as.character(NGenOffs2014$site[i]) #pick out a destination site\n",
    "    \n",
    "    SimSampDestination <- Simulation2014SurvGrowth %>% #USING DF WITH SURV/SIZE WEIGHTING ***\n",
    "                                filter(destination==destination_eval) %>%\n",
    "                                sample_n(as.numeric(NGenOffs2014$n_offs_gen[i]),  replace=F) %>% #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "                                select(one_of(names(Simulation2014)))#keep matching columns with the original df instead of carrying over the columns used for survival weighting\n",
    "    SimulatedSampling2014 <- bind_rows(SimulatedSampling2014, SimSampDestination) #build into a sampled particle df\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>date</th><th scope=col>source</th><th scope=col>destination</th><th scope=col>SourceSampled</th><th scope=col>DestSampled</th><th scope=col>SimMonth</th><th scope=col>SimDay</th><th scope=col>SimYear</th><th scope=col>YearSampled</th><th scope=col>SimMonsoon</th><th scope=col>DailyParticles</th><th scope=col>ParticlesReleasedDaily</th><th scope=col>dist_km</th><th scope=col>bearing</th><th scope=col>direction</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2014-01-14    </td><td>SF3           </td><td>Cabatoan      </td><td>no            </td><td>yes           </td><td> 1            </td><td> 1            </td><td>2014          </td><td>2014          </td><td>NEM           </td><td> 42           </td><td>2976          </td><td> 4.857907     </td><td> -36.41887    </td><td>323.5811      </td></tr>\n",
       "\t<tr><td>2013-12-22    </td><td>Cabatoan      </td><td>Cabatoan      </td><td>yes           </td><td>yes           </td><td>12            </td><td>12            </td><td>2013          </td><td>2014          </td><td>NEM           </td><td> 14           </td><td> 992          </td><td> 0.000000     </td><td>-180.00000    </td><td>-10.0000      </td></tr>\n",
       "\t<tr><td>2013-12-26    </td><td>Sitio Baybayon</td><td>Cabatoan      </td><td>yes           </td><td>yes           </td><td>12            </td><td>12            </td><td>2013          </td><td>2014          </td><td>NEM           </td><td>467           </td><td>1984          </td><td>24.910562     </td><td> -12.35333    </td><td>347.6467      </td></tr>\n",
       "\t<tr><td>2013-12-26    </td><td>Sitio Baybayon</td><td>Cabatoan      </td><td>yes           </td><td>yes           </td><td>12            </td><td>12            </td><td>2013          </td><td>2014          </td><td>NEM           </td><td>467           </td><td>1984          </td><td>24.910562     </td><td> -12.35333    </td><td>347.6467      </td></tr>\n",
       "\t<tr><td>2014-01-07    </td><td>Cabatoan      </td><td>Cabatoan      </td><td>yes           </td><td>yes           </td><td> 1            </td><td> 1            </td><td>2014          </td><td>2014          </td><td>NEM           </td><td> 68           </td><td> 992          </td><td> 0.000000     </td><td>-180.00000    </td><td>-10.0000      </td></tr>\n",
       "\t<tr><td>2014-01-21    </td><td>SF2           </td><td>Cabatoan      </td><td>no            </td><td>yes           </td><td> 1            </td><td> 1            </td><td>2014          </td><td>2014          </td><td>NEM           </td><td>117           </td><td>3968          </td><td> 1.858614     </td><td> -34.78244    </td><td>325.2176      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " date & source & destination & SourceSampled & DestSampled & SimMonth & SimDay & SimYear & YearSampled & SimMonsoon & DailyParticles & ParticlesReleasedDaily & dist\\_km & bearing & direction\\\\\n",
       "\\hline\n",
       "\t 2014-01-14     & SF3            & Cabatoan       & no             & yes            &  1             &  1             & 2014           & 2014           & NEM            &  42            & 2976           &  4.857907      &  -36.41887     & 323.5811      \\\\\n",
       "\t 2013-12-22     & Cabatoan       & Cabatoan       & yes            & yes            & 12             & 12             & 2013           & 2014           & NEM            &  14            &  992           &  0.000000      & -180.00000     & -10.0000      \\\\\n",
       "\t 2013-12-26     & Sitio Baybayon & Cabatoan       & yes            & yes            & 12             & 12             & 2013           & 2014           & NEM            & 467            & 1984           & 24.910562      &  -12.35333     & 347.6467      \\\\\n",
       "\t 2013-12-26     & Sitio Baybayon & Cabatoan       & yes            & yes            & 12             & 12             & 2013           & 2014           & NEM            & 467            & 1984           & 24.910562      &  -12.35333     & 347.6467      \\\\\n",
       "\t 2014-01-07     & Cabatoan       & Cabatoan       & yes            & yes            &  1             &  1             & 2014           & 2014           & NEM            &  68            &  992           &  0.000000      & -180.00000     & -10.0000      \\\\\n",
       "\t 2014-01-21     & SF2            & Cabatoan       & no             & yes            &  1             &  1             & 2014           & 2014           & NEM            & 117            & 3968           &  1.858614      &  -34.78244     & 325.2176      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| date | source | destination | SourceSampled | DestSampled | SimMonth | SimDay | SimYear | YearSampled | SimMonsoon | DailyParticles | ParticlesReleasedDaily | dist_km | bearing | direction |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 2014-01-14     | SF3            | Cabatoan       | no             | yes            |  1             |  1             | 2014           | 2014           | NEM            |  42            | 2976           |  4.857907      |  -36.41887     | 323.5811       |\n",
       "| 2013-12-22     | Cabatoan       | Cabatoan       | yes            | yes            | 12             | 12             | 2013           | 2014           | NEM            |  14            |  992           |  0.000000      | -180.00000     | -10.0000       |\n",
       "| 2013-12-26     | Sitio Baybayon | Cabatoan       | yes            | yes            | 12             | 12             | 2013           | 2014           | NEM            | 467            | 1984           | 24.910562      |  -12.35333     | 347.6467       |\n",
       "| 2013-12-26     | Sitio Baybayon | Cabatoan       | yes            | yes            | 12             | 12             | 2013           | 2014           | NEM            | 467            | 1984           | 24.910562      |  -12.35333     | 347.6467       |\n",
       "| 2014-01-07     | Cabatoan       | Cabatoan       | yes            | yes            |  1             |  1             | 2014           | 2014           | NEM            |  68            |  992           |  0.000000      | -180.00000     | -10.0000       |\n",
       "| 2014-01-21     | SF2            | Cabatoan       | no             | yes            |  1             |  1             | 2014           | 2014           | NEM            | 117            | 3968           |  1.858614      |  -34.78244     | 325.2176       |\n",
       "\n"
      ],
      "text/plain": [
       "  date       source         destination SourceSampled DestSampled SimMonth\n",
       "1 2014-01-14 SF3            Cabatoan    no            yes          1      \n",
       "2 2013-12-22 Cabatoan       Cabatoan    yes           yes         12      \n",
       "3 2013-12-26 Sitio Baybayon Cabatoan    yes           yes         12      \n",
       "4 2013-12-26 Sitio Baybayon Cabatoan    yes           yes         12      \n",
       "5 2014-01-07 Cabatoan       Cabatoan    yes           yes          1      \n",
       "6 2014-01-21 SF2            Cabatoan    no            yes          1      \n",
       "  SimDay SimYear YearSampled SimMonsoon DailyParticles ParticlesReleasedDaily\n",
       "1  1     2014    2014        NEM         42            2976                  \n",
       "2 12     2013    2014        NEM         14             992                  \n",
       "3 12     2013    2014        NEM        467            1984                  \n",
       "4 12     2013    2014        NEM        467            1984                  \n",
       "5  1     2014    2014        NEM         68             992                  \n",
       "6  1     2014    2014        NEM        117            3968                  \n",
       "  dist_km   bearing    direction\n",
       "1  4.857907  -36.41887 323.5811 \n",
       "2  0.000000 -180.00000 -10.0000 \n",
       "3 24.910562  -12.35333 347.6467 \n",
       "4 24.910562  -12.35333 347.6467 \n",
       "5  0.000000 -180.00000 -10.0000 \n",
       "6  1.858614  -34.78244 325.2176 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(SimulatedSampling2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Narrow down data to the year of interests__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#what if we account for post-settlement mortality and not sampling <3.5 cm recruits?\n",
    "NumDays <- nrow(Simulation2012 %>% distinct(date))#200 days in a simulation\n",
    "\n",
    "#make a df with weighted values for the days of the simluation oldest to most recent\n",
    "SimDates <- Simulation2012 %>%\n",
    "    distinct(date) %>%\n",
    "    mutate(DateSeq=row_number()) %>% #assign row numbers, so more recent dates are higher than older\n",
    "    mutate(SurvivalWeightExp=exp(DateSeq)) %>% #apply the exponential function to get a survival column\n",
    "    mutate(SurvivalWeightExp=SurvivalWeightExp/max(SurvivalWeightExp))%>%#normalize as a survival \"probability\"\n",
    "    mutate(SurvivalWeightLin=(((0.25/2)/5)*DateSeq)) %>%#maybe a linear survival function (y=mx)is more appropriate (eyeball from Allison's Fig 3C because what the hell why not we're just thinking here)\n",
    "    mutate(SurvivalWeightLin=SurvivalWeightLin/max(SurvivalWeightLin)) #%>%#normalize as a survival \"probability\"\n",
    "    #filter(DateSeq %!in% seq((max(DateSeq)-60), max(DateSeq), 1))#account for the fact that we didn't sample <3.5 cm\n",
    "#the max survival prob will be different depending on when I filter out the more recent recruits. I don't want an artificially high prob of sampling based on a survival prob of 1 so I'm cutting fish out after prob weight calculations\n",
    "Simulation2012SurvGrowth <- left_join(Simulation2012, SimDates, by=\"date\") %>%\n",
    "    filter(DateSeq %!in% seq((max(DateSeq)-60), max(DateSeq), 1))\n",
    "nrow(Simulation2012SurvGrowth)<nrow(Simulation2012)#should be TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "9"
      ],
      "text/latex": [
       "9"
      ],
      "text/markdown": [
       "9"
      ],
      "text/plain": [
       "[1] 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "63"
      ],
      "text/latex": [
       "63"
      ],
      "text/markdown": [
       "63"
      ],
      "text/plain": [
       "[1] 63"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3"
      ],
      "text/latex": [
       "3"
      ],
      "text/markdown": [
       "3"
      ],
      "text/plain": [
       "[1] 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#RUNNING ON 3/18/2021 ACCOUNTING FOR DIFFERENTIAL SAMPLING BASED ON SIZE/POSTSETTLEMENT SURVIVAL\n",
    "#sample the simulation results according to how many offspring we sampled at that site in real life, each row is a column\n",
    "NGenOffs2012 <- AnnualRecsSamp %>%\n",
    "    filter(year==\"2012\")\n",
    "\n",
    "nrow(NGenOffs2012) #should be 9 sites sampled for 2012\n",
    "\n",
    "#make an empty dataframe with the same columns as original, this will be sampled particles\n",
    "SimulatedSampling2012 = Simulation2012[FALSE,]\n",
    "\n",
    "for(i in 1:nrow(NGenOffs2012)){ \n",
    "    \n",
    "    destination_eval <- as.character(NGenOffs2012$site[i]) #pick out a destination site\n",
    "    \n",
    "    SimSampDestination <- Simulation2012 %>% #USING DF WITH SURV/SIZE WEIGHTING SurvGrowth ***\n",
    "                                filter(destination==destination_eval) %>%\n",
    "                                sample_n(as.numeric(NGenOffs2012$n_offs_gen[i]), replace=F) %>% #, weight=SurvivalWeightLin, sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "                                select(one_of(names(Simulation2012)))#keep matching columns with the original df instead of carrying over the columns used for survival weighting\n",
    "    SimulatedSampling2012 <- bind_rows(SimulatedSampling2012, SimSampDestination) #build into a sampled particle df\n",
    "}\n",
    "\n",
    "#assign a numeric ID for each row (which is a sampled particle)\n",
    "SimulatedSampling2012 <- SimulatedSampling2012 %>%\n",
    "    mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "\n",
    "nrow(SimulatedSampling2012)==sum(NGenOffs2012$n_offs_gen) #should be TRUE\n",
    "\n",
    "#now randomly assign parentage match status to some of these rows\n",
    "NumPar <- as.numeric(kernels %>%\n",
    "    filter(Year==\"2012\") %>%\n",
    "    select(NumParentageMatches))\n",
    "\n",
    "SimulatedSampling2012Par <- SimulatedSampling2012 %>%\n",
    "    ungroup() %>%\n",
    "    filter(source %in% NGenOffs2012$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "    sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "    mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "    #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "    #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "\n",
    "#find the rows that haven't been assigned parentage\n",
    "SimulatedSampling2012_2 <- anti_join((SimulatedSampling2012 %>% ungroup()), SimulatedSampling2012Par, by=c(\"ParticleSampID\")) \n",
    "\n",
    "SimulatedSampling2012_2$Parentage <- 0 #add in the column for parentage\n",
    "\n",
    "#combine parentage and non-parentage dfs\n",
    "SimulatedSampling2012Par3 <- bind_rows(SimulatedSampling2012Par, SimulatedSampling2012_2) %>%\n",
    "    mutate(YearSampled=as.character(YearSampled))\n",
    "\n",
    "nrow(SimulatedSampling2012Par3) \n",
    "nrow(SimulatedSampling2012Par3 %>% filter(Parentage==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct carry over of sampled particles in TotalSimSamp\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct carry over of sampled particles in TotalSimSamp2\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of parentage matches in TotalSimPar\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of destination sites, corresponding to number of surveyed sites in SimSampSummary2012, which is used for unassigned row\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of destination sites, corresponding to number of surveyed sites in TotalSimPar2, which will be spread into parentage matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of parentage matches in TotalSimPar2, which will be spread into parentage matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of source sites in final matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of destination sites in final matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of parentage matches in final matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3"
      ],
      "text/latex": [
       "3"
      ],
      "text/markdown": [
       "3"
      ],
      "text/plain": [
       "[1] 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of unassigned recruits in final matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "60"
      ],
      "text/latex": [
       "60"
      ],
      "text/markdown": [
       "60"
      ],
      "text/plain": [
       "[1] 60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] TRUE TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PropSamp2012 <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                filter(end_year ==\"2012\" & PropSamp > 0) %>%\n",
    "                #rename(source=\"site\") %>%\n",
    "                select(-end_year, -PropSamp)\n",
    "\n",
    "#PropSamp2012$destination <- PropSamp2012$source #make another column for destination\n",
    "\n",
    "#make a table with the total number of particles sampled at each site\n",
    "TotalSimSamp <- SimulatedSampling2012Par3 %>% \n",
    "            select(source, destination) %>%\n",
    "            group_by(destination) %>%\n",
    "            summarise(NumSimSampRec=n()) %>%\n",
    "            ungroup()\n",
    "print(\"correct carry over of sampled particles in TotalSimSamp\")\n",
    "sum(TotalSimSamp$NumSimSampRec)==sum(NGenOffs2012$n_offs_gen) #should be true\n",
    "\n",
    "#add in all surveyed sites\n",
    "TotalSimSamp2 <- left_join(PropSamp2012, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "    rename(destination=\"site\")#rename sites to destination after joining\n",
    "\n",
    "print(\"correct carry over of sampled particles in TotalSimSamp2\")\n",
    "sum(TotalSimSamp$NumSimSampRec)==sum(TotalSimSamp2$NumSimSampRec) #should be TRUE\n",
    "\n",
    "#make a table with the total number of parentage matches found in the simulated loop\n",
    "TotalSimPar <- SimulatedSampling2012Par3 %>% \n",
    "            select(source, destination, Parentage) %>%\n",
    "            group_by(source,destination) %>%\n",
    "            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "            select(-Parentage) %>%\n",
    "            ungroup() %>%\n",
    "            distinct(source, destination, .keep_all = T)\n",
    "\n",
    "print(\"correct number of parentage matches in TotalSimPar\")\n",
    "sum(TotalSimPar$NumPar)==NumPar #should be TRUE\n",
    "\n",
    "#combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "SimSampSummary2012 <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "    distinct(source, destination, .keep_all = T) %>%\n",
    "    group_by(destination) %>%\n",
    "    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "    distinct(destination, .keep_all = T) %>%\n",
    "    select(-source) %>%\n",
    "    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "\n",
    "print(\"correct number of destination sites, corresponding to number of surveyed sites in SimSampSummary2012, which is used for unassigned row\")\n",
    "nrow(SimSampSummary2012 %>% distinct(destination, .keep_all = T))==nrow(PropSamp2012) #should be TRUE, 9 possible destinations for 2012\n",
    "\n",
    "\n",
    "#finally, join all of the sites surveyed for a complete parentage matrix\n",
    "#for this, need to have a source/destination column for all sites\n",
    "PropSamp2012 <- PropSamp2012 %>%\n",
    "                rename(source=\"site\")\n",
    "\n",
    "PropSamp2012$destination <- PropSamp2012$source #make another column for destination\n",
    "\n",
    "#this below will become parentage matrix! \n",
    "TotalSimPar2 <- full_join(TotalSimPar,PropSamp2012, by=c(\"source\", \"destination\")) %>%\n",
    "    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "\n",
    "print(\"correct number of destination sites, corresponding to number of surveyed sites in TotalSimPar2, which will be spread into parentage matrix\")\n",
    "nrow(TotalSimPar2 %>% distinct(destination, .keep_all = T))==nrow(PropSamp2012) #should be TRUE, 9 possible destinations for 2012\n",
    "\n",
    "#check that the number of matches is still correct\n",
    "print(\"correct number of parentage matches in TotalSimPar2, which will be spread into parentage matrix\")\n",
    "sum(TotalSimPar2$NumPar)==NumPar\n",
    "\n",
    "#spread into matrix format\n",
    "SimDispMat <- TotalSimPar2 %>%\n",
    "    filter(source %in% NGenOffs2012$site) %>%\n",
    "    arrange(source, destination)  %>%\n",
    "    spread(destination, NumPar) %>%\n",
    "    select(-source)\n",
    "SimDispMat[is.na(SimDispMat)] <- 0\n",
    "\n",
    "#add in unassigned row\n",
    "unassigned <- t(as.matrix(SimSampSummary2012 %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "#rownames(unassigned)<-NULL\n",
    "colnames(unassigned)<-names(SimDispMat)\n",
    "\n",
    "SimDispMatFull2012 <- rbind(SimDispMat, unassigned)\n",
    "#colnames(SimDispMatFull2012) <- NULL\n",
    "\n",
    "#error check final matrix \n",
    "print(\"correct number of source sites in final matrix\")\n",
    "nrow(SimDispMatFull2012)==nrow(PropSamp2012)+1\n",
    "\n",
    "print(\"correct number of destination sites in final matrix\")\n",
    "ncol(SimDispMatFull2012)==nrow(PropSamp2012)\n",
    "\n",
    "print(\"correct number of parentage matches in final matrix\")\n",
    "sum(SimDispMatFull2012[1:nrow(PropSamp2012),])==NumPar\n",
    "NumPar\n",
    "\n",
    "print(\"correct number of unassigned recruits in final matrix\")\n",
    "sum(SimDispMatFull2012[nrow(PropSamp2012)+1,])==sum(NGenOffs2012$n_offs_gen)-NumPar\n",
    "sum(NGenOffs2012$n_offs_gen)-NumPar\n",
    "\n",
    "#finally- make sure dimensions of simulated parentage matrix match that of the genetic kernel fits. we should be totally replicating the genetic kernel fitting here\n",
    "#EXCEPT! Remember that in the genetic data Magbangon was separated into two sites, but in the simulated data it's not\n",
    "EmpiricalAssignments <- read.csv(\"~/parentage/kernel_fitting/1340_loci/input/parentage_matrix12_corrected.csv\", header=F)\n",
    "\n",
    "#print(\"dimensions of simulated and empirical parentage matrix are the same\")\n",
    "(dim(EmpiricalAssignments)-1)==dim(SimDispMatFull2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>row</th><th scope=col>col</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " row & col\\\\\n",
       "\\hline\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| row | col |\n",
       "|---|---|\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "\n"
      ],
      "text/plain": [
       "      row  col \n",
       " [1,] TRUE TRUE\n",
       " [2,] TRUE TRUE\n",
       " [3,] TRUE TRUE\n",
       " [4,] TRUE TRUE\n",
       " [5,] TRUE TRUE\n",
       " [6,] TRUE TRUE\n",
       " [7,] TRUE TRUE\n",
       " [8,] TRUE TRUE\n",
       " [9,] TRUE TRUE\n",
       "[10,] TRUE TRUE\n",
       "[11,] TRUE TRUE\n",
       "[12,] TRUE TRUE\n",
       "[13,] TRUE TRUE\n",
       "[14,] TRUE TRUE\n",
       "[15,] TRUE TRUE\n",
       "[16,] TRUE TRUE\n",
       "[17,] TRUE TRUE\n",
       "[18,] TRUE TRUE\n",
       "[19,] TRUE TRUE\n",
       "[20,] TRUE TRUE\n",
       "[21,] TRUE TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>row</th><th scope=col>col</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " row & col\\\\\n",
       "\\hline\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| row | col |\n",
       "|---|---|\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "\n"
      ],
      "text/plain": [
       "      row  col \n",
       " [1,] TRUE TRUE\n",
       " [2,] TRUE TRUE\n",
       " [3,] TRUE TRUE\n",
       " [4,] TRUE TRUE\n",
       " [5,] TRUE TRUE\n",
       " [6,] TRUE TRUE\n",
       " [7,] TRUE TRUE\n",
       " [8,] TRUE TRUE\n",
       " [9,] TRUE TRUE\n",
       "[10,] TRUE TRUE\n",
       "[11,] TRUE TRUE\n",
       "[12,] TRUE TRUE\n",
       "[13,] TRUE TRUE\n",
       "[14,] TRUE TRUE\n",
       "[15,] TRUE TRUE\n",
       "[16,] TRUE TRUE\n",
       "[17,] TRUE TRUE\n",
       "[18,] TRUE TRUE\n",
       "[19,] TRUE TRUE\n",
       "[20,] TRUE TRUE\n",
       "[21,] TRUE TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>row</th><th scope=col>col</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td><td>TRUE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " row & col\\\\\n",
       "\\hline\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\t TRUE & TRUE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| row | col |\n",
       "|---|---|\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "| TRUE | TRUE |\n",
       "\n"
      ],
      "text/plain": [
       "      row  col \n",
       " [1,] TRUE TRUE\n",
       " [2,] TRUE TRUE\n",
       " [3,] TRUE TRUE\n",
       " [4,] TRUE TRUE\n",
       " [5,] TRUE TRUE\n",
       " [6,] TRUE TRUE\n",
       " [7,] TRUE TRUE\n",
       " [8,] TRUE TRUE\n",
       " [9,] TRUE TRUE\n",
       "[10,] TRUE TRUE\n",
       "[11,] TRUE TRUE\n",
       "[12,] TRUE TRUE\n",
       "[13,] TRUE TRUE\n",
       "[14,] TRUE TRUE\n",
       "[15,] TRUE TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#everything should be true\n",
    "Assignments <- SimDispMatFullAll\n",
    "which(SimDispMat >0, arr.ind =T)==which(SimDispMatFullAll[1:nrow(PropSampAll),]>0, arr.ind =T)\n",
    "#unassigned\n",
    "which(SimDispMat >0, arr.ind =T)==which(Assignments[1:nrow(PropSampAll),]>0, arr.ind =T)\n",
    "which(SimDispMatFullAll[nrow(PropSampAll)+1,]>0, arr.ind =T)==which(Assignments[nrow(PropSampAll)+1,]>0, arr.ind =T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get all the components of the kernel fitting process together__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "34"
      ],
      "text/latex": [
       "34"
      ],
      "text/markdown": [
       "34"
      ],
      "text/plain": [
       "[1] 34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "9"
      ],
      "text/latex": [
       "9"
      ],
      "text/markdown": [
       "9"
      ],
      "text/plain": [
       "[1] 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "9"
      ],
      "text/latex": [
       "9"
      ],
      "text/markdown": [
       "9"
      ],
      "text/plain": [
       "[1] 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#assemble all of the components for annual kernel fitting\n",
    "centroids <- read.csv(\"~/oceanography/empirical_data/site_centroids_simulation_kernels.csv\", header=TRUE, stringsAsFactors = F)\n",
    "\n",
    "Area <- read.csv(\"~/oceanography/empirical_data/site_area_header_nonsurveyed_simulation_kernels.csv\", header=TRUE) %>%\n",
    "    arrange(site) %>%\n",
    "    filter(site %!in% c(\"near_north_full1\", \"near_north_full2\", \"near_north_full3\", \"near_south_full1\", \"near_south_full2\", \"near_south_full3\")) %>%\n",
    "    mutate(kmsq=msq*10^-6) #%>%\n",
    "    #select(kmsq)\n",
    "Reef_sizes <- as.matrix(Area)\n",
    "\n",
    "#give every site in the distance matrix of the simulation (even if we didn't sample there) an index number\n",
    "AllSites <- centroids %>%\n",
    "    select(site) %>%\n",
    "    arrange(site)\n",
    "nrow(AllSites) #should be 34x1\n",
    "AllSites$index <- seq(from=1, to=34, by=1)\n",
    "\n",
    "SampledSites2012 <- inner_join(PropSamp2012 %>% select(source), AllSites, by=c(source=\"site\")) \n",
    "\n",
    "#check for correct number of rows\n",
    "nrow(SampledSites2012)==nrow(PropSamp2012) #should be true\n",
    "SampledSites2012Index <- t(as.matrix(SampledSites2012$index))\n",
    "ncol(SampledSites2012Index)\n",
    "\n",
    "Sampled_reefs <- SampledSites2012Index\n",
    "\n",
    "#proportion sampled matrix for kernel fitting\n",
    "\n",
    "#for annual\n",
    "Adult_sample_proportions <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                filter(end_year ==\"2012\" & PropSamp > 0) \n",
    "\n",
    "Adult_sample_proportions <- as.matrix(Adult_sample_proportions$PropSamp)\n",
    "nrow(Adult_sample_proportions) #should be 9 for 2012\n",
    "\n",
    "#distance matrix using the centroids with combined Magbangon\n",
    "### List of source locations\n",
    "sites_source <- centroids\n",
    "\n",
    "### List of destination locations\n",
    "sites_dest <- centroids\n",
    "\n",
    "dist_mat_m <- distm(sites_source[,c('lon','lat')], sites_source[,c('lon','lat')], fun=distVincentyEllipsoid)\n",
    "Distances <- dist_mat_m*10^-3\n",
    "\n",
    "Centroids <- centroids %>%\n",
    "    select(-site)\n",
    "\n",
    "Assignments <- SimDispMatFull2012\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>source</th><th scope=col>index</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Cabatoan         </td><td> 1               </td></tr>\n",
       "\t<tr><td>Caridad Cemetery </td><td> 8               </td></tr>\n",
       "\t<tr><td>Caridad Proper   </td><td> 9               </td></tr>\n",
       "\t<tr><td>Elementary School</td><td>14               </td></tr>\n",
       "\t<tr><td>Haina            </td><td>16               </td></tr>\n",
       "\t<tr><td>Hicgop South     </td><td>17               </td></tr>\n",
       "\t<tr><td>Magbangon        </td><td>18               </td></tr>\n",
       "\t<tr><td>Palanas          </td><td>25               </td></tr>\n",
       "\t<tr><td>Poroc Rose       </td><td>26               </td></tr>\n",
       "\t<tr><td>Poroc San Flower </td><td>27               </td></tr>\n",
       "\t<tr><td>San Agustin      </td><td>28               </td></tr>\n",
       "\t<tr><td>Sitio Baybayon   </td><td>29               </td></tr>\n",
       "\t<tr><td>Sitio Lonas      </td><td>30               </td></tr>\n",
       "\t<tr><td>Tamakin Dacot    </td><td>32               </td></tr>\n",
       "\t<tr><td>Visca            </td><td>33               </td></tr>\n",
       "\t<tr><td>Wangag           </td><td>34               </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " source & index\\\\\n",
       "\\hline\n",
       "\t Cabatoan          &  1               \\\\\n",
       "\t Caridad Cemetery  &  8               \\\\\n",
       "\t Caridad Proper    &  9               \\\\\n",
       "\t Elementary School & 14               \\\\\n",
       "\t Haina             & 16               \\\\\n",
       "\t Hicgop South      & 17               \\\\\n",
       "\t Magbangon         & 18               \\\\\n",
       "\t Palanas           & 25               \\\\\n",
       "\t Poroc Rose        & 26               \\\\\n",
       "\t Poroc San Flower  & 27               \\\\\n",
       "\t San Agustin       & 28               \\\\\n",
       "\t Sitio Baybayon    & 29               \\\\\n",
       "\t Sitio Lonas       & 30               \\\\\n",
       "\t Tamakin Dacot     & 32               \\\\\n",
       "\t Visca             & 33               \\\\\n",
       "\t Wangag            & 34               \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| source | index |\n",
       "|---|---|\n",
       "| Cabatoan          |  1                |\n",
       "| Caridad Cemetery  |  8                |\n",
       "| Caridad Proper    |  9                |\n",
       "| Elementary School | 14                |\n",
       "| Haina             | 16                |\n",
       "| Hicgop South      | 17                |\n",
       "| Magbangon         | 18                |\n",
       "| Palanas           | 25                |\n",
       "| Poroc Rose        | 26                |\n",
       "| Poroc San Flower  | 27                |\n",
       "| San Agustin       | 28                |\n",
       "| Sitio Baybayon    | 29                |\n",
       "| Sitio Lonas       | 30                |\n",
       "| Tamakin Dacot     | 32                |\n",
       "| Visca             | 33                |\n",
       "| Wangag            | 34                |\n",
       "\n"
      ],
      "text/plain": [
       "   source            index\n",
       "1  Cabatoan           1   \n",
       "2  Caridad Cemetery   8   \n",
       "3  Caridad Proper     9   \n",
       "4  Elementary School 14   \n",
       "5  Haina             16   \n",
       "6  Hicgop South      17   \n",
       "7  Magbangon         18   \n",
       "8  Palanas           25   \n",
       "9  Poroc Rose        26   \n",
       "10 Poroc San Flower  27   \n",
       "11 San Agustin       28   \n",
       "12 Sitio Baybayon    29   \n",
       "13 Sitio Lonas       30   \n",
       "14 Tamakin Dacot     32   \n",
       "15 Visca             33   \n",
       "16 Wangag            34   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>source</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Cabatoan         </td></tr>\n",
       "\t<tr><td>Caridad Cemetery </td></tr>\n",
       "\t<tr><td>Caridad Proper   </td></tr>\n",
       "\t<tr><td>Elementary School</td></tr>\n",
       "\t<tr><td>Haina            </td></tr>\n",
       "\t<tr><td>Hicgop South     </td></tr>\n",
       "\t<tr><td>Magbangon        </td></tr>\n",
       "\t<tr><td>Palanas          </td></tr>\n",
       "\t<tr><td>Poroc Rose       </td></tr>\n",
       "\t<tr><td>Poroc San Flower </td></tr>\n",
       "\t<tr><td>San Agustin      </td></tr>\n",
       "\t<tr><td>Sitio Baybayon   </td></tr>\n",
       "\t<tr><td>Sitio Lonas      </td></tr>\n",
       "\t<tr><td>Tamakin Dacot    </td></tr>\n",
       "\t<tr><td>Visca            </td></tr>\n",
       "\t<tr><td>Wangag           </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       " source\\\\\n",
       "\\hline\n",
       "\t Cabatoan         \\\\\n",
       "\t Caridad Cemetery \\\\\n",
       "\t Caridad Proper   \\\\\n",
       "\t Elementary School\\\\\n",
       "\t Haina            \\\\\n",
       "\t Hicgop South     \\\\\n",
       "\t Magbangon        \\\\\n",
       "\t Palanas          \\\\\n",
       "\t Poroc Rose       \\\\\n",
       "\t Poroc San Flower \\\\\n",
       "\t San Agustin      \\\\\n",
       "\t Sitio Baybayon   \\\\\n",
       "\t Sitio Lonas      \\\\\n",
       "\t Tamakin Dacot    \\\\\n",
       "\t Visca            \\\\\n",
       "\t Wangag           \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| source |\n",
       "|---|\n",
       "| Cabatoan          |\n",
       "| Caridad Cemetery  |\n",
       "| Caridad Proper    |\n",
       "| Elementary School |\n",
       "| Haina             |\n",
       "| Hicgop South      |\n",
       "| Magbangon         |\n",
       "| Palanas           |\n",
       "| Poroc Rose        |\n",
       "| Poroc San Flower  |\n",
       "| San Agustin       |\n",
       "| Sitio Baybayon    |\n",
       "| Sitio Lonas       |\n",
       "| Tamakin Dacot     |\n",
       "| Visca             |\n",
       "| Wangag            |\n",
       "\n"
      ],
      "text/plain": [
       "   source           \n",
       "1  Cabatoan         \n",
       "2  Caridad Cemetery \n",
       "3  Caridad Proper   \n",
       "4  Elementary School\n",
       "5  Haina            \n",
       "6  Hicgop South     \n",
       "7  Magbangon        \n",
       "8  Palanas          \n",
       "9  Poroc Rose       \n",
       "10 Poroc San Flower \n",
       "11 San Agustin      \n",
       "12 Sitio Baybayon   \n",
       "13 Sitio Lonas      \n",
       "14 Tamakin Dacot    \n",
       "15 Visca            \n",
       "16 Wangag           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>site</th><th scope=col>index</th></tr></thead>\n",
       "<tbody>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " site & index\\\\\n",
       "\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| site | index |\n",
       "|---|---|\n",
       "\n"
      ],
      "text/plain": [
       "     site index"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>site</th><th scope=col>index</th></tr></thead>\n",
       "<tbody>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " site & index\\\\\n",
       "\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| site | index |\n",
       "|---|---|\n",
       "\n"
      ],
      "text/plain": [
       "     site index"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#do all of the site ids carry over properly\n",
    "SampledSitesAll\n",
    "PropSampAll\n",
    "AllSites %>% filter(site %in% PropSampAll$source & site %!in% SampledSitesAll$source) #the site names are correct because this doesn't bring up a match\n",
    "AllSites %>% filter(site %in% PropSampAll$source & index %!in% SampledSitesAll$index) #the site indexes are correct because this doesn't bring up a match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>site</th><th scope=col>msq</th><th scope=col>kmsq</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>19</th><td>near_north_ten_per_cover1</td><td>175000                   </td><td>0.175000                 </td></tr>\n",
       "\t<tr><th scope=row>20</th><td>near_north_ten_per_cover2</td><td>175000                   </td><td>0.175000                 </td></tr>\n",
       "\t<tr><th scope=row>21</th><td>near_north_ten_per_cover3</td><td>175000                   </td><td>0.175000                 </td></tr>\n",
       "\t<tr><th scope=row>22</th><td>near_south_ten_per_cover1</td><td>158333                   </td><td>0.158333                 </td></tr>\n",
       "\t<tr><th scope=row>23</th><td>near_south_ten_per_cover2</td><td>158333                   </td><td>0.158333                 </td></tr>\n",
       "\t<tr><th scope=row>24</th><td>near_south_ten_per_cover3</td><td>158333                   </td><td>0.158333                 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & site & msq & kmsq\\\\\n",
       "\\hline\n",
       "\t19 & near\\_north\\_ten\\_per\\_cover1 & 175000                            & 0.175000                         \\\\\n",
       "\t20 & near\\_north\\_ten\\_per\\_cover2 & 175000                            & 0.175000                         \\\\\n",
       "\t21 & near\\_north\\_ten\\_per\\_cover3 & 175000                            & 0.175000                         \\\\\n",
       "\t22 & near\\_south\\_ten\\_per\\_cover1 & 158333                            & 0.158333                         \\\\\n",
       "\t23 & near\\_south\\_ten\\_per\\_cover2 & 158333                            & 0.158333                         \\\\\n",
       "\t24 & near\\_south\\_ten\\_per\\_cover3 & 158333                            & 0.158333                         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | site | msq | kmsq |\n",
       "|---|---|---|---|\n",
       "| 19 | near_north_ten_per_cover1 | 175000                    | 0.175000                  |\n",
       "| 20 | near_north_ten_per_cover2 | 175000                    | 0.175000                  |\n",
       "| 21 | near_north_ten_per_cover3 | 175000                    | 0.175000                  |\n",
       "| 22 | near_south_ten_per_cover1 | 158333                    | 0.158333                  |\n",
       "| 23 | near_south_ten_per_cover2 | 158333                    | 0.158333                  |\n",
       "| 24 | near_south_ten_per_cover3 | 158333                    | 0.158333                  |\n",
       "\n"
      ],
      "text/plain": [
       "   site                      msq    kmsq    \n",
       "19 near_north_ten_per_cover1 175000 0.175000\n",
       "20 near_north_ten_per_cover2 175000 0.175000\n",
       "21 near_north_ten_per_cover3 175000 0.175000\n",
       "22 near_south_ten_per_cover1 158333 0.158333\n",
       "23 near_south_ten_per_cover2 158333 0.158333\n",
       "24 near_south_ten_per_cover3 158333 0.158333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>site_i</th><th scope=col>site_j</th><th scope=col>dist_km</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Cabatoan               </td><td>Cabatoan               </td><td> 0.0000000             </td></tr>\n",
       "\t<tr><td>camotes_central1       </td><td>Cabatoan               </td><td>30.8887144             </td></tr>\n",
       "\t<tr><td>camotes_central2       </td><td>Cabatoan               </td><td>43.7121318             </td></tr>\n",
       "\t<tr><td>camotes_east1          </td><td>Cabatoan               </td><td>17.9721103             </td></tr>\n",
       "\t<tr><td>camotes_east2          </td><td>Cabatoan               </td><td>28.3601067             </td></tr>\n",
       "\t<tr><td>camotes_west1          </td><td>Cabatoan               </td><td>42.5550042             </td></tr>\n",
       "\t<tr><td>camotes_west2          </td><td>Cabatoan               </td><td>57.5651655             </td></tr>\n",
       "\t<tr><td>Caridad Cemetery       </td><td>Cabatoan               </td><td> 3.0328732             </td></tr>\n",
       "\t<tr><td>Caridad Proper         </td><td>Cabatoan               </td><td> 3.7812405             </td></tr>\n",
       "\t<tr><td>cuatras_islas_central  </td><td>Cabatoan               </td><td>39.5449097             </td></tr>\n",
       "\t<tr><td>cuatras_islas_northeast</td><td>Cabatoan               </td><td>35.1442145             </td></tr>\n",
       "\t<tr><td>cuatras_islas_northwest</td><td>Cabatoan               </td><td>36.4198977             </td></tr>\n",
       "\t<tr><td>cuatras_islas_south    </td><td>Cabatoan               </td><td>40.8659979             </td></tr>\n",
       "\t<tr><td>Elementary School      </td><td>Cabatoan               </td><td> 7.7170642             </td></tr>\n",
       "\t<tr><td>Gabas                  </td><td>Cabatoan               </td><td>15.8629348             </td></tr>\n",
       "\t<tr><td>Haina                  </td><td>Cabatoan               </td><td>24.4585460             </td></tr>\n",
       "\t<tr><td>Hicgop South           </td><td>Cabatoan               </td><td> 6.0996424             </td></tr>\n",
       "\t<tr><td>Magbangon              </td><td>Cabatoan               </td><td> 0.2491593             </td></tr>\n",
       "\t<tr><td>near_north_full1       </td><td>Cabatoan               </td><td> 6.2133808             </td></tr>\n",
       "\t<tr><td>near_north_full2       </td><td>Cabatoan               </td><td>10.2063710             </td></tr>\n",
       "\t<tr><td>near_north_full3       </td><td>Cabatoan               </td><td>12.8958210             </td></tr>\n",
       "\t<tr><td>near_south_full1       </td><td>Cabatoan               </td><td>28.2728912             </td></tr>\n",
       "\t<tr><td>near_south_full2       </td><td>Cabatoan               </td><td>31.1047113             </td></tr>\n",
       "\t<tr><td>near_south_full3       </td><td>Cabatoan               </td><td>34.8892299             </td></tr>\n",
       "\t<tr><td>Palanas                </td><td>Cabatoan               </td><td> 2.6540921             </td></tr>\n",
       "\t<tr><td>Poroc Rose             </td><td>Cabatoan               </td><td>12.7521560             </td></tr>\n",
       "\t<tr><td>Poroc San Flower       </td><td>Cabatoan               </td><td>11.9430714             </td></tr>\n",
       "\t<tr><td>San Agustin            </td><td>Cabatoan               </td><td>11.3862533             </td></tr>\n",
       "\t<tr><td>Sitio Baybayon         </td><td>Cabatoan               </td><td>24.7874862             </td></tr>\n",
       "\t<tr><td>Sitio Lonas            </td><td>Cabatoan               </td><td>10.8525552             </td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>camotes_east2          </td><td>Wangag                 </td><td>28.1388738             </td></tr>\n",
       "\t<tr><td>camotes_west1          </td><td>Wangag                 </td><td>42.1692446             </td></tr>\n",
       "\t<tr><td>camotes_west2          </td><td>Wangag                 </td><td>57.3421487             </td></tr>\n",
       "\t<tr><td>Caridad Cemetery       </td><td>Wangag                 </td><td> 5.1471170             </td></tr>\n",
       "\t<tr><td>Caridad Proper         </td><td>Wangag                 </td><td> 5.9014240             </td></tr>\n",
       "\t<tr><td>cuatras_islas_central  </td><td>Wangag                 </td><td>41.0485538             </td></tr>\n",
       "\t<tr><td>cuatras_islas_northeast</td><td>Wangag                 </td><td>36.5673271             </td></tr>\n",
       "\t<tr><td>cuatras_islas_northwest</td><td>Wangag                 </td><td>37.7441889             </td></tr>\n",
       "\t<tr><td>cuatras_islas_south    </td><td>Wangag                 </td><td>42.3820949             </td></tr>\n",
       "\t<tr><td>Elementary School      </td><td>Wangag                 </td><td> 9.8446575             </td></tr>\n",
       "\t<tr><td>Gabas                  </td><td>Wangag                 </td><td>17.9621025             </td></tr>\n",
       "\t<tr><td>Haina                  </td><td>Wangag                 </td><td>26.4270338             </td></tr>\n",
       "\t<tr><td>Hicgop South           </td><td>Wangag                 </td><td> 8.2246965             </td></tr>\n",
       "\t<tr><td>Magbangon              </td><td>Wangag                 </td><td> 1.8840396             </td></tr>\n",
       "\t<tr><td>near_north_full1       </td><td>Wangag                 </td><td> 4.1384768             </td></tr>\n",
       "\t<tr><td>near_north_full2       </td><td>Wangag                 </td><td> 8.1181992             </td></tr>\n",
       "\t<tr><td>near_north_full3       </td><td>Wangag                 </td><td>10.7683163             </td></tr>\n",
       "\t<tr><td>near_south_full1       </td><td>Wangag                 </td><td>30.1597827             </td></tr>\n",
       "\t<tr><td>near_south_full2       </td><td>Wangag                 </td><td>32.9680426             </td></tr>\n",
       "\t<tr><td>near_south_full3       </td><td>Wangag                 </td><td>36.7356596             </td></tr>\n",
       "\t<tr><td>Palanas                </td><td>Wangag                 </td><td> 0.5403139             </td></tr>\n",
       "\t<tr><td>Poroc Rose             </td><td>Wangag                 </td><td>14.8651598             </td></tr>\n",
       "\t<tr><td>Poroc San Flower       </td><td>Wangag                 </td><td>14.0641495             </td></tr>\n",
       "\t<tr><td>San Agustin            </td><td>Wangag                 </td><td>13.5090937             </td></tr>\n",
       "\t<tr><td>Sitio Baybayon         </td><td>Wangag                 </td><td>26.7319570             </td></tr>\n",
       "\t<tr><td>Sitio Lonas            </td><td>Wangag                 </td><td>12.9782678             </td></tr>\n",
       "\t<tr><td>Sitio Tugas            </td><td>Wangag                 </td><td> 9.0863667             </td></tr>\n",
       "\t<tr><td>Tamakin Dacot          </td><td>Wangag                 </td><td>25.2645433             </td></tr>\n",
       "\t<tr><td>Visca                  </td><td>Wangag                 </td><td>16.0183961             </td></tr>\n",
       "\t<tr><td>Wangag                 </td><td>Wangag                 </td><td> 0.0000000             </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " site\\_i & site\\_j & dist\\_km\\\\\n",
       "\\hline\n",
       "\t Cabatoan                & Cabatoan                &  0.0000000             \\\\\n",
       "\t camotes\\_central1        & Cabatoan                  & 30.8887144               \\\\\n",
       "\t camotes\\_central2        & Cabatoan                  & 43.7121318               \\\\\n",
       "\t camotes\\_east1           & Cabatoan                  & 17.9721103               \\\\\n",
       "\t camotes\\_east2           & Cabatoan                  & 28.3601067               \\\\\n",
       "\t camotes\\_west1           & Cabatoan                  & 42.5550042               \\\\\n",
       "\t camotes\\_west2           & Cabatoan                  & 57.5651655               \\\\\n",
       "\t Caridad Cemetery        & Cabatoan                &  3.0328732             \\\\\n",
       "\t Caridad Proper          & Cabatoan                &  3.7812405             \\\\\n",
       "\t cuatras\\_islas\\_central   & Cabatoan                    & 39.5449097                 \\\\\n",
       "\t cuatras\\_islas\\_northeast & Cabatoan                    & 35.1442145                 \\\\\n",
       "\t cuatras\\_islas\\_northwest & Cabatoan                    & 36.4198977                 \\\\\n",
       "\t cuatras\\_islas\\_south     & Cabatoan                    & 40.8659979                 \\\\\n",
       "\t Elementary School       & Cabatoan                &  7.7170642             \\\\\n",
       "\t Gabas                   & Cabatoan                & 15.8629348             \\\\\n",
       "\t Haina                   & Cabatoan                & 24.4585460             \\\\\n",
       "\t Hicgop South            & Cabatoan                &  6.0996424             \\\\\n",
       "\t Magbangon               & Cabatoan                &  0.2491593             \\\\\n",
       "\t near\\_north\\_full1        & Cabatoan                    &  6.2133808                 \\\\\n",
       "\t near\\_north\\_full2        & Cabatoan                    & 10.2063710                 \\\\\n",
       "\t near\\_north\\_full3        & Cabatoan                    & 12.8958210                 \\\\\n",
       "\t near\\_south\\_full1        & Cabatoan                    & 28.2728912                 \\\\\n",
       "\t near\\_south\\_full2        & Cabatoan                    & 31.1047113                 \\\\\n",
       "\t near\\_south\\_full3        & Cabatoan                    & 34.8892299                 \\\\\n",
       "\t Palanas                 & Cabatoan                &  2.6540921             \\\\\n",
       "\t Poroc Rose              & Cabatoan                & 12.7521560             \\\\\n",
       "\t Poroc San Flower        & Cabatoan                & 11.9430714             \\\\\n",
       "\t San Agustin             & Cabatoan                & 11.3862533             \\\\\n",
       "\t Sitio Baybayon          & Cabatoan                & 24.7874862             \\\\\n",
       "\t Sitio Lonas             & Cabatoan                & 10.8525552             \\\\\n",
       "\t ... & ... & ...\\\\\n",
       "\t camotes\\_east2           & Wangag                    & 28.1388738               \\\\\n",
       "\t camotes\\_west1           & Wangag                    & 42.1692446               \\\\\n",
       "\t camotes\\_west2           & Wangag                    & 57.3421487               \\\\\n",
       "\t Caridad Cemetery        & Wangag                  &  5.1471170             \\\\\n",
       "\t Caridad Proper          & Wangag                  &  5.9014240             \\\\\n",
       "\t cuatras\\_islas\\_central   & Wangag                      & 41.0485538                 \\\\\n",
       "\t cuatras\\_islas\\_northeast & Wangag                      & 36.5673271                 \\\\\n",
       "\t cuatras\\_islas\\_northwest & Wangag                      & 37.7441889                 \\\\\n",
       "\t cuatras\\_islas\\_south     & Wangag                      & 42.3820949                 \\\\\n",
       "\t Elementary School       & Wangag                  &  9.8446575             \\\\\n",
       "\t Gabas                   & Wangag                  & 17.9621025             \\\\\n",
       "\t Haina                   & Wangag                  & 26.4270338             \\\\\n",
       "\t Hicgop South            & Wangag                  &  8.2246965             \\\\\n",
       "\t Magbangon               & Wangag                  &  1.8840396             \\\\\n",
       "\t near\\_north\\_full1        & Wangag                      &  4.1384768                 \\\\\n",
       "\t near\\_north\\_full2        & Wangag                      &  8.1181992                 \\\\\n",
       "\t near\\_north\\_full3        & Wangag                      & 10.7683163                 \\\\\n",
       "\t near\\_south\\_full1        & Wangag                      & 30.1597827                 \\\\\n",
       "\t near\\_south\\_full2        & Wangag                      & 32.9680426                 \\\\\n",
       "\t near\\_south\\_full3        & Wangag                      & 36.7356596                 \\\\\n",
       "\t Palanas                 & Wangag                  &  0.5403139             \\\\\n",
       "\t Poroc Rose              & Wangag                  & 14.8651598             \\\\\n",
       "\t Poroc San Flower        & Wangag                  & 14.0641495             \\\\\n",
       "\t San Agustin             & Wangag                  & 13.5090937             \\\\\n",
       "\t Sitio Baybayon          & Wangag                  & 26.7319570             \\\\\n",
       "\t Sitio Lonas             & Wangag                  & 12.9782678             \\\\\n",
       "\t Sitio Tugas             & Wangag                  &  9.0863667             \\\\\n",
       "\t Tamakin Dacot           & Wangag                  & 25.2645433             \\\\\n",
       "\t Visca                   & Wangag                  & 16.0183961             \\\\\n",
       "\t Wangag                  & Wangag                  &  0.0000000             \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| site_i | site_j | dist_km |\n",
       "|---|---|---|\n",
       "| Cabatoan                | Cabatoan                |  0.0000000              |\n",
       "| camotes_central1        | Cabatoan                | 30.8887144              |\n",
       "| camotes_central2        | Cabatoan                | 43.7121318              |\n",
       "| camotes_east1           | Cabatoan                | 17.9721103              |\n",
       "| camotes_east2           | Cabatoan                | 28.3601067              |\n",
       "| camotes_west1           | Cabatoan                | 42.5550042              |\n",
       "| camotes_west2           | Cabatoan                | 57.5651655              |\n",
       "| Caridad Cemetery        | Cabatoan                |  3.0328732              |\n",
       "| Caridad Proper          | Cabatoan                |  3.7812405              |\n",
       "| cuatras_islas_central   | Cabatoan                | 39.5449097              |\n",
       "| cuatras_islas_northeast | Cabatoan                | 35.1442145              |\n",
       "| cuatras_islas_northwest | Cabatoan                | 36.4198977              |\n",
       "| cuatras_islas_south     | Cabatoan                | 40.8659979              |\n",
       "| Elementary School       | Cabatoan                |  7.7170642              |\n",
       "| Gabas                   | Cabatoan                | 15.8629348              |\n",
       "| Haina                   | Cabatoan                | 24.4585460              |\n",
       "| Hicgop South            | Cabatoan                |  6.0996424              |\n",
       "| Magbangon               | Cabatoan                |  0.2491593              |\n",
       "| near_north_full1        | Cabatoan                |  6.2133808              |\n",
       "| near_north_full2        | Cabatoan                | 10.2063710              |\n",
       "| near_north_full3        | Cabatoan                | 12.8958210              |\n",
       "| near_south_full1        | Cabatoan                | 28.2728912              |\n",
       "| near_south_full2        | Cabatoan                | 31.1047113              |\n",
       "| near_south_full3        | Cabatoan                | 34.8892299              |\n",
       "| Palanas                 | Cabatoan                |  2.6540921              |\n",
       "| Poroc Rose              | Cabatoan                | 12.7521560              |\n",
       "| Poroc San Flower        | Cabatoan                | 11.9430714              |\n",
       "| San Agustin             | Cabatoan                | 11.3862533              |\n",
       "| Sitio Baybayon          | Cabatoan                | 24.7874862              |\n",
       "| Sitio Lonas             | Cabatoan                | 10.8525552              |\n",
       "| ... | ... | ... |\n",
       "| camotes_east2           | Wangag                  | 28.1388738              |\n",
       "| camotes_west1           | Wangag                  | 42.1692446              |\n",
       "| camotes_west2           | Wangag                  | 57.3421487              |\n",
       "| Caridad Cemetery        | Wangag                  |  5.1471170              |\n",
       "| Caridad Proper          | Wangag                  |  5.9014240              |\n",
       "| cuatras_islas_central   | Wangag                  | 41.0485538              |\n",
       "| cuatras_islas_northeast | Wangag                  | 36.5673271              |\n",
       "| cuatras_islas_northwest | Wangag                  | 37.7441889              |\n",
       "| cuatras_islas_south     | Wangag                  | 42.3820949              |\n",
       "| Elementary School       | Wangag                  |  9.8446575              |\n",
       "| Gabas                   | Wangag                  | 17.9621025              |\n",
       "| Haina                   | Wangag                  | 26.4270338              |\n",
       "| Hicgop South            | Wangag                  |  8.2246965              |\n",
       "| Magbangon               | Wangag                  |  1.8840396              |\n",
       "| near_north_full1        | Wangag                  |  4.1384768              |\n",
       "| near_north_full2        | Wangag                  |  8.1181992              |\n",
       "| near_north_full3        | Wangag                  | 10.7683163              |\n",
       "| near_south_full1        | Wangag                  | 30.1597827              |\n",
       "| near_south_full2        | Wangag                  | 32.9680426              |\n",
       "| near_south_full3        | Wangag                  | 36.7356596              |\n",
       "| Palanas                 | Wangag                  |  0.5403139              |\n",
       "| Poroc Rose              | Wangag                  | 14.8651598              |\n",
       "| Poroc San Flower        | Wangag                  | 14.0641495              |\n",
       "| San Agustin             | Wangag                  | 13.5090937              |\n",
       "| Sitio Baybayon          | Wangag                  | 26.7319570              |\n",
       "| Sitio Lonas             | Wangag                  | 12.9782678              |\n",
       "| Sitio Tugas             | Wangag                  |  9.0863667              |\n",
       "| Tamakin Dacot           | Wangag                  | 25.2645433              |\n",
       "| Visca                   | Wangag                  | 16.0183961              |\n",
       "| Wangag                  | Wangag                  |  0.0000000              |\n",
       "\n"
      ],
      "text/plain": [
       "     site_i                  site_j   dist_km   \n",
       "1    Cabatoan                Cabatoan  0.0000000\n",
       "2    camotes_central1        Cabatoan 30.8887144\n",
       "3    camotes_central2        Cabatoan 43.7121318\n",
       "4    camotes_east1           Cabatoan 17.9721103\n",
       "5    camotes_east2           Cabatoan 28.3601067\n",
       "6    camotes_west1           Cabatoan 42.5550042\n",
       "7    camotes_west2           Cabatoan 57.5651655\n",
       "8    Caridad Cemetery        Cabatoan  3.0328732\n",
       "9    Caridad Proper          Cabatoan  3.7812405\n",
       "10   cuatras_islas_central   Cabatoan 39.5449097\n",
       "11   cuatras_islas_northeast Cabatoan 35.1442145\n",
       "12   cuatras_islas_northwest Cabatoan 36.4198977\n",
       "13   cuatras_islas_south     Cabatoan 40.8659979\n",
       "14   Elementary School       Cabatoan  7.7170642\n",
       "15   Gabas                   Cabatoan 15.8629348\n",
       "16   Haina                   Cabatoan 24.4585460\n",
       "17   Hicgop South            Cabatoan  6.0996424\n",
       "18   Magbangon               Cabatoan  0.2491593\n",
       "19   near_north_full1        Cabatoan  6.2133808\n",
       "20   near_north_full2        Cabatoan 10.2063710\n",
       "21   near_north_full3        Cabatoan 12.8958210\n",
       "22   near_south_full1        Cabatoan 28.2728912\n",
       "23   near_south_full2        Cabatoan 31.1047113\n",
       "24   near_south_full3        Cabatoan 34.8892299\n",
       "25   Palanas                 Cabatoan  2.6540921\n",
       "26   Poroc Rose              Cabatoan 12.7521560\n",
       "27   Poroc San Flower        Cabatoan 11.9430714\n",
       "28   San Agustin             Cabatoan 11.3862533\n",
       "29   Sitio Baybayon          Cabatoan 24.7874862\n",
       "30   Sitio Lonas             Cabatoan 10.8525552\n",
       "...  ...                     ...      ...       \n",
       "1127 camotes_east2           Wangag   28.1388738\n",
       "1128 camotes_west1           Wangag   42.1692446\n",
       "1129 camotes_west2           Wangag   57.3421487\n",
       "1130 Caridad Cemetery        Wangag    5.1471170\n",
       "1131 Caridad Proper          Wangag    5.9014240\n",
       "1132 cuatras_islas_central   Wangag   41.0485538\n",
       "1133 cuatras_islas_northeast Wangag   36.5673271\n",
       "1134 cuatras_islas_northwest Wangag   37.7441889\n",
       "1135 cuatras_islas_south     Wangag   42.3820949\n",
       "1136 Elementary School       Wangag    9.8446575\n",
       "1137 Gabas                   Wangag   17.9621025\n",
       "1138 Haina                   Wangag   26.4270338\n",
       "1139 Hicgop South            Wangag    8.2246965\n",
       "1140 Magbangon               Wangag    1.8840396\n",
       "1141 near_north_full1        Wangag    4.1384768\n",
       "1142 near_north_full2        Wangag    8.1181992\n",
       "1143 near_north_full3        Wangag   10.7683163\n",
       "1144 near_south_full1        Wangag   30.1597827\n",
       "1145 near_south_full2        Wangag   32.9680426\n",
       "1146 near_south_full3        Wangag   36.7356596\n",
       "1147 Palanas                 Wangag    0.5403139\n",
       "1148 Poroc Rose              Wangag   14.8651598\n",
       "1149 Poroc San Flower        Wangag   14.0641495\n",
       "1150 San Agustin             Wangag   13.5090937\n",
       "1151 Sitio Baybayon          Wangag   26.7319570\n",
       "1152 Sitio Lonas             Wangag   12.9782678\n",
       "1153 Sitio Tugas             Wangag    9.0863667\n",
       "1154 Tamakin Dacot           Wangag   25.2645433\n",
       "1155 Visca                   Wangag   16.0183961\n",
       "1156 Wangag                  Wangag    0.0000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check that the distance and area matrixes line up with the correct site ids\n",
    "library(fields)\n",
    "#centroids\n",
    "Area <- read.csv(\"~/oceanography/empirical_data/site_area_header_nonsurveyed_simulation_kernels.csv\", header=TRUE, stringsAsFactors = F) %>%\n",
    "    arrange(site) %>%\n",
    "    filter(site %!in% c(\"near_north_full1\", \"near_north_full2\", \"near_north_full3\", \"near_south_full1\", \"near_south_full2\", \"near_south_full3\")) %>%\n",
    "    mutate(kmsq=msq*10^-6)\n",
    "not_matching <- which(Area$site!=centroids$site, arr.ind = T)\n",
    "Area[not_matching,] #the near north/south rows won't match because their site ids are worded differently but that's fine\n",
    "\n",
    "##calculate the distance from all potential parents and all potential offspring\n",
    "all_possible_dists <- (distm(sites_source[,c('lon','lat')], sites_source[,c('lon','lat')], fun=distVincentyEllipsoid))\n",
    "all_possible_dists <- as.data.frame(dist_mat_m*10^-3)\n",
    "\n",
    "##attach the sample_ids to each distance, so you can also get site and year\n",
    "colnames(all_possible_dists) <- centroids$site\n",
    "all_possible_dists$site_i <- centroids$site\n",
    "\n",
    "##gather into tidy df\n",
    "all_possible_dists_tidy <- all_possible_dists %>%\n",
    "    dplyr::select(site_i, everything()) %>%\n",
    "    gather(2:35, key=site_j, value=dist_km) \n",
    "(all_possible_dists_tidy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>row</th><th scope=col>col</th></tr></thead>\n",
       "<tbody>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " row & col\\\\\n",
       "\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| row | col |\n",
       "|---|---|\n",
       "\n"
      ],
      "text/plain": [
       "     row col"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "which(t(all_possible_dists_tidy2$dist_km)-t(all_possible_dists_tidy$dist_km)>0.3, arr.ind = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Haina</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "\t<tr><td>TRUE</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       " Haina\\\\\n",
       "\\hline\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\t TRUE\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Haina |\n",
       "|---|\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "| TRUE |\n",
       "\n"
      ],
      "text/plain": [
       "      Haina\n",
       " [1,] TRUE \n",
       " [2,] TRUE \n",
       " [3,] TRUE \n",
       " [4,] TRUE \n",
       " [5,] TRUE \n",
       " [6,] TRUE \n",
       " [7,] TRUE \n",
       " [8,] TRUE \n",
       " [9,] TRUE \n",
       "[10,] TRUE \n",
       "[11,] TRUE \n",
       "[12,] TRUE \n",
       "[13,] TRUE \n",
       "[14,] TRUE \n",
       "[15,] TRUE \n",
       "[16,] TRUE \n",
       "[17,] TRUE \n",
       "[18,] TRUE \n",
       "[19,] TRUE \n",
       "[20,] TRUE \n",
       "[21,] TRUE \n",
       "[22,] TRUE \n",
       "[23,] TRUE \n",
       "[24,] TRUE \n",
       "[25,] TRUE \n",
       "[26,] TRUE \n",
       "[27,] TRUE \n",
       "[28,] TRUE \n",
       "[29,] TRUE \n",
       "[30,] TRUE \n",
       "[31,] TRUE \n",
       "[32,] TRUE \n",
       "[33,] TRUE \n",
       "[34,] TRUE "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>site</th><th scope=col>index</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Haina</td><td>16   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " site & index\\\\\n",
       "\\hline\n",
       "\t Haina & 16   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| site | index |\n",
       "|---|---|\n",
       "| Haina | 16    |\n",
       "\n"
      ],
      "text/plain": [
       "  site  index\n",
       "1 Haina 16   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "as.matrix((all_possible_dists %>% select(Haina)))==as.matrix(Distances[,16]) #all true, so yes it looks like this code works fine\n",
    "#does the index number match up?\n",
    "AllSites %>% filter(index==16) #yes, all fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "18"
      ],
      "text/latex": [
       "18"
      ],
      "text/markdown": [
       "18"
      ],
      "text/plain": [
       "[1] 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "11"
      ],
      "text/latex": [
       "11"
      ],
      "text/markdown": [
       "11"
      ],
      "text/plain": [
       "[1] 11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#what is going on with 2014??\n",
    "nrow(PropSamp %>% filter(end_year==\"2014\") %>% select(site))\n",
    "nrow(PropSamp %>% filter(end_year==\"2014\")%>% filter(PropSamp > 0) %>% select(site))\n",
    "nrow(N_gen_offs_annual %>% filter(year==\"2014\") %>% select(site))\n",
    "nrow(AnnualRecsSamp %>% filter(year==\"2014\") %>% select(site))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>site</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Caridad Cemetery </td></tr>\n",
       "\t<tr><td>Caridad Proper   </td></tr>\n",
       "\t<tr><td>Elementary School</td></tr>\n",
       "\t<tr><td>Hicgop South     </td></tr>\n",
       "\t<tr><td>Magbangon        </td></tr>\n",
       "\t<tr><td>San Agustin      </td></tr>\n",
       "\t<tr><td>Sitio Lonas      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       " site\\\\\n",
       "\\hline\n",
       "\t Caridad Cemetery \\\\\n",
       "\t Caridad Proper   \\\\\n",
       "\t Elementary School\\\\\n",
       "\t Hicgop South     \\\\\n",
       "\t Magbangon        \\\\\n",
       "\t San Agustin      \\\\\n",
       "\t Sitio Lonas      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| site |\n",
       "|---|\n",
       "| Caridad Cemetery  |\n",
       "| Caridad Proper    |\n",
       "| Elementary School |\n",
       "| Hicgop South      |\n",
       "| Magbangon         |\n",
       "| San Agustin       |\n",
       "| Sitio Lonas       |\n",
       "\n"
      ],
      "text/plain": [
       "  site             \n",
       "1 Caridad Cemetery \n",
       "2 Caridad Proper   \n",
       "3 Elementary School\n",
       "4 Hicgop South     \n",
       "5 Magbangon        \n",
       "6 San Agustin      \n",
       "7 Sitio Lonas      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#what are the sites in 2014 that we surveyed but didn't get recruits at?\n",
    "SitesRec <- (N_gen_offs_annual %>% filter(year==\"2014\") %>% select(site))\n",
    "SitesSurv <- PropSamp %>% filter(end_year==\"2014\")%>% filter(PropSamp > 0) %>% select(site)\n",
    "SitesSurv %>% filter(site %!in% SitesRec$site)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "18"
      ],
      "text/latex": [
       "18"
      ],
      "text/markdown": [
       "18"
      ],
      "text/plain": [
       "[1] 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "9"
      ],
      "text/latex": [
       "9"
      ],
      "text/markdown": [
       "9"
      ],
      "text/plain": [
       "[1] 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "9"
      ],
      "text/latex": [
       "9"
      ],
      "text/markdown": [
       "9"
      ],
      "text/plain": [
       "[1] 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "9"
      ],
      "text/latex": [
       "9"
      ],
      "text/markdown": [
       "9"
      ],
      "text/plain": [
       "[1] 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(PropSamp %>% filter(end_year==\"2012\") %>% select(site))\n",
    "nrow(PropSamp %>% filter(end_year==\"2012\") %>% filter(PropSamp > 0) %>% select(site))\n",
    "nrow(N_gen_offs_annual %>% filter(year==\"2012\") %>% select(site))\n",
    "nrow(AnnualRecsSamp %>% filter(year==\"2012\") %>% select(site))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "18"
      ],
      "text/latex": [
       "18"
      ],
      "text/markdown": [
       "18"
      ],
      "text/plain": [
       "[1] 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "15"
      ],
      "text/latex": [
       "15"
      ],
      "text/markdown": [
       "15"
      ],
      "text/plain": [
       "[1] 15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(PropSamp %>% filter(end_year==\"2013\") %>% select(site))\n",
    "nrow(PropSamp %>% filter(end_year==\"2013\")%>% filter(PropSamp > 0) %>% select(site) )\n",
    "nrow(N_gen_offs_annual %>% filter(year==\"2013\") %>% select(site))\n",
    "nrow(AnnualRecsSamp %>% filter(year==\"2013\") %>% select(site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "mle2(minuslogl = LL_kt_bbmle, start = list(k = -2.51, theta = 1.5), \n",
       "    method = \"L-BFGS-B\", data = x, lower = c(-10, 0.15), upper = c(10, \n",
       "        8), control = list(maxit = 500))\n",
       "\n",
       "Coefficients:\n",
       "         k      theta \n",
       "-1.4347062  0.6571524 \n",
       "\n",
       "Log-likelihood: -16.03 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "9.85594492201658"
      ],
      "text/latex": [
       "9.85594492201658"
      ],
      "text/markdown": [
       "9.85594492201658"
      ],
      "text/plain": [
       "[1] 9.855945"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "Sim2012Fit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-2.51, theta=1.5), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "Sim2012Fit\n",
    "\n",
    "BestK2012 <- as.numeric(coef(Sim2012Fit)[1])\n",
    "BestTheta2012 <- as.numeric(coef(Sim2012Fit)[2])\n",
    "\n",
    "SimMDD2012 <- cubintegrate(integrate_kernel_sum1, lower = 0, upper = Inf, k=BestK2012, theta=BestTheta2012, , method = \"pcubature\")$integral\n",
    "SimMDD2012\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 20.23442 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#awesome! it works! let's rip with a 100 iteration for loop\n",
    "col <- c(\"year\", \"k\", \"theta\", \"mdd\", \"med\", \"dist90\", \"iteration\")\n",
    "SimulatedKernels2012 <- as.data.frame(matrix(nrow=0, ncol=7), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernels2012) <- col\n",
    "\n",
    "#don't print warnings for this loop, they are only for setting row names in a tibble which is depracated. But it works. \n",
    "options(warn=-1)\n",
    "\n",
    "pb <- txtProgressBar(min = 0, max = 100, style = 3)\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "for(n in 1:100){\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    #make an empty dataframe with the same columns as original, this will be sampled particles\n",
    "    SimulatedSampling2012 = Simulation2012[FALSE,]\n",
    "    \n",
    "    for(i in 1:nrow(NGenOffs2012)){ \n",
    "        \n",
    "        destination_eval <- as.character(NGenOffs2012$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- Simulation2012SurvGrowth %>% #USING DF WITH SURV/SIZE WEIGHTING ***SurvGrowth\n",
    "                                filter(destination==destination_eval) %>%\n",
    "                                sample_n(as.numeric(NGenOffs2012$n_offs_gen[i]),  replace=F) %>% #weight=SurvivalWeightLin,, sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "                                select(one_of(names(Simulation2012)))#keep matching columns with the original df instead of carrying over the columns used for survival weighting\n",
    "        \n",
    "        SimulatedSampling2012 <- bind_rows(SimulatedSampling2012, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "    \n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSampling2012 <- SimulatedSampling2012 %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSampling2012)==sum(NGenOffs2012$n_offs_gen) #should be TRUE\n",
    "    \n",
    "    #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>%\n",
    "        filter(Year==\"2012\") %>%\n",
    "        select(NumParentageMatches))\n",
    "    \n",
    "    SimulatedSampling2012Par <- SimulatedSampling2012 %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% NGenOffs2012$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSampling2012_2 <- anti_join((SimulatedSampling2012 %>% ungroup()), SimulatedSampling2012Par, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSampling2012_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSampling2012Par3 <- bind_rows(SimulatedSampling2012Par, SimulatedSampling2012_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSamp2012 <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2012\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSamp2012$destination <- PropSamp2012$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSampling2012Par3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in all surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSamp2012, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSampling2012Par3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummary2012 <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finally, join all of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for all sites\n",
    "                PropSamp2012 <- PropSamp2012 %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSamp2012$destination <- PropSamp2012$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSamp2012, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% NGenOffs2012$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummary2012 %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFull2012 <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFull2012) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFull2012\n",
    "    \n",
    "    #NOW FIT THE KERNEL\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "Sim2012Fit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "\n",
    "BestK2012 <- as.numeric(coef(Sim2012Fit)[1])\n",
    "BestTheta2012 <- as.numeric(coef(Sim2012Fit)[2])\n",
    "MDD2012 <- as.numeric(cubintegrate(integrate_kernel_sum1, lower = 0, upper = Inf, k=BestK2012, theta=BestTheta2012, , method = \"pcubature\")$integral)\n",
    "k_eval <- BestK2012\n",
    "theta_eval <- BestTheta2012\n",
    "Med2012  <- round(nleqslv(x = 7, fn = cdf_solve)$x, 2) \n",
    "Dist90_2012 <- round(nleqslv(x = 7, fn = cdf_solve90)$x, 2)\n",
    "    \n",
    "    #store the info in this df\n",
    "    SimulatedKernels2012_beta <- as.data.frame(matrix(nrow=1, ncol=7), stringsAsFactors = FALSE)\n",
    "    colnames(SimulatedKernels2012_beta) <- col\n",
    "    \n",
    "    SimulatedKernels2012_beta$year <- 2012\n",
    "    SimulatedKernels2012_beta$k <- BestK2012\n",
    "    SimulatedKernels2012_beta$theta <- BestTheta2012\n",
    "    SimulatedKernels2012_beta$mdd <- MDD2012\n",
    "    SimulatedKernels2012_beta$med <- Med2012\n",
    "    SimulatedKernels2012_beta$dist90 <- Dist90_2012\n",
    "    SimulatedKernels2012_beta$iteration <- n\n",
    "    \n",
    "    \n",
    "#join results into larger df\n",
    "SimulatedKernels2012 <- bind_rows(SimulatedKernels2012, SimulatedKernels2012_beta)\n",
    "    \n",
    "setTxtProgressBar(pb, n)\n",
    "\n",
    "\n",
    "}\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "options(warn=0) #turn warnings back on\n",
    "\n",
    "\n",
    "write.csv(SimulatedKernels2012, file=\"~/oceanography/script_output/KernelFits/100SimulatedKernels2012Growth.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 9.855328 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 14.26825 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 11.84184 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#re-do ensembles with only the sampling correction\n",
    "#awesome! it works! let's rip with a 100 iteration for loop\n",
    "col <- c(\"year\", \"k\", \"theta\", \"mdd\", \"med\", \"dist90\", \"iteration\")\n",
    "\n",
    "#awesome! it works! let's rip with a 100 iteration for loop\n",
    "col <- c(\"year\", \"k\", \"theta\", \"mdd\", \"med\", \"dist90\", \"iteration\")\n",
    "SimulatedKernels2012 <- as.data.frame(matrix(nrow=0, ncol=7), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernels2012) <- col\n",
    "\n",
    "#don't print warnings for this loop, they are only for setting row names in a tibble which is depracated. But it works. \n",
    "options(warn=-1)\n",
    "\n",
    "pb <- txtProgressBar(min = 0, max = 100, style = 3)\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "for(n in 1:100){\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    #make an empty dataframe with the same columns as original, this will be sampled particles\n",
    "    SimulatedSampling2012 = Simulation2012[FALSE,]\n",
    "    \n",
    "    for(i in 1:nrow(NGenOffs2012)){ \n",
    "        \n",
    "        destination_eval <- as.character(NGenOffs2012$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- Simulation2012SurvGrowth %>% #USING DF WITH SURV/SIZE WEIGHTING ***SurvGrowth\n",
    "                                filter(destination==destination_eval) %>%\n",
    "                                sample_n(as.numeric(NGenOffs2012$n_offs_gen[i]),  replace=F) %>% #weight=SurvivalWeightLin,, sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "                                select(one_of(names(Simulation2012)))#keep matching columns with the original df instead of carrying over the columns used for survival weighting\n",
    "        \n",
    "        SimulatedSampling2012 <- bind_rows(SimulatedSampling2012, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "    \n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSampling2012 <- SimulatedSampling2012 %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSampling2012)==sum(NGenOffs2012$n_offs_gen) #should be TRUE\n",
    "    \n",
    "    #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>%\n",
    "        filter(Year==\"2012\") %>%\n",
    "        select(NumParentageMatches))\n",
    "    \n",
    "    SimulatedSampling2012Par <- SimulatedSampling2012 %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% NGenOffs2012$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSampling2012_2 <- anti_join((SimulatedSampling2012 %>% ungroup()), SimulatedSampling2012Par, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSampling2012_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSampling2012Par3 <- bind_rows(SimulatedSampling2012Par, SimulatedSampling2012_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSamp2012 <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2012\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSamp2012$destination <- PropSamp2012$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSampling2012Par3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in all surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSamp2012, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSampling2012Par3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummary2012 <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finally, join all of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for all sites\n",
    "                PropSamp2012 <- PropSamp2012 %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSamp2012$destination <- PropSamp2012$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSamp2012, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% NGenOffs2012$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummary2012 %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFull2012 <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFull2012) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFull2012\n",
    "    \n",
    "    #NOW FIT THE KERNEL\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "Sim2012Fit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "\n",
    "BestK2012 <- as.numeric(coef(Sim2012Fit)[1])\n",
    "BestTheta2012 <- as.numeric(coef(Sim2012Fit)[2])\n",
    "MDD2012 <- as.numeric(cubintegrate(integrate_kernel_sum1, lower = 0, upper = Inf, k=BestK2012, theta=BestTheta2012, , method = \"pcubature\")$integral)\n",
    "k_eval <- BestK2012\n",
    "theta_eval <- BestTheta2012\n",
    "Med2012  <- round(nleqslv(x = 7, fn = cdf_solve)$x, 2) \n",
    "Dist90_2012 <- round(nleqslv(x = 7, fn = cdf_solve90)$x, 2)\n",
    "    \n",
    "    #store the info in this df\n",
    "    SimulatedKernels2012_beta <- as.data.frame(matrix(nrow=1, ncol=7), stringsAsFactors = FALSE)\n",
    "    colnames(SimulatedKernels2012_beta) <- col\n",
    "    \n",
    "    SimulatedKernels2012_beta$year <- 2012\n",
    "    SimulatedKernels2012_beta$k <- BestK2012\n",
    "    SimulatedKernels2012_beta$theta <- BestTheta2012\n",
    "    SimulatedKernels2012_beta$mdd <- MDD2012\n",
    "    SimulatedKernels2012_beta$med <- Med2012\n",
    "    SimulatedKernels2012_beta$dist90 <- Dist90_2012\n",
    "    SimulatedKernels2012_beta$iteration <- n\n",
    "    \n",
    "    \n",
    "#join results into larger df\n",
    "SimulatedKernels2012 <- bind_rows(SimulatedKernels2012, SimulatedKernels2012_beta)\n",
    "    \n",
    "setTxtProgressBar(pb, n)\n",
    "\n",
    "\n",
    "}\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "options(warn=0) #turn warnings back on\n",
    "\n",
    "\n",
    "write.csv(SimulatedKernels2012, file=\"~/oceanography/script_output/KernelFits/100SimulatedKernels2012Growth.csv\", row.names=F)\n",
    "SimulatedKernels2013 <- as.data.frame(matrix(nrow=0, ncol=7), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernels2013) <- col\n",
    "\n",
    "#don't print warnings for this loop, they are only for setting row names in a tibble which is depracated. But it works. \n",
    "options(warn=-1)\n",
    "\n",
    "pb <- txtProgressBar(min = 0, max = 100, style = 3)\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "for(n in 1:100){\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    #make an empty dataframe with the same columns as original, this will be sampled particles\n",
    "    SimulatedSampling2013 = Simulation2013[FALSE,]\n",
    "    \n",
    "    for(i in 1:nrow(NGenOffs2013)){ \n",
    "        \n",
    "        destination_eval <- as.character(NGenOffs2013$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- Simulation2013SurvGrowth %>% #USING DF WITH SURV/SIZE WEIGHTING ***SurvGrowth\n",
    "                                filter(destination==destination_eval) %>%\n",
    "                                sample_n(as.numeric(NGenOffs2013$n_offs_gen[i]),  replace=F) %>% #weight=SurvivalWeightLin,, sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "                                select(one_of(names(Simulation2013)))#keep matching columns with the original df instead of carrying over the columns used for survival weighting\n",
    "        \n",
    "        SimulatedSampling2013 <- bind_rows(SimulatedSampling2013, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "    \n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSampling2013 <- SimulatedSampling2013 %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSampling2013)==sum(NGenOffs2013$n_offs_gen) #should be TRUE\n",
    "    \n",
    "    #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>%\n",
    "        filter(Year==\"2013\") %>%\n",
    "        select(NumParentageMatches))\n",
    "    \n",
    "    SimulatedSampling2013Par <- SimulatedSampling2013 %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% NGenOffs2013$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSampling2013_2 <- anti_join((SimulatedSampling2013 %>% ungroup()), SimulatedSampling2013Par, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSampling2013_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSampling2013Par3 <- bind_rows(SimulatedSampling2013Par, SimulatedSampling2013_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSamp2013 <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2013\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSamp2013$destination <- PropSamp2013$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSampling2013Par3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in all surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSamp2013, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSampling2013Par3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummary2013 <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finally, join all of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for all sites\n",
    "                PropSamp2013 <- PropSamp2013 %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSamp2013$destination <- PropSamp2013$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSamp2013, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% NGenOffs2013$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummary2013 %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFull2013 <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFull2013) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFull2013\n",
    "    \n",
    "    #NOW FIT THE KERNEL\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "Sim2013Fit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "\n",
    "BestK2013 <- as.numeric(coef(Sim2013Fit)[1])\n",
    "BestTheta2013 <- as.numeric(coef(Sim2013Fit)[2])\n",
    "MDD2013 <- as.numeric(cubintegrate(integrate_kernel_sum1, lower = 0, upper = Inf, k=BestK2013, theta=BestTheta2013, , method = \"pcubature\")$integral)\n",
    "k_eval <- BestK2013\n",
    "theta_eval <- BestTheta2013\n",
    "Med2013  <- round(nleqslv(x = 7, fn = cdf_solve)$x, 2) \n",
    "Dist90_2013 <- round(nleqslv(x = 7, fn = cdf_solve90)$x, 2)\n",
    "    \n",
    "    #store the info in this df\n",
    "    SimulatedKernels2013_beta <- as.data.frame(matrix(nrow=1, ncol=7), stringsAsFactors = FALSE)\n",
    "    colnames(SimulatedKernels2013_beta) <- col\n",
    "    \n",
    "    SimulatedKernels2013_beta$year <- 2013\n",
    "    SimulatedKernels2013_beta$k <- BestK2013\n",
    "    SimulatedKernels2013_beta$theta <- BestTheta2013\n",
    "    SimulatedKernels2013_beta$mdd <- MDD2013\n",
    "    SimulatedKernels2013_beta$med <- Med2013\n",
    "    SimulatedKernels2013_beta$dist90 <- Dist90_2013\n",
    "    SimulatedKernels2013_beta$iteration <- n\n",
    "    \n",
    "    \n",
    "#join results into larger df\n",
    "SimulatedKernels2013 <- bind_rows(SimulatedKernels2013, SimulatedKernels2013_beta)\n",
    "    \n",
    "setTxtProgressBar(pb, n)\n",
    "\n",
    "\n",
    "}\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "options(warn=0) #turn warnings back on\n",
    "\n",
    "\n",
    "write.csv(SimulatedKernels2013, file=\"~/oceanography/script_output/KernelFits/100SimulatedKernels2013Growth.csv\", row.names=F)\n",
    "\n",
    "SimulatedKernels2014 <- as.data.frame(matrix(nrow=0, ncol=7), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernels2014) <- col\n",
    "\n",
    "#don't print warnings for this loop, they are only for setting row names in a tibble which is depracated. But it works. \n",
    "options(warn=-1)\n",
    "\n",
    "pb <- txtProgressBar(min = 0, max = 100, style = 3)\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "for(n in 1:100){\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    #make an empty dataframe with the same columns as original, this will be sampled particles\n",
    "    SimulatedSampling2014 = Simulation2014[FALSE,]\n",
    "    \n",
    "    for(i in 1:nrow(NGenOffs2014)){ \n",
    "        \n",
    "        destination_eval <- as.character(NGenOffs2014$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- Simulation2014SurvGrowth %>% #USING DF WITH SURV/SIZE WEIGHTING ***SurvGrowth\n",
    "                                filter(destination==destination_eval) %>%\n",
    "                                sample_n(as.numeric(NGenOffs2014$n_offs_gen[i]),  replace=F) %>% #weight=SurvivalWeightLin,, sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "                                select(one_of(names(Simulation2014)))#keep matching columns with the original df instead of carrying over the columns used for survival weighting\n",
    "        \n",
    "        SimulatedSampling2014 <- bind_rows(SimulatedSampling2014, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "    \n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSampling2014 <- SimulatedSampling2014 %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSampling2014)==sum(NGenOffs2014$n_offs_gen) #should be TRUE\n",
    "    \n",
    "    #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>%\n",
    "        filter(Year==\"2014\") %>%\n",
    "        select(NumParentageMatches))\n",
    "    \n",
    "    SimulatedSampling2014Par <- SimulatedSampling2014 %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% NGenOffs2014$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSampling2014_2 <- anti_join((SimulatedSampling2014 %>% ungroup()), SimulatedSampling2014Par, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSampling2014_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSampling2014Par3 <- bind_rows(SimulatedSampling2014Par, SimulatedSampling2014_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSamp2014 <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSamp2014$destination <- PropSamp2014$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSampling2014Par3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in all surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSamp2014, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSampling2014Par3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummary2014 <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finally, join all of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for all sites\n",
    "                PropSamp2014 <- PropSamp2014 %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSamp2014$destination <- PropSamp2014$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSamp2014, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% NGenOffs2014$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummary2014 %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFull2014 <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFull2014) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFull2014\n",
    "    \n",
    "    #NOW FIT THE KERNEL\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "Sim2014Fit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "\n",
    "BestK2014 <- as.numeric(coef(Sim2014Fit)[1])\n",
    "BestTheta2014 <- as.numeric(coef(Sim2014Fit)[2])\n",
    "MDD2014 <- as.numeric(cubintegrate(integrate_kernel_sum1, lower = 0, upper = Inf, k=BestK2014, theta=BestTheta2014, , method = \"pcubature\")$integral)\n",
    "k_eval <- BestK2014\n",
    "theta_eval <- BestTheta2014\n",
    "Med2014  <- round(nleqslv(x = 7, fn = cdf_solve)$x, 2) \n",
    "Dist90_2014 <- round(nleqslv(x = 7, fn = cdf_solve90)$x, 2)\n",
    "    \n",
    "    #store the info in this df\n",
    "    SimulatedKernels2014_beta <- as.data.frame(matrix(nrow=1, ncol=7), stringsAsFactors = FALSE)\n",
    "    colnames(SimulatedKernels2014_beta) <- col\n",
    "    \n",
    "    SimulatedKernels2014_beta$year <- 2014\n",
    "    SimulatedKernels2014_beta$k <- BestK2014\n",
    "    SimulatedKernels2014_beta$theta <- BestTheta2014\n",
    "    SimulatedKernels2014_beta$mdd <- MDD2014\n",
    "    SimulatedKernels2014_beta$med <- Med2014\n",
    "    SimulatedKernels2014_beta$dist90 <- Dist90_2014\n",
    "    SimulatedKernels2014_beta$iteration <- n\n",
    "    \n",
    "    \n",
    "#join results into larger df\n",
    "SimulatedKernels2014 <- bind_rows(SimulatedKernels2014, SimulatedKernels2014_beta)\n",
    "    \n",
    "setTxtProgressBar(pb, n)\n",
    "\n",
    "\n",
    "}\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "options(warn=0) #turn warnings back on\n",
    "\n",
    "\n",
    "write.csv(SimulatedKernels2014, file=\"~/oceanography/script_output/KernelFits/100SimulatedKernels2014Growth.csv\", row.names=F)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "394"
      ],
      "text/latex": [
       "394"
      ],
      "text/markdown": [
       "394"
      ],
      "text/plain": [
       "[1] 394"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#combine simulations\n",
    "SimulationAll <- bind_rows(Simulation2012, Simulation2013, Simulation2014)\n",
    "\n",
    "#make a DF of all of the sampled fish over 2012-2014\n",
    "AllYearsRecruits <- AnnualRecsSamp %>% distinct(site, .keep_all = T)\n",
    "sum(AllYearsRecruits$n_offs_gen_all_years) #should be 394 for 2012-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#what if we account for post-settlement mortality and not sampling <3.5 cm recruits?\n",
    "NumDays <- nrow(SimulationAll %>% distinct(date))#200 days in a simulation\n",
    "\n",
    "#make a df with weighted values for the days of the simluation oldest to most recent\n",
    "SimDates <- SimulationAll %>%\n",
    "    distinct(date) %>%\n",
    "    mutate(DateSeq=row_number()) %>% #assign row numbers, so more recent dates are higher than older\n",
    "    mutate(SurvivalWeightExp=exp(DateSeq)) %>% #apply the exponential function to get a survival column\n",
    "    mutate(SurvivalWeightExp=SurvivalWeightExp/max(SurvivalWeightExp))%>%#normalize as a survival \"probability\"\n",
    "    mutate(SurvivalWeightLin=(((0.25/2)/5)*DateSeq)) %>%#maybe a linear survival function (y=mx)is more appropriate (eyeball from Allison's Fig 3C because what the hell why not we're just thinking here)\n",
    "    mutate(SurvivalWeightLin=SurvivalWeightLin/max(SurvivalWeightLin)) #%>%#normalize as a survival \"probability\"\n",
    "    #filter(DateSeq %!in% seq((max(DateSeq)-60), max(DateSeq), 1))#account for the fact that we didn't sample <3.5 cm\n",
    "#the max survival prob will be different depending on when I filter out the more recent recruits. I don't want an artificially high prob of sampling based on a survival prob of 1 so I'm cutting fish out after prob weight calculations\n",
    "SimulationAllSurvGrowth <- left_join(SimulationAll, SimDates, by=\"date\") %>%\n",
    "    filter(DateSeq %!in% seq((max(DateSeq)-60), max(DateSeq), 1))\n",
    "nrow(SimulationAllSurvGrowth)<nrow(SimulationAll)#should be TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "34"
      ],
      "text/latex": [
       "34"
      ],
      "text/markdown": [
       "34"
      ],
      "text/plain": [
       "[1] 34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get together kernel fitting components for all years/seasonal\n",
    "\n",
    "#assemble all of the components for annual kernel fitting\n",
    "centroids <- read.csv(\"~/oceanography/empirical_data/site_centroids_simulation_kernels.csv\", header=TRUE)\n",
    "\n",
    "Area <- read.csv(\"~/oceanography/empirical_data/site_area_header_nonsurveyed_simulation_kernels.csv\", header=TRUE) %>%\n",
    "    arrange(site) %>%\n",
    "    filter(site %!in% c(\"near_north_full1\", \"near_north_full2\", \"near_north_full3\", \"near_south_full1\", \"near_south_full2\", \"near_south_full3\")) %>%\n",
    "    mutate(kmsq=msq*10^-6) %>%\n",
    "    select(kmsq)\n",
    "Reef_sizes <- as.matrix(Area)\n",
    "\n",
    "#give every site in the distance matrix of the simulation (even if we didn't sample there) an index number\n",
    "AllSites <- centroids %>%\n",
    "    select(site) %>%\n",
    "    arrange(site)\n",
    "nrow(AllSites) #should be 34x1\n",
    "AllSites$index <- seq(from=1, to=34, by=1)\n",
    "\n",
    "PropSampAll <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "            filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "            rename(source=\"site\") %>%\n",
    "            select(-end_year, -PropSamp)\n",
    "\n",
    "SampledSitesAll <- inner_join(PropSampAll %>% select(source), AllSites, by=c(source=\"site\")) \n",
    "\n",
    "#check for correct number of rows\n",
    "nrow(SampledSitesAll)==nrow(PropSampAll) #should be true\n",
    "SampledSitesAllIndex <- t(as.matrix(SampledSitesAll$index))\n",
    "ncol(SampledSitesAllIndex)\n",
    "\n",
    "Sampled_reefs <- SampledSitesAllIndex\n",
    "\n",
    "#proportion sampled matrix for kernel fitting\n",
    "\n",
    "Adult_sample_proportions <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                filter(end_year ==\"2014\" & PropSamp > 0) \n",
    "\n",
    "Adult_sample_proportions <- as.matrix(Adult_sample_proportions$PropSamp)\n",
    "nrow(Adult_sample_proportions) \n",
    "\n",
    "#distance matrix using the centroids with combined Magbangon\n",
    "### List of source locations\n",
    "sites_source <- centroids\n",
    "\n",
    "### List of destination locations\n",
    "sites_dest <- centroids\n",
    "\n",
    "dist_mat_m <- distm(sites_source[,c('lon','lat')], sites_source[,c('lon','lat')], fun=distVincentyEllipsoid)\n",
    "Distances <- dist_mat_m*10^-3\n",
    "\n",
    "Centroids <- centroids %>%\n",
    "    select(-site)\n",
    "\n",
    "#for the all years sites sampled in the simulation, it's a total of 16. That's lower than the all year used in kernel fitting because we didn't sample Sitio Tugas or Gabas until after 2014. We also combined the Magbangons, so 19-16=3 accounted for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All of the corresponding simulation years combined (2011-14)\n",
    "\n",
    "col <- c(\"year\", \"k\", \"theta\", \"mdd\", \"med\", \"dist90\", \"iteration\")\n",
    "SimulatedKernelsAll <- as.data.frame(matrix(nrow=0, ncol=7), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernelsAll) <- col\n",
    "\n",
    "#don't print warnings for this loop, they are only for setting row names in a tibble which is depracated. But it works. \n",
    "options(warn=-1)\n",
    "\n",
    "pb <- txtProgressBar(min = 0, max = 100, style = 3)#7 years in each interation\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "\n",
    "for(n in 1:100){\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    SimulatedSamplingAll = SimulationAll[FALSE,]\n",
    "    \n",
    "    for(i in 1:nrow(AllYearsRecruits)){ \n",
    "        \n",
    "        destination_eval <- as.character(AllYearsRecruits$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- SimulationAllSurvGrowth %>%\n",
    "                                    filter(destination==destination_eval) %>%\n",
    "                                    sample_n(as.numeric(AllYearsRecruits$n_offs_gen_all_years[i]), replace=F) #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "        \n",
    "        SimulatedSamplingAll <- bind_rows(SimulatedSamplingAll, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "\n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSamplingAll <- SimulatedSamplingAll %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSamplingAll)==sum(NGenOffsAll$n_offs_gen) #should be TRUE\n",
    "    \n",
    "    #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>% #should be 37 for 2012-2014\n",
    "        filter(Year %in% c(\"2012\", \"2013\", \"2014\")) %>%\n",
    "        select(NumParentageMatches) %>%\n",
    "        summarise(NumParentageMatches=sum(NumParentageMatches)))\n",
    "    \n",
    "    SimulatedSamplingAllPar <- SimulatedSamplingAll %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% NGenOffsAll$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSamplingAll_2 <- anti_join((SimulatedSamplingAll %>% ungroup()), SimulatedSamplingAllPar, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSamplingAll_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSamplingAllPar3 <- bind_rows(SimulatedSamplingAllPar, SimulatedSamplingAll_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSampAll <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSampAll$destination <- PropSampAll$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSamplingAllPar3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in all surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSampAll, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSamplingAllPar3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummaryAll <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finally, join all of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for all sites\n",
    "                PropSampAll <- PropSampAll %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSampAll$destination <- PropSampAll$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSampAll, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% NGenOffsAll$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummaryAll %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFullAll <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFullAll) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFullAll\n",
    "    \n",
    "    #NOW FIT THE KERNEL\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "SimAllFit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "\n",
    "BestKAll <- as.numeric(coef(SimAllFit)[1])\n",
    "BestThetaAll <- as.numeric(coef(SimAllFit)[2])\n",
    "MDDAll <- as.numeric(cubintegrate(integrate_kernel_sum1, lower = 0, upper = Inf, k=BestKAll, theta=BestThetaAll, , method = \"pcubature\")$integral)\n",
    "k_eval <- BestKAll\n",
    "theta_eval <- BestThetaAll\n",
    "MedAll  <- round(nleqslv(x = 7, fn = cdf_solve)$x, 2) \n",
    "Dist90_All <- round(nleqslv(x = 7, fn = cdf_solve90)$x, 2)\n",
    "    \n",
    "    #store the info in this df\n",
    "    SimulatedKernelsAll_beta <- as.data.frame(matrix(nrow=1, ncol=7), stringsAsFactors = FALSE)\n",
    "    colnames(SimulatedKernelsAll_beta) <- col\n",
    "    \n",
    "    SimulatedKernelsAll_beta$year <- NA\n",
    "    SimulatedKernelsAll_beta$k <- BestKAll\n",
    "    SimulatedKernelsAll_beta$theta <- BestThetaAll\n",
    "    SimulatedKernelsAll_beta$med <- MedAll\n",
    "    SimulatedKernelsAll_beta$mdd <- MDDAll\n",
    "    SimulatedKernelsAll_beta$dist90 <- Dist90_All\n",
    "    SimulatedKernelsAll_beta$iteration <- n\n",
    "    \n",
    "    \n",
    "#join results into larger df\n",
    "SimulatedKernelsAll <- bind_rows(SimulatedKernelsAll, SimulatedKernelsAll_beta)\n",
    "    \n",
    "setTxtProgressBar(pb, n)\n",
    "\n",
    "\n",
    "}\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "options(warn=0) #turn warnings back on\n",
    "\n",
    "\n",
    "#write.csv(SimulatedKernelsAll, file=\"~/oceanography/script_output/KernelFits/100SimulatedKernelsAllGrowth.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    SimulatedSamplingAll = SimulationAll[FALSE,]\n",
    "    \n",
    "    for(i in 1:nrow(AllYearsRecruits)){ \n",
    "        \n",
    "        destination_eval <- as.character(AllYearsRecruits$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- SimulationAllSurvGrowth %>%\n",
    "                                    filter(destination==destination_eval) %>%\n",
    "                                    sample_n(as.numeric(AllYearsRecruits$n_offs_gen_all_years[i]), replace=F) #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "        \n",
    "        SimulatedSamplingAll <- bind_rows(SimulatedSamplingAll, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "\n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSamplingAll <- SimulatedSamplingAll %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSamplingAll)==sum(NGenOffsAll$n_offs_gen) #should be TRUE\n",
    "    \n",
    "    #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>% #should be 37 for 2012-2014\n",
    "        filter(Year %in% c(\"2012\", \"2013\", \"2014\")) %>%\n",
    "        select(NumParentageMatches) %>%\n",
    "        summarise(NumParentageMatches=sum(NumParentageMatches)))\n",
    "    \n",
    "    SimulatedSamplingAllPar <- SimulatedSamplingAll %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% NGenOffsAll$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSamplingAll_2 <- anti_join((SimulatedSamplingAll %>% ungroup()), SimulatedSamplingAllPar, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSamplingAll_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSamplingAllPar3 <- bind_rows(SimulatedSamplingAllPar, SimulatedSamplingAll_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSampAll <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSampAll$destination <- PropSampAll$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSamplingAllPar3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in all surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSampAll, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSamplingAllPar3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummaryAll <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finally, join all of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for all sites\n",
    "                PropSampAll <- PropSampAll %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSampAll$destination <- PropSampAll$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSampAll, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% NGenOffsAll$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummaryAll %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFullAll <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFullAll) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFullAll\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>1 </td><td>8 </td><td>9 </td><td>14</td><td>16</td><td>17</td><td>18</td><td>25</td><td>26</td><td>27</td><td>28</td><td>29</td><td>30</td><td>32</td><td>33</td><td>34</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllllllllllllll}\n",
       "\t 1  & 8  & 9  & 14 & 16 & 17 & 18 & 25 & 26 & 27 & 28 & 29 & 30 & 32 & 33 & 34\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 1  | 8  | 9  | 14 | 16 | 17 | 18 | 25 | 26 | 27 | 28 | 29 | 30 | 32 | 33 | 34 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14]\n",
       "[1,] 1    8    9    14   16   17   18   25   26   27    28    29    30    32   \n",
       "     [,15] [,16]\n",
       "[1,] 33    34   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow(Adult_sample_proportions)\n",
    "Sampled_reefs\n",
    "#write.table(Adult_sample_proportions, file=\"~/parentage/kernel_fitting/1340_loci/input/prop_samp_2012-14.csv\", row.names=FALSE, quote=FALSE, col.names=FALSE, sep=\",\")\n",
    "#write.table(Sampled_reefs, file=\"~/parentage/kernel_fitting/1340_loci/input/site_index_2012-14.csv\", row.names=FALSE, quote=FALSE, col.names=FALSE, sep=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>year</th><th scope=col>k</th><th scope=col>theta</th><th scope=col>mdd</th><th scope=col>med</th><th scope=col>dist90</th><th scope=col>iteration</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>NA       </td><td>-2.477364</td><td>1.1883882</td><td>NA       </td><td>7.10     </td><td>21.53    </td><td>1        </td></tr>\n",
       "\t<tr><td>NA       </td><td>-2.435259</td><td>1.2625946</td><td>NA       </td><td>6.53     </td><td>19.23    </td><td>2        </td></tr>\n",
       "\t<tr><td>NA       </td><td>-0.315683</td><td>0.6688679</td><td>NA       </td><td>1.75     </td><td> 7.51    </td><td>3        </td></tr>\n",
       "\t<tr><td>NA       </td><td>-1.814762</td><td>0.7841033</td><td>NA       </td><td>5.84     </td><td>22.47    </td><td>4        </td></tr>\n",
       "\t<tr><td>NA       </td><td>-2.424130</td><td>1.1589185</td><td>NA       </td><td>6.86     </td><td>21.07    </td><td>5        </td></tr>\n",
       "\t<tr><td>NA       </td><td>-1.766098</td><td>0.7476509</td><td>NA       </td><td>6.03     </td><td>23.92    </td><td>6        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       " year & k & theta & mdd & med & dist90 & iteration\\\\\n",
       "\\hline\n",
       "\t NA        & -2.477364 & 1.1883882 & NA        & 7.10      & 21.53     & 1        \\\\\n",
       "\t NA        & -2.435259 & 1.2625946 & NA        & 6.53      & 19.23     & 2        \\\\\n",
       "\t NA        & -0.315683 & 0.6688679 & NA        & 1.75      &  7.51     & 3        \\\\\n",
       "\t NA        & -1.814762 & 0.7841033 & NA        & 5.84      & 22.47     & 4        \\\\\n",
       "\t NA        & -2.424130 & 1.1589185 & NA        & 6.86      & 21.07     & 5        \\\\\n",
       "\t NA        & -1.766098 & 0.7476509 & NA        & 6.03      & 23.92     & 6        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| year | k | theta | mdd | med | dist90 | iteration |\n",
       "|---|---|---|---|---|---|---|\n",
       "| NA        | -2.477364 | 1.1883882 | NA        | 7.10      | 21.53     | 1         |\n",
       "| NA        | -2.435259 | 1.2625946 | NA        | 6.53      | 19.23     | 2         |\n",
       "| NA        | -0.315683 | 0.6688679 | NA        | 1.75      |  7.51     | 3         |\n",
       "| NA        | -1.814762 | 0.7841033 | NA        | 5.84      | 22.47     | 4         |\n",
       "| NA        | -2.424130 | 1.1589185 | NA        | 6.86      | 21.07     | 5         |\n",
       "| NA        | -1.766098 | 0.7476509 | NA        | 6.03      | 23.92     | 6         |\n",
       "\n"
      ],
      "text/plain": [
       "  year k         theta     mdd med  dist90 iteration\n",
       "1 NA   -2.477364 1.1883882 NA  7.10 21.53  1        \n",
       "2 NA   -2.435259 1.2625946 NA  6.53 19.23  2        \n",
       "3 NA   -0.315683 0.6688679 NA  1.75  7.51  3        \n",
       "4 NA   -1.814762 0.7841033 NA  5.84 22.47  4        \n",
       "5 NA   -2.424130 1.1589185 NA  6.86 21.07  5        \n",
       "6 NA   -1.766098 0.7476509 NA  6.03 23.92  6        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(SimulatedKernelsAll)\n",
    "#write.csv(SimulatedKernelsAll, file=\"~/oceanography/script_output/KernelFits/1000SimulatedKernelsAllStoppedEarly.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Seasonal kernel fits__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimulationSWM <- SimulationAllSurvGrowth %>% #filter by the growth surv adjusted df otherwise\n",
    "    filter(SimMonsoon==\"SWM\")\n",
    "SimulationNEM <- SimulationAllSurvGrowth %>%\n",
    "    filter(SimMonsoon==\"NEM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 10.43739 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SWM of the corresponding simulation years combined (2011-SWM)\n",
    "\n",
    "col <- c(\"season\", \"k\", \"theta\", \"mdd\", \"med\", \"dist90\", \"iteration\")\n",
    "SimulatedKernelsSWM <- as.data.frame(matrix(nrow=0, ncol=7), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernelsSWM) <- col\n",
    "\n",
    "#don't print warnings for this loop, they are only for setting row names in a tibble which is depracated. But it works. \n",
    "options(warn=-1)\n",
    "\n",
    "pb <- txtProgressBar(min = 0, max = 100, style = 3)\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "\n",
    "for(n in 1:100){\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    SimulatedSamplingSWM = SimulationSWM[FALSE,]\n",
    "    \n",
    "    \n",
    "    for(i in 1:nrow(AllYearsRecruits)){ \n",
    "        \n",
    "        destination_eval <- as.character(AllYearsRecruits$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- SimulationSWM %>%\n",
    "                                    filter(destination==destination_eval) %>%\n",
    "                                    sample_n(as.numeric(AllYearsRecruits$n_offs_gen_all_years[i]), replace=F) #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "        \n",
    "        SimulatedSamplingSWM <- bind_rows(SimulatedSamplingSWM, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "\n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSamplingSWM <- SimulatedSamplingSWM %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSamplingSWM)==sum(NGenOffsSWM$n_offs_gen) #should be TRUE\n",
    "    \n",
    "   #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>% #should be 37 for 2012-2014\n",
    "        filter(Year %in% c(\"2012\", \"2013\", \"2014\")) %>%\n",
    "        select(NumParentageMatches) %>%\n",
    "        summarise(NumParentageMatches=sum(NumParentageMatches)))\n",
    "    \n",
    "    SimulatedSamplingSWMPar <- SimulatedSamplingSWM %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% AllYearsRecruits$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSamplingSWM_2 <- anti_join((SimulatedSamplingSWM %>% ungroup()), SimulatedSamplingSWMPar, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSamplingSWM_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSamplingSWMPar3 <- bind_rows(SimulatedSamplingSWMPar, SimulatedSamplingSWM_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSampSWM <- PropSamp %>%  #add in SWM sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSampSWM$destination <- PropSampSWM$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSamplingSWMPar3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in SWM surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSampSWM, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSamplingSWMPar3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum SWM the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummarySWM <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum SWM the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finSWMy, join SWM of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for SWM sites\n",
    "                PropSampSWM <- PropSampSWM %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSampSWM$destination <- PropSampSWM$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSampSWM, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% AllYearsRecruits$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummarySWM %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFullSWM <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFullSWM) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFullSWM\n",
    "    \n",
    "    #NOW FIT THE KERNEL\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "SimSWMFit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "\n",
    "BestKSWM <- as.numeric(coef(SimSWMFit)[1])\n",
    "BestThetaSWM <- as.numeric(coef(SimSWMFit)[2])\n",
    "MDDSWM <- as.numeric(cubintegrate(integrate_kernel_sum1, lower = 0, upper = Inf, k=BestKSWM, theta=BestThetaSWM, , method = \"pcubature\")$integral)\n",
    "k_eval <- BestKSWM\n",
    "theta_eval <- BestThetaSWM\n",
    "MedSWM  <- round(nleqslv(x = 7, fn = cdf_solve)$x, 2) \n",
    "Dist90_SWM <- round(nleqslv(x = 7, fn = cdf_solve90)$x, 2)\n",
    "    \n",
    "    #store the info in this df\n",
    "    SimulatedKernelsSWM_beta <- as.data.frame(matrix(nrow=1, ncol=7), stringsAsFactors = FALSE)\n",
    "    colnames(SimulatedKernelsSWM_beta) <- col\n",
    "    \n",
    "    SimulatedKernelsSWM_beta$season <- NA\n",
    "    SimulatedKernelsSWM_beta$k <- BestKSWM\n",
    "    SimulatedKernelsSWM_beta$theta <- BestThetaSWM\n",
    "    SimulatedKernelsSWM_beta$med <- MedSWM\n",
    "    SimulatedKernelsSWM_beta$mdd <- MDDSWM\n",
    "    SimulatedKernelsSWM_beta$dist90 <- Dist90_SWM\n",
    "    SimulatedKernelsSWM_beta$iteration <- n\n",
    "\n",
    "    \n",
    "#join results into larger df\n",
    "SimulatedKernelsSWM <- bind_rows(SimulatedKernelsSWM, SimulatedKernelsSWM_beta) %>%\n",
    "    mutate(season=\"SWM\")\n",
    "    \n",
    "setTxtProgressBar(pb, n)\n",
    "\n",
    "\n",
    "}\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "options(warn=0) #turn warnings back on\n",
    "\n",
    "\n",
    "write.csv(SimulatedKernelsSWM, file=\"~/oceanography/script_output/KernelFits/100SimulatedKernelsSWMGrowth.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 41.84831 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NEM of the corresponding simulation years combined (2011-NEM)\n",
    "\n",
    "col <- c(\"season\", \"k\", \"theta\", \"mdd\", \"med\", \"dist90\", \"iteration\")\n",
    "SimulatedKernelsNEM <- as.data.frame(matrix(nrow=0, ncol=7), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernelsNEM) <- col\n",
    "\n",
    "#don't print warnings for this loop, they are only for setting row names in a tibble which is depracated. But it works. \n",
    "options(warn=-1)\n",
    "\n",
    "pb <- txtProgressBar(min = 0, max = 100, style = 3)\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "\n",
    "for(n in 1:100){\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    SimulatedSamplingNEM = SimulationNEM[FALSE,]\n",
    "    \n",
    "    \n",
    "    for(i in 1:nrow(AllYearsRecruits)){ \n",
    "        \n",
    "        destination_eval <- as.character(AllYearsRecruits$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- SimulationNEM %>%\n",
    "                                    filter(destination==destination_eval) %>%\n",
    "                                    sample_n(as.numeric(AllYearsRecruits$n_offs_gen_all_years[i]), replace=F) #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "        \n",
    "        SimulatedSamplingNEM <- bind_rows(SimulatedSamplingNEM, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "\n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSamplingNEM <- SimulatedSamplingNEM %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSamplingNEM)==sum(NGenOffsNEM$n_offs_gen) #should be TRUE\n",
    "    \n",
    "   #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>% #should be 37 for 2012-2014\n",
    "        filter(Year %in% c(\"2012\", \"2013\", \"2014\")) %>%\n",
    "        select(NumParentageMatches) %>%\n",
    "        summarise(NumParentageMatches=sum(NumParentageMatches)))\n",
    "    \n",
    "    SimulatedSamplingNEMPar <- SimulatedSamplingNEM %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% AllYearsRecruits$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSamplingNEM_2 <- anti_join((SimulatedSamplingNEM %>% ungroup()), SimulatedSamplingNEMPar, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSamplingNEM_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSamplingNEMPar3 <- bind_rows(SimulatedSamplingNEMPar, SimulatedSamplingNEM_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSampNEM <- PropSamp %>%  #add in NEM sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSampNEM$destination <- PropSampNEM$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSamplingNEMPar3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in NEM surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSampNEM, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSamplingNEMPar3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum NEM the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummaryNEM <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum NEM the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finNEMy, join NEM of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for NEM sites\n",
    "                PropSampNEM <- PropSampNEM %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSampNEM$destination <- PropSampNEM$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSampNEM, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% AllYearsRecruits$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummaryNEM %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFullNEM <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFullNEM) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFullNEM\n",
    "    \n",
    "    #NOW FIT THE KERNEL\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "SimNEMFit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "\n",
    "BestKNEM <- as.numeric(coef(SimNEMFit)[1])\n",
    "BestThetaNEM <- as.numeric(coef(SimNEMFit)[2])\n",
    "MDDNEM <- as.numeric(cubintegrate(integrate_kernel_sum1, lower = 0, upper = Inf, k=BestKNEM, theta=BestThetaNEM, , method = \"pcubature\")$integral)\n",
    "k_eval <- BestKNEM\n",
    "theta_eval <- BestThetaNEM\n",
    "MedNEM  <- round(nleqslv(x = 7, fn = cdf_solve)$x, 2) \n",
    "Dist90_NEM <- round(nleqslv(x = 7, fn = cdf_solve90)$x, 2)\n",
    "    \n",
    "    #store the info in this df\n",
    "    SimulatedKernelsNEM_beta <- as.data.frame(matrix(nrow=1, ncol=7), stringsAsFactors = FALSE)\n",
    "    colnames(SimulatedKernelsNEM_beta) <- col\n",
    "    \n",
    "    SimulatedKernelsNEM_beta$season <- NA\n",
    "    SimulatedKernelsNEM_beta$k <- BestKNEM\n",
    "    SimulatedKernelsNEM_beta$theta <- BestThetaNEM\n",
    "    SimulatedKernelsNEM_beta$med <- MedNEM\n",
    "    SimulatedKernelsNEM_beta$mdd <- MDDNEM\n",
    "    SimulatedKernelsNEM_beta$dist90 <- Dist90_NEM\n",
    "    SimulatedKernelsNEM_beta$iteration <- n\n",
    "\n",
    "    \n",
    "#join results into larger df\n",
    "SimulatedKernelsNEM <- bind_rows(SimulatedKernelsNEM, SimulatedKernelsNEM_beta) %>%\n",
    "    mutate(season=\"NEM\")\n",
    "    \n",
    "setTxtProgressBar(pb, n)\n",
    "\n",
    "\n",
    "}\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "options(warn=0) #turn warnings back on\n",
    "\n",
    "\n",
    "write.csv(SimulatedKernelsNEM, file=\"~/oceanography/script_output/KernelFits/100SimulatedKernelsNEMGrowth.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monsoon season prep\n",
    "NEM_months <- c(11, 12, 1, 2, 3, 4)\n",
    "SWM_months <- c(5, 6, 7, 8, 9, 10)\n",
    "\n",
    "NEM <- conn_mat_full4 %>%\n",
    "    filter(month %in% NEM_months) %>%\n",
    "    group_by(source, destination) %>%\n",
    "    summarise(conn=max(fraction))\n",
    "\n",
    "SWM <- conn_mat_full4 %>%\n",
    "    filter(month %in% SWM_months) %>%\n",
    "    group_by(source, destination) %>%\n",
    "    summarise(conn=max(fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CELL BELOW IS WORKING FOR GLM OF OBSERVED DATA BY SIMULATED DATA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(GenSimConn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(is.na(GenSimConn)==T) #should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__run GLM observed genetic dispersal predicted by simulations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(GenSimConn$obs_disp) #should be 0.024\n",
    "var(GenSimConn$obs_disp) #should be 0.054\n",
    "#overdispersion?\n",
    "#no, because residual deviance of the model is not greater than the df\n",
    "#Residual deviance:  38.221  on 948  degrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plan:\n",
    "#fit 3 successive log-linear models starting with main efects only(fit1), main effects plus all 2-way interactions (fit2), and added in all 3 way interactions (fit3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NullMod <- glm(obs_disp ~ dist_km , data=GenSimConn, family=\"poisson\")\n",
    "summary(NullMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObsModExpYearFit1 <- glm(obs_disp ~ AnnRecPart + YearSampled + direction + dist_km +SourcePropSamp +DestPropSamp, data=GenSimConn, family=\"poisson\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(ObsModExpYearFit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#only main effects, first find worthwhile predictors with AIC\n",
    "#the intercept is very significant but I think that just means 0s are more common in the data. totally true!\n",
    "\n",
    "ObsModExpYearFit1 <- glm(obs_disp ~ AnnRecPart + YearSampled + direction + dist_km +SourcePropSamp +DestPropSamp, data=GenSimConn, family=\"poisson\")\n",
    "MainEff_AnnRecPart <- update(ObsModExpYearFit1, . ~ . -AnnRecPart)\n",
    "MainEff_YearSampled <- update(ObsModExpYearFit1, . ~ . -YearSampled)\n",
    "MainEff_direction <- update(ObsModExpYearFit1, . ~ . -direction)\n",
    "MainEff_dist_km <- update(ObsModExpYearFit1, . ~ . -dist_km)\n",
    "MainEff_SourcePropSamp <- update(ObsModExpYearFit1, . ~ . -SourcePropSamp)\n",
    "MainEff_DestPropSamp <- update(ObsModExpYearFit1, . ~ . -DestPropSamp)\n",
    "#drop the 3 terms AIC doesn't support? maybe not though, because when there's an interaction that's the best model\n",
    "MainEff_ARP_DPrp_Dist <- glm(obs_disp ~ YearSampled + direction +SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "#add the interaction between year and simulations\n",
    "ObsModExpYearFit2IntYear <- glm(obs_disp ~ AnnRecPart*YearSampled + direction+SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "ObsModExpYearFit2IntDir <- glm(obs_disp ~ AnnRecPart*YearSampled + direction+SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "ObsModExpYearFit2IntDirNoROMS <- glm(obs_disp ~ AnnRecPart+YearSampled*direction+SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "ObsModExpYearFit3Int <- glm(obs_disp ~ AnnRecPart*YearSampled*direction+SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "\n",
    "FullModNoROMSDestPropSamp <- glm(obs_disp ~  YearSampled + direction + dist_km +SourcePropSamp , data=GenSimConn, family=\"poisson\")\n",
    "FullModNoROMSDestPropSampInt <- glm(obs_disp ~  YearSampled* direction + dist_km +SourcePropSamp , data=GenSimConn, family=\"poisson\")\n",
    "\n",
    "MainEffAIC <- as.data.frame(AIC(NullMod, FullModNoROMSDestPropSampInt, FullModNoROMSDestPropSamp, ObsModExpYearFit1, MainEff_AnnRecPart, MainEff_YearSampled, MainEff_direction, MainEff_dist_km, MainEff_SourcePropSamp, MainEff_DestPropSamp, ObsModExpYearFit2IntDir, ObsModExpYearFit2IntYear, ObsModExpYearFit2IntDirNoROMS, ObsModExpYearFit3Int))\n",
    "MainEffAIC$model <- row.names(MainEffAIC)\n",
    "MainEffAIC <- MainEffAIC %>% arrange(AIC)\n",
    "MainEffAIC\n",
    "#/write.csv(MainEffAIC, file=\"~/oceanography/script_output/GLM/GLMObsDispAIC.csv\",row.names=F,  quote=F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullModNoROMSDestPropSampInt <- glm(obs_disp ~  YearSampled* direction+direction+YearSampled + dist_km +SourcePropSamp , data=GenSimConn, family=\"poisson\")\n",
    "\n",
    "summary(FullModNoROMSDestPropSampInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC(test, MainEff_AnnRecPart,MainEff_DestPropSamp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(ObsModExpYearFit2Int ) #judging by the significant intercept (which should be AnnRecPart:Year2012?) when there's more particles expected from the ROMS model, there's actually less in the observed data.\n",
    "ObsModExpYearFit2Int_Sum <- tidy(ObsModExpYearFit2Int)\n",
    "#write.csv(ObsModExpYearFit2Int_Sum, file=\"~/oceanography/script_output/GLM/YearDispIntBestModSum.csv\",row.names=F,  quote=F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROMSFull <- glm(AnnRecPart ~ as.factor(SimYear) + direction + dist_km + source + destination, data=GenSimConn, family=\"poisson\")\n",
    "#MainEff_AnnRecPart <- update(ObsModExpYearFit1, . ~ . -AnnRecPart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary(ROMSFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(SimConnDFDir$NormSourceMonsoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what are the routes that create these peaks in direction annually?\n",
    "\n",
    "#are there similar patterns seasonally?\n",
    "\n",
    "#plot the connectivity matrix with of the roms model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head(SimConnDFMeta %>% dplyr::select(AnnRecPart, direction, SimYear, source, destination))\n",
    "SimConnDFMeta %>%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(SimConnDFMeta$direction, breaks=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(SimConnDFMeta$direction)\n",
    "(SimConnDFMeta$direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this isn't significant, which means the residual difference is small enough here to say the model fits reasonably well\n",
    "with(test_mod, cbind(res.deviance = deviance, df = df.residual,\n",
    "  p = pchisq(deviance, df.residual, lower.tail=FALSE)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how much devience is explained here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(obs_disp ~ ExpDisp, data=SimPlusGenWithDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot(test_mod_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot predicted model\n",
    "range(SimPlusGenWithDist$ExpDisp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_disp_range <- seq(0, 66114, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_disp_pred <- predict(test_mod_int,type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot( SimPlusGenWithDist$ExpDisp, SimPlusGenWithDist$obs_disp, pch = 16)#, xlab = \"WEIGHT (g)\", ylab = \"VS\")\n",
    "\n",
    "lines(obs_disp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
