{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Packages <- c(\"dplyr\",\"broom\",\"cubature\", \"geosphere\", \"data.table\",  \"ggplot2\", \"bbmle\", \"dplyr\",\"tidyr\", \"stringr\", \"tidyverse\", \"lubridate\", \"RColorBrewer\")\n",
    "\n",
    "invisible(suppressPackageStartupMessages(lapply(Packages, library, character.only = TRUE)))\n",
    "\n",
    "setwd('/local/home/katrinac/oceanography')\n",
    "\"%!in%\" <- function(x,table) match(x,table, nomatch = 0) == 0\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/ll_kt_both_bbmle.R\")\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/GenGausKernInt_sum0.5.R\") #integrate_kernel_sum1\n",
    "source(\"~/parentage/kernel_fitting/1340_loci/functions/GenGausKernInt_sum1.R\") #integrate_kernel_sum0.5\n",
    "\n",
    "\n",
    "#clownfish metadata\n",
    "load(\"~/parentage/r_data/total_sampling_across_years.RData\")\n",
    "load(\"~/parentage/r_data/sampled_area_each_year.RData\")\n",
    "#https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Script_outputs/cumulative_prop_hab_sampled_by_site.RData)\n",
    "load(\"~/parentage/r_data/cumulative_prop_hab_sampled_by_site.RData\")\n",
    "#download.file(url = \"https://github.com/pinskylab/genomics/blob/master/data/fish-obs.RData?raw=true\", destfile = \"~/parentage/r_data/fish-obs.RData\")\n",
    "fish_obs <- readRDS(\"~/parentage/r_data/fish-obs.RData\") \n",
    "load(\"~/parentage/r_data/site_dist_info.RData\")\n",
    "#download.file(url = \"https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Data_from_database/anem_db.RData?raw=true\", destfile = \"~/parentage/r_data/anem_db.RData\")\n",
    "load(\"~/parentage/r_data/anem_db.RData\")\n",
    "#download.file(url = \"https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Data_from_database/dives_db.RData?raw=true\", destfile = \"~/parentage/r_data/dives_db.RData\")\n",
    "load(\"~/parentage/r_data/dives_db.RData\")\n",
    "#download.file(url = \"https://github.com/pinskylab/Clownfish_persistence/blob/master/Data/Data_from_database/fish_db.RData?raw=true\", destfile = \"~/parentage/r_data/dives_db.RData\")\n",
    "load(\"~/parentage/r_data/fish_db.RData\")\n",
    "load(\"~/parentage/r_data/gps_db.RData\")\n",
    "\n",
    "#stop dplyr's courtesy warnings about grouping variables and summarise()\n",
    "options(dplyr.summarise.inform=F) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnsampledSites <- c(\"SF1\", \"SF2\", \"SF3\", \"SF4\", \"SF5\", \"SF6\", \"Pangasugan\", \"CAI\", \"Other\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in the df where each particle is an observation\n",
    "Simulation2012 <- fread(file=\"~/oceanography/script_output/SimulationSummaryTables/SimConnLongForm2012YearSampled.csv\", showProgress = T)\n",
    "Simulation2013 <- fread(file=\"~/oceanography/script_output/SimulationSummaryTables/SimConnLongForm2013YearSampled.csv\", showProgress = T)\n",
    "Simulation2014 <- fread(file=\"~/oceanography/script_output/SimulationSummaryTables/SimConnLongForm2014YearSampled.csv\", showProgress = T)\n",
    "\n",
    "#this is about 3 GB so fread is fastest, but consider these options for dealing with a large csv\n",
    "#https://inbo.github.io/tutorials/tutorials/r_large_data_files_handling/\n",
    "\n",
    "#head(Simulation2012 %>% group_by(date, source, destination) %>% summarise(Check=n()))\n",
    "#CAI should be 201718, it is, all good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read in the centroids adjusted for the simulation, so the Magbangons combined \n",
    "centroids <- read.csv(file=\"~/oceanography/script_output/SurveyData/SimulationCentroids.csv\", header=T, stringsAsFactors = F)\n",
    "#read in the distance matrix adjusted for the simulation\n",
    "distances <- read.csv(file=\"~/oceanography/script_output/SurveyData/SimulationAllDistances.csv\", header=T, stringsAsFactors = F)\n",
    "\n",
    "\n",
    "#proportion sampled\n",
    "#add how well we sampled sites- proportion of habitat sampled\n",
    "load(\"~/parentage/r_data/cumulative_prop_hab_sampled_by_site.RData\")\n",
    "PropSamp <- cumulative_prop_hab_sampled_by_site %>%\n",
    "    mutate(total_possible_sample_anems = ifelse(site==\"Caridad Proper\", 4, total_possible_sample_anems) ) %>%\n",
    "    mutate(total_prop_hab_sampled_anems_tidied= ifelse(site==\"Caridad Proper\" & total_anems_sampled==4, 1, total_prop_hab_sampled_anems_tidied) ) %>%\n",
    "    mutate(total_possible_sample_anems = ifelse(site==\"Sitio Lonas\", total_anems_sampled, total_possible_sample_anems) ) %>%\n",
    "    mutate(total_prop_hab_sampled_anems_tidied= ifelse(site==\"Sitio Lonas\", 1, total_prop_hab_sampled_anems_tidied) )%>%\n",
    "    mutate(total_prop_hab_sampled_anems_tidied= ifelse(is.nan(total_prop_hab_sampled_anems_tidied), 0, total_prop_hab_sampled_anems_tidied) ) %>%\n",
    "    dplyr::select(site, time_frame, end_year, total_prop_hab_sampled_anems_tidied) \n",
    "\n",
    "PropSamp$site <- gsub(\". \", \".\", PropSamp$site, fixed=TRUE) #fix spaces in Magbangon names\n",
    "\n",
    "S.Mag <- PropSamp %>%#make a table for all of the S. Mabangon years/prop sampled. Then join to the DF, make a column adding S.Magbangon values to all rows of prop sampled, but only sub that value in for PropSamp in N.Magbangon rows, then rename N.Magbangon as Magbangon\n",
    "    filter(site==\"S.Magbangon\") %>%\n",
    "    dplyr::select(site, end_year, total_prop_hab_sampled_anems_tidied) %>%\n",
    "    rename(S.MagVal=\"total_prop_hab_sampled_anems_tidied\", extra=\"site\")\n",
    "\n",
    "PropSamp <- left_join(PropSamp, S.Mag, by=c(\"end_year\")) %>%\n",
    "    mutate(S.MagSum=total_prop_hab_sampled_anems_tidied+S.MagVal) %>% #create col adding the S.Mag values to prop hab - keep in mind values could be greater than 1- if so change them to 1\n",
    "    mutate(total_prop_hab_sampled_anems_tidied= ifelse(site==\"N.Magbangon\", S.MagSum, total_prop_hab_sampled_anems_tidied)) %>%#sub this value in for only N.Mag\n",
    "    mutate(site=ifelse(site==\"N.Magbangon\", \"Magbangon\", site)) %>%#change N.Mag name to generic Mag\n",
    "    filter(site !=\"S.Magbangon\") %>%#eliminate the S.Mag rows, they are now repeats\n",
    "    dplyr::select(-S.MagVal,-extra, -S.MagSum, -time_frame) %>%\n",
    "    rename(PropSamp=\"total_prop_hab_sampled_anems_tidied\")\n",
    "\n",
    "\n",
    "#check if there are values>1, should be none\n",
    "sum(which(PropSamp$total_prop_hab_sampled_anems_tidied >1)) #zero, that's good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "791"
      ],
      "text/latex": [
       "791"
      ],
      "text/markdown": [
       "791"
      ],
      "text/plain": [
       "[1] 791"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load data from the genetic sampling in each year\n",
    "#read in the kernel fitting summary\n",
    "kernels <- read.csv(file=\"~/parentage/kernel_fitting/1340_loci/final_results/tables/kernel_fitting_summary.csv\", header=T, stringsAsFactors = F)\n",
    "\n",
    "##read in the sites that we sampled each year\n",
    "N_gen_par <- read.table(file=\"~/parentage/colony2/20190523_1340loci/input/all_parents_corrected.txt\", header = TRUE, stringsAsFactors = F) %>%#not sure that I need the parents here\n",
    "    mutate(fish_indiv=as.character(fish_indiv))\n",
    "N_gen_offs <- read.table(file=\"~/parentage/colony2/20190523_1340loci/input/all_offspring_corrected.txt\", header=T, stringsAsFactors = F) %>%\n",
    "    mutate(fish_indiv=as.character(fish_indiv))\n",
    "\n",
    "\n",
    "\n",
    "#gather the summary of total offspring sampled\n",
    "#from Allison, putting all the meta data together (Constants_database_common_functions.R)\n",
    "##### Match up other relevant info (site, date, fish_indiv, etc.) to fish in the clownfish table\n",
    "# Pull out year and month into a separate column in dives_db\n",
    "dives_db_processed <- dives_db %>%\n",
    "  mutate(year = as.integer(substring(date,1,4))) %>%\n",
    "  mutate(month = as.integer(substring(date,6,7))) %>%\n",
    "  mutate(dive_date = date(date))\n",
    "\n",
    "# Pull all APCL caught or otherwise in the clownfish table\n",
    "allfish_fish <- fish_db %>%\n",
    "  select(fish_table_id, anem_table_id, fish_spp, sample_id, anem_table_id, recap, tag_id, color, sex, size, fish_obs_time, fish_notes) %>%\n",
    "  filter(fish_spp == 'APCL') %>%\n",
    "  mutate(size = as.numeric(size))  # make the size numeric (rather than chr) so can do means and such\n",
    "\n",
    "# and their corresponding anemones\n",
    "allfish_anems <- anem_db %>%\n",
    "  select(anem_table_id, dive_table_id, anem_obs, anem_id, old_anem_id, anem_notes) %>%\n",
    "  filter(anem_table_id %in% allfish_fish$anem_table_id)\n",
    "\n",
    "# and the corresponding dive info\n",
    "allfish_dives <- dives_db_processed %>%\n",
    "  select(dive_table_id, dive_type, date, year, month, site, gps, dive_notes) %>%\n",
    "  filter(dive_table_id %in% allfish_anems$dive_table_id) \n",
    "\n",
    "# join together\n",
    "allfish_caught <- left_join(allfish_fish, allfish_anems, by=\"anem_table_id\")\n",
    "allfish_caught <- left_join(allfish_caught, allfish_dives, by=\"dive_table_id\")\n",
    "\n",
    "# add in the gen_ids and fish_indiv (now in a separate gen_id table) - gen_id only comes in the time the fish was sequenced, not at all captures\n",
    "allfish_caught <- left_join(allfish_caught, (fish_obs %>% select(fish_table_id, gen_id, fish_indiv)), by = \"fish_table_id\") %>%\n",
    "    select(fish_indiv, sample_id, site) %>%\n",
    "    mutate()\n",
    "\n",
    "N_gen_offs_annual  <- left_join(N_gen_offs, allfish_caught, by=c(\"fish_indiv\", \"sample_id\")) %>% \n",
    "    group_by(year, site) %>%\n",
    "    summarise(n_offs_gen=n()) %>%\n",
    "    ungroup()\n",
    "\n",
    "N_gen_offs_annual$site <- gsub(\". \", \".\", N_gen_offs_annual$site, fixed=TRUE)\n",
    "\n",
    "##for all years\n",
    "NGenOffsAll <- N_gen_offs_annual %>% \n",
    "    group_by(site) %>% \n",
    "    summarise(n_offs_gen=sum(n_offs_gen, na.rm=T))\n",
    "\n",
    "sum(NGenOffsAll$n_offs_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "791"
      ],
      "text/latex": [
       "791"
      ],
      "text/markdown": [
       "791"
      ],
      "text/plain": [
       "[1] 791"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#combine N/S Magbangon in the genetic sampling data\n",
    "\n",
    "AnnualRecsSamp <- bind_rows(N_gen_offs_annual %>%\n",
    "                        filter(site !=\"N.Magbangon\" & site!=\"S.Magbangon\"),\n",
    "                    N_gen_offs_annual %>%\n",
    "                        mutate(Magbangon=ifelse(site==\"N.Magbangon\" | site==\"S.Magbangon\", \"Magbangon\", \"no\")) %>%\n",
    "                        filter(Magbangon==\"Magbangon\") %>%\n",
    "                        group_by(year, Magbangon) %>%\n",
    "                        summarise(sum_offs=sum(n_offs_gen)) %>%\n",
    "                        rename(site=\"Magbangon\", n_offs_gen=\"sum_offs\")) %>%\n",
    "                        mutate(year=as.character(year)) %>%\n",
    "                        ungroup()\n",
    "sum(AnnualRecsSamp$n_offs_gen) #should be 791\n",
    "\n",
    "#add in ALL sites that we sampled, even though we didn't find recruits there\n",
    "AnnualRecsSamp <- left_join(PropSamp %>%  #add in all sampled sites as possible offs sites\n",
    "                            filter(PropSamp > 0),\n",
    "                          AnnualRecsSamp, \n",
    "                              by=c(\"site\", end_year=\"year\")) %>%\n",
    "                        rename(year=\"end_year\")  %>%\n",
    "                        mutate(n_offs_gen=ifelse(is.na(n_offs_gen), 0, n_offs_gen)) %>%#if we didn't sample a recruit at a site that we still visited, put a 0 in place of the NA\n",
    "                        filter(year %in% c(\"2012\", \"2013\", \"2014\")) %>%  #* restrict to what we can pick up combining all years of simulation data\n",
    "                        group_by(site) %>% #*\n",
    "                        mutate(n_offs_gen_all_years=sum(n_offs_gen)) #*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#what if we account for post-settlement mortality and not sampling <3.5 cm recruits?\n",
    "NumDays <- nrow(Simulation2014 %>% distinct(date))#200 days in a simulation\n",
    "\n",
    "#make a df with weighted values for the days of the simluation oldest to most recent\n",
    "SimDates <- Simulation2014 %>%\n",
    "    distinct(date) %>%\n",
    "    mutate(DateSeq=row_number()) %>% #assign row numbers, so more recent dates are higher than older\n",
    "    mutate(SurvivalWeightExp=exp(DateSeq)) %>% #apply the exponential function to get a survival column\n",
    "    mutate(SurvivalWeightExp=SurvivalWeightExp/max(SurvivalWeightExp))%>%#normalize as a survival \"probability\"\n",
    "    mutate(SurvivalWeightLin=(((0.25/2)/5)*DateSeq)) %>%#maybe a linear survival function (y=mx)is more appropriate (eyeball from Allison's Fig 3C because what the hell why not we're just thinking here)\n",
    "    mutate(SurvivalWeightLin=SurvivalWeightLin/max(SurvivalWeightLin)) #%>%#normalize as a survival \"probability\"\n",
    "    #filter(DateSeq %!in% seq((max(DateSeq)-60), max(DateSeq), 1))#account for the fact that we didn't sample <3.5 cm\n",
    "#the max survival prob will be different depending on when I filter out the more recent recruits. I don't want an artificially high prob of sampling based on a survival prob of 1 so I'm cutting fish out after prob weight calculations\n",
    "Simulation2014SurvGrowth <- left_join(Simulation2014, SimDates, by=\"date\") %>%\n",
    "    filter(DateSeq %!in% seq((max(DateSeq)-60), max(DateSeq), 1))\n",
    "nrow(Simulation2014SurvGrowth)<nrow(Simulation2014)#should be TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       " 0.0050  0.1700  0.3400  0.3471  0.5300  0.6950 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(Simulation2014SurvGrowth$SurvivalWeightLin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(i in 1:nrow(NGenOffs2014)){ \n",
    "    \n",
    "    destination_eval <- as.character(NGenOffs2014$site[i]) #pick out a destination site\n",
    "    \n",
    "    SimSampDestination <- Simulation2014SurvGrowth %>% #USING DF WITH SURV/SIZE WEIGHTING ***\n",
    "                                filter(destination==destination_eval) %>%\n",
    "                                sample_n(as.numeric(NGenOffs2014$n_offs_gen[i]),  replace=F) %>% #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "                                select(one_of(names(Simulation2014)))#keep matching columns with the original df instead of carrying over the columns used for survival weighting\n",
    "    SimulatedSampling2014 <- bind_rows(SimulatedSampling2014, SimSampDestination) #build into a sampled particle df\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>date</th><th scope=col>source</th><th scope=col>destination</th><th scope=col>SourceSampled</th><th scope=col>DestSampled</th><th scope=col>SimMonth</th><th scope=col>SimDay</th><th scope=col>SimYear</th><th scope=col>YearSampled</th><th scope=col>SimMonsoon</th><th scope=col>DailyParticles</th><th scope=col>ParticlesReleasedDaily</th><th scope=col>dist_km</th><th scope=col>bearing</th><th scope=col>direction</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2014-01-14    </td><td>SF3           </td><td>Cabatoan      </td><td>no            </td><td>yes           </td><td> 1            </td><td> 1            </td><td>2014          </td><td>2014          </td><td>NEM           </td><td> 42           </td><td>2976          </td><td> 4.857907     </td><td> -36.41887    </td><td>323.5811      </td></tr>\n",
       "\t<tr><td>2013-12-22    </td><td>Cabatoan      </td><td>Cabatoan      </td><td>yes           </td><td>yes           </td><td>12            </td><td>12            </td><td>2013          </td><td>2014          </td><td>NEM           </td><td> 14           </td><td> 992          </td><td> 0.000000     </td><td>-180.00000    </td><td>-10.0000      </td></tr>\n",
       "\t<tr><td>2013-12-26    </td><td>Sitio Baybayon</td><td>Cabatoan      </td><td>yes           </td><td>yes           </td><td>12            </td><td>12            </td><td>2013          </td><td>2014          </td><td>NEM           </td><td>467           </td><td>1984          </td><td>24.910562     </td><td> -12.35333    </td><td>347.6467      </td></tr>\n",
       "\t<tr><td>2013-12-26    </td><td>Sitio Baybayon</td><td>Cabatoan      </td><td>yes           </td><td>yes           </td><td>12            </td><td>12            </td><td>2013          </td><td>2014          </td><td>NEM           </td><td>467           </td><td>1984          </td><td>24.910562     </td><td> -12.35333    </td><td>347.6467      </td></tr>\n",
       "\t<tr><td>2014-01-07    </td><td>Cabatoan      </td><td>Cabatoan      </td><td>yes           </td><td>yes           </td><td> 1            </td><td> 1            </td><td>2014          </td><td>2014          </td><td>NEM           </td><td> 68           </td><td> 992          </td><td> 0.000000     </td><td>-180.00000    </td><td>-10.0000      </td></tr>\n",
       "\t<tr><td>2014-01-21    </td><td>SF2           </td><td>Cabatoan      </td><td>no            </td><td>yes           </td><td> 1            </td><td> 1            </td><td>2014          </td><td>2014          </td><td>NEM           </td><td>117           </td><td>3968          </td><td> 1.858614     </td><td> -34.78244    </td><td>325.2176      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " date & source & destination & SourceSampled & DestSampled & SimMonth & SimDay & SimYear & YearSampled & SimMonsoon & DailyParticles & ParticlesReleasedDaily & dist\\_km & bearing & direction\\\\\n",
       "\\hline\n",
       "\t 2014-01-14     & SF3            & Cabatoan       & no             & yes            &  1             &  1             & 2014           & 2014           & NEM            &  42            & 2976           &  4.857907      &  -36.41887     & 323.5811      \\\\\n",
       "\t 2013-12-22     & Cabatoan       & Cabatoan       & yes            & yes            & 12             & 12             & 2013           & 2014           & NEM            &  14            &  992           &  0.000000      & -180.00000     & -10.0000      \\\\\n",
       "\t 2013-12-26     & Sitio Baybayon & Cabatoan       & yes            & yes            & 12             & 12             & 2013           & 2014           & NEM            & 467            & 1984           & 24.910562      &  -12.35333     & 347.6467      \\\\\n",
       "\t 2013-12-26     & Sitio Baybayon & Cabatoan       & yes            & yes            & 12             & 12             & 2013           & 2014           & NEM            & 467            & 1984           & 24.910562      &  -12.35333     & 347.6467      \\\\\n",
       "\t 2014-01-07     & Cabatoan       & Cabatoan       & yes            & yes            &  1             &  1             & 2014           & 2014           & NEM            &  68            &  992           &  0.000000      & -180.00000     & -10.0000      \\\\\n",
       "\t 2014-01-21     & SF2            & Cabatoan       & no             & yes            &  1             &  1             & 2014           & 2014           & NEM            & 117            & 3968           &  1.858614      &  -34.78244     & 325.2176      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| date | source | destination | SourceSampled | DestSampled | SimMonth | SimDay | SimYear | YearSampled | SimMonsoon | DailyParticles | ParticlesReleasedDaily | dist_km | bearing | direction |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 2014-01-14     | SF3            | Cabatoan       | no             | yes            |  1             |  1             | 2014           | 2014           | NEM            |  42            | 2976           |  4.857907      |  -36.41887     | 323.5811       |\n",
       "| 2013-12-22     | Cabatoan       | Cabatoan       | yes            | yes            | 12             | 12             | 2013           | 2014           | NEM            |  14            |  992           |  0.000000      | -180.00000     | -10.0000       |\n",
       "| 2013-12-26     | Sitio Baybayon | Cabatoan       | yes            | yes            | 12             | 12             | 2013           | 2014           | NEM            | 467            | 1984           | 24.910562      |  -12.35333     | 347.6467       |\n",
       "| 2013-12-26     | Sitio Baybayon | Cabatoan       | yes            | yes            | 12             | 12             | 2013           | 2014           | NEM            | 467            | 1984           | 24.910562      |  -12.35333     | 347.6467       |\n",
       "| 2014-01-07     | Cabatoan       | Cabatoan       | yes            | yes            |  1             |  1             | 2014           | 2014           | NEM            |  68            |  992           |  0.000000      | -180.00000     | -10.0000       |\n",
       "| 2014-01-21     | SF2            | Cabatoan       | no             | yes            |  1             |  1             | 2014           | 2014           | NEM            | 117            | 3968           |  1.858614      |  -34.78244     | 325.2176       |\n",
       "\n"
      ],
      "text/plain": [
       "  date       source         destination SourceSampled DestSampled SimMonth\n",
       "1 2014-01-14 SF3            Cabatoan    no            yes          1      \n",
       "2 2013-12-22 Cabatoan       Cabatoan    yes           yes         12      \n",
       "3 2013-12-26 Sitio Baybayon Cabatoan    yes           yes         12      \n",
       "4 2013-12-26 Sitio Baybayon Cabatoan    yes           yes         12      \n",
       "5 2014-01-07 Cabatoan       Cabatoan    yes           yes          1      \n",
       "6 2014-01-21 SF2            Cabatoan    no            yes          1      \n",
       "  SimDay SimYear YearSampled SimMonsoon DailyParticles ParticlesReleasedDaily\n",
       "1  1     2014    2014        NEM         42            2976                  \n",
       "2 12     2013    2014        NEM         14             992                  \n",
       "3 12     2013    2014        NEM        467            1984                  \n",
       "4 12     2013    2014        NEM        467            1984                  \n",
       "5  1     2014    2014        NEM         68             992                  \n",
       "6  1     2014    2014        NEM        117            3968                  \n",
       "  dist_km   bearing    direction\n",
       "1  4.857907  -36.41887 323.5811 \n",
       "2  0.000000 -180.00000 -10.0000 \n",
       "3 24.910562  -12.35333 347.6467 \n",
       "4 24.910562  -12.35333 347.6467 \n",
       "5  0.000000 -180.00000 -10.0000 \n",
       "6  1.858614  -34.78244 325.2176 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(SimulatedSampling2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Narrow down data to the year of interests__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "181"
      ],
      "text/latex": [
       "181"
      ],
      "text/markdown": [
       "181"
      ],
      "text/plain": [
       "[1] 181"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "13"
      ],
      "text/latex": [
       "13"
      ],
      "text/markdown": [
       "13"
      ],
      "text/plain": [
       "[1] 13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#RUNNING ON 3/18/2021 ACCOUNTING FOR DIFFERENTIAL SAMPLING BASED ON SIZE/POSTSETTLEMENT SURVIVAL\n",
    "#sample the simulation results according to how many offspring we sampled at that site in real life, each row is a column\n",
    "NGenOffs2014 <- AnnualRecsSamp %>%\n",
    "    filter(year==\"2014\")\n",
    "\n",
    "nrow(NGenOffs2014) #should be 9 sites sampled for 2014\n",
    "\n",
    "#make an empty dataframe with the same columns as original, this will be sampled particles\n",
    "SimulatedSampling2014 = Simulation2014[FALSE,]\n",
    "\n",
    "for(i in 1:nrow(NGenOffs2014)){ \n",
    "    \n",
    "    destination_eval <- as.character(NGenOffs2014$site[i]) #pick out a destination site\n",
    "    \n",
    "    SimSampDestination <- Simulation2014SurvGrowth %>% #USING DF WITH SURV/SIZE WEIGHTING ***\n",
    "                                filter(destination==destination_eval) %>%\n",
    "                                sample_n(as.numeric(NGenOffs2014$n_offs_gen[i]), weight=SurvivalWeightLin, replace=F) %>% #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "                                select(one_of(names(Simulation2014)))#keep matching columns with the original df instead of carrying over the columns used for survival weighting\n",
    "    SimulatedSampling2014 <- bind_rows(SimulatedSampling2014, SimSampDestination) #build into a sampled particle df\n",
    "}\n",
    "\n",
    "#assign a numeric ID for each row (which is a sampled particle)\n",
    "SimulatedSampling2014 <- SimulatedSampling2014 %>%\n",
    "    mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "\n",
    "nrow(SimulatedSampling2014)==sum(NGenOffs2014$n_offs_gen) #should be TRUE\n",
    "\n",
    "#now randomly assign parentage match status to some of these rows\n",
    "NumPar <- as.numeric(kernels %>%\n",
    "    filter(Year==\"2014\") %>%\n",
    "    select(NumParentageMatches))\n",
    "\n",
    "SimulatedSampling2014Par <- SimulatedSampling2014 %>%\n",
    "    ungroup() %>%\n",
    "    filter(source %in% NGenOffs2014$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "    sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "    mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "    #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "    #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "\n",
    "#find the rows that haven't been assigned parentage\n",
    "SimulatedSampling2014_2 <- anti_join((SimulatedSampling2014 %>% ungroup()), SimulatedSampling2014Par, by=c(\"ParticleSampID\")) \n",
    "\n",
    "SimulatedSampling2014_2$Parentage <- 0 #add in the column for parentage\n",
    "\n",
    "#combine parentage and non-parentage dfs\n",
    "SimulatedSampling2014Par3 <- bind_rows(SimulatedSampling2014Par, SimulatedSampling2014_2) %>%\n",
    "    mutate(YearSampled=as.character(YearSampled))\n",
    "\n",
    "nrow(SimulatedSampling2014Par3) \n",
    "nrow(SimulatedSampling2014Par3 %>% filter(Parentage==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct carry over of sampled particles in TotalSimSamp\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct carry over of sampled particles in TotalSimSamp2\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of parentage matches in TotalSimPar\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of destination sites, corresponding to number of surveyed sites in SimSampSummary2014, which is used for unassigned row\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of destination sites, corresponding to number of surveyed sites in TotalSimPar2, which will be spread into parentage matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of parentage matches in TotalSimPar2, which will be spread into parentage matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of source sites in final matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of destination sites in final matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of parentage matches in final matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "13"
      ],
      "text/latex": [
       "13"
      ],
      "text/markdown": [
       "13"
      ],
      "text/plain": [
       "[1] 13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"correct number of unassigned recruits in final matrix\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "168"
      ],
      "text/latex": [
       "168"
      ],
      "text/markdown": [
       "168"
      ],
      "text/plain": [
       "[1] 168"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PropSamp2014 <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "                #rename(source=\"site\") %>%\n",
    "                select(-end_year, -PropSamp)\n",
    "\n",
    "#PropSamp2014$destination <- PropSamp2014$source #make another column for destination\n",
    "\n",
    "#make a table with the total number of particles sampled at each site\n",
    "TotalSimSamp <- SimulatedSampling2014Par3 %>% \n",
    "            select(source, destination) %>%\n",
    "            group_by(destination) %>%\n",
    "            summarise(NumSimSampRec=n()) %>%\n",
    "            ungroup()\n",
    "print(\"correct carry over of sampled particles in TotalSimSamp\")\n",
    "sum(TotalSimSamp$NumSimSampRec)==sum(NGenOffs2014$n_offs_gen) #should be true\n",
    "\n",
    "#add in all surveyed sites\n",
    "TotalSimSamp2 <- left_join(PropSamp2014, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "    rename(destination=\"site\")#rename sites to destination after joining\n",
    "\n",
    "print(\"correct carry over of sampled particles in TotalSimSamp2\")\n",
    "sum(TotalSimSamp$NumSimSampRec)==sum(TotalSimSamp2$NumSimSampRec) #should be TRUE\n",
    "\n",
    "#make a table with the total number of parentage matches found in the simulated loop\n",
    "TotalSimPar <- SimulatedSampling2014Par3 %>% \n",
    "            select(source, destination, Parentage) %>%\n",
    "            group_by(source,destination) %>%\n",
    "            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "            select(-Parentage) %>%\n",
    "            ungroup() %>%\n",
    "            distinct(source, destination, .keep_all = T)\n",
    "\n",
    "print(\"correct number of parentage matches in TotalSimPar\")\n",
    "sum(TotalSimPar$NumPar)==NumPar #should be TRUE\n",
    "\n",
    "#combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "SimSampSummary2014 <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "    distinct(source, destination, .keep_all = T) %>%\n",
    "    group_by(destination) %>%\n",
    "    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "    distinct(destination, .keep_all = T) %>%\n",
    "    select(-source) %>%\n",
    "    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "\n",
    "print(\"correct number of destination sites, corresponding to number of surveyed sites in SimSampSummary2014, which is used for unassigned row\")\n",
    "nrow(SimSampSummary2014 %>% distinct(destination, .keep_all = T))==nrow(PropSamp2014) #should be TRUE, 9 possible destinations for 2014\n",
    "\n",
    "\n",
    "#finally, join all of the sites surveyed for a complete parentage matrix\n",
    "#for this, need to have a source/destination column for all sites\n",
    "PropSamp2014 <- PropSamp2014 %>%\n",
    "                rename(source=\"site\")\n",
    "\n",
    "PropSamp2014$destination <- PropSamp2014$source #make another column for destination\n",
    "\n",
    "#this below will become parentage matrix! \n",
    "TotalSimPar2 <- full_join(TotalSimPar,PropSamp2014, by=c(\"source\", \"destination\")) %>%\n",
    "    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "\n",
    "print(\"correct number of destination sites, corresponding to number of surveyed sites in TotalSimPar2, which will be spread into parentage matrix\")\n",
    "nrow(TotalSimPar2 %>% distinct(destination, .keep_all = T))==nrow(PropSamp2014) #should be TRUE, 9 possible destinations for 2014\n",
    "\n",
    "#check that the number of matches is still correct\n",
    "print(\"correct number of parentage matches in TotalSimPar2, which will be spread into parentage matrix\")\n",
    "sum(TotalSimPar2$NumPar)==NumPar\n",
    "\n",
    "#spread into matrix format\n",
    "SimDispMat <- TotalSimPar2 %>%\n",
    "    filter(source %in% NGenOffs2014$site) %>%\n",
    "    arrange(source, destination)  %>%\n",
    "    spread(destination, NumPar) %>%\n",
    "    select(-source)\n",
    "SimDispMat[is.na(SimDispMat)] <- 0\n",
    "\n",
    "#add in unassigned row\n",
    "unassigned <- t(as.matrix(SimSampSummary2014 %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "rownames(unassigned)<-NULL\n",
    "colnames(unassigned)<-names(SimDispMat)\n",
    "\n",
    "SimDispMatFull2014 <- rbind(SimDispMat, unassigned)\n",
    "colnames(SimDispMatFull2014) <- NULL\n",
    "\n",
    "#error check final matrix \n",
    "print(\"correct number of source sites in final matrix\")\n",
    "nrow(SimDispMatFull2014)==nrow(PropSamp2014)+1\n",
    "\n",
    "print(\"correct number of destination sites in final matrix\")\n",
    "ncol(SimDispMatFull2014)==nrow(PropSamp2014)\n",
    "\n",
    "print(\"correct number of parentage matches in final matrix\")\n",
    "sum(SimDispMatFull2014[1:nrow(PropSamp2014),])==NumPar\n",
    "NumPar\n",
    "\n",
    "print(\"correct number of unassigned recruits in final matrix\")\n",
    "sum(SimDispMatFull2014[nrow(PropSamp2014)+1,])==sum(NGenOffs2014$n_offs_gen)-NumPar\n",
    "sum(NGenOffs2014$n_offs_gen)-NumPar\n",
    "\n",
    "#finally- make sure dimensions of simulated parentage matrix match that of the genetic kernel fits. we should be totally replicating the genetic kernel fitting here\n",
    "#EXCEPT! Remember that in the genetic data Magbangon was separated into two sites, but in the simulated data it's not\n",
    "#EmpiricalAssignments <- read.csv(\"~/parentage/kernel_fitting/1340_loci/input/parentage_matrix13_corrected.csv\", header=F)\n",
    "\n",
    "#print(\"dimensions of simulated and empirical parentage matrix are the same\")\n",
    "#(dim(EmpiricalAssignments)-1)==dim(SimDispMatFull2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get all the components of the kernel fitting process together__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "34"
      ],
      "text/latex": [
       "34"
      ],
      "text/markdown": [
       "34"
      ],
      "text/plain": [
       "[1] 34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#assemble all of the components for annual kernel fitting\n",
    "centroids <- read.csv(\"~/oceanography/empirical_data/site_centroids_simulation_kernels.csv\", header=TRUE)\n",
    "\n",
    "Area <- read.csv(\"~/oceanography/empirical_data/site_area_header_nonsurveyed_simulation_kernels.csv\", header=TRUE) %>%\n",
    "    arrange(site) %>%\n",
    "    filter(site %!in% c(\"near_north_full1\", \"near_north_full2\", \"near_north_full3\", \"near_south_full1\", \"near_south_full2\", \"near_south_full3\")) %>%\n",
    "    mutate(kmsq=msq*10^-6) %>%\n",
    "    select(kmsq)\n",
    "Reef_sizes <- as.matrix(Area)\n",
    "\n",
    "#give every site in the distance matrix of the simulation (even if we didn't sample there) an index number\n",
    "AllSites <- centroids %>%\n",
    "    select(site) %>%\n",
    "    arrange(site)\n",
    "nrow(AllSites) #should be 34x1\n",
    "AllSites$index <- seq(from=1, to=34, by=1)\n",
    "\n",
    "SampledSites2014 <- inner_join(PropSamp2014 %>% select(source), AllSites, by=c(source=\"site\")) \n",
    "\n",
    "#check for correct number of rows\n",
    "nrow(SampledSites2014)==nrow(PropSamp2014) #should be true\n",
    "SampledSites2014Index <- t(as.matrix(SampledSites2014$index))\n",
    "ncol(SampledSites2014Index)\n",
    "\n",
    "Sampled_reefs <- SampledSites2014Index\n",
    "\n",
    "#proportion sampled matrix for kernel fitting\n",
    "\n",
    "#for annual\n",
    "Adult_sample_proportions <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                filter(end_year ==\"2014\" & PropSamp > 0) \n",
    "\n",
    "Adult_sample_proportions <- as.matrix(Adult_sample_proportions$PropSamp)\n",
    "nrow(Adult_sample_proportions) #should be 9 for 2014\n",
    "\n",
    "#distance matrix using the centroids with combined Magbangon\n",
    "### List of source locations\n",
    "sites_source <- centroids\n",
    "\n",
    "### List of destination locations\n",
    "sites_dest <- centroids\n",
    "\n",
    "dist_mat_m <- distm(sites_source[,c('lon','lat')], sites_source[,c('lon','lat')], fun=distVincentyEllipsoid)\n",
    "Distances <- dist_mat_m*10^-3\n",
    "\n",
    "Centroids <- centroids %>%\n",
    "    select(-site)\n",
    "\n",
    "Assignments <- SimDispMatFull2014\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "mle2(minuslogl = LL_kt_bbmle, start = list(k = -3, theta = 1), \n",
       "    method = \"L-BFGS-B\", data = x, lower = c(-10, 0.15), upper = c(10, \n",
       "        8), control = list(maxit = 500))\n",
       "\n",
       "Coefficients:\n",
       "        k     theta \n",
       "-3.399413  8.000000 \n",
       "\n",
       "Log-likelihood: -92.77 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "14.4113627526779"
      ],
      "text/latex": [
       "14.4113627526779"
      ],
      "text/markdown": [
       "14.4113627526779"
      ],
      "text/plain": [
       "[1] 14.41136"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "Sim2014Fit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "Sim2014Fit\n",
    "\n",
    "BestK2014 <- as.numeric(coef(Sim2014Fit)[1])\n",
    "BestTheta2014 <- as.numeric(coef(Sim2014Fit)[2])\n",
    "\n",
    "SimMDD2014 <- cubintegrate(integrate_kernel_sum1, lower = 0, upper = Inf, k=BestK2014, theta=BestTheta2014, , method = \"pcubature\")$integral\n",
    "SimMDD2014\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 13.21333 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#awesome! it works! let's rip with a 100 iteration for loop\n",
    "col <- c(\"year\", \"k\", \"theta\", \"mdd\", \"iteration\")\n",
    "SimulatedKernels2014 <- as.data.frame(matrix(nrow=0, ncol=5), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernels2014) <- col\n",
    "\n",
    "#don't print warnings for this loop, they are only for setting row names in a tibble which is depracated. But it works. \n",
    "options(warn=-1)\n",
    "\n",
    "pb <- txtProgressBar(min = 0, max = 100, style = 3)\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "for(n in 1:100){\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    #make an empty dataframe with the same columns as original, this will be sampled particles\n",
    "    SimulatedSampling2014 = Simulation2014[FALSE,]\n",
    "    \n",
    "    for(i in 1:nrow(NGenOffs2014)){ \n",
    "        \n",
    "        destination_eval <- as.character(NGenOffs2014$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- Simulation2014SurvGrowth %>% #USING DF WITH SURV/SIZE WEIGHTING ***\n",
    "                                filter(destination==destination_eval) %>%\n",
    "                                sample_n(as.numeric(NGenOffs2014$n_offs_gen[i]), weight=SurvivalWeightLin, replace=F) %>% #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "                                select(one_of(names(Simulation2014)))#keep matching columns with the original df instead of carrying over the columns used for survival weighting\n",
    "        \n",
    "        SimulatedSampling2014 <- bind_rows(SimulatedSampling2014, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "    \n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSampling2014 <- SimulatedSampling2014 %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSampling2014)==sum(NGenOffs2014$n_offs_gen) #should be TRUE\n",
    "    \n",
    "    #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>%\n",
    "        filter(Year==\"2014\") %>%\n",
    "        select(NumParentageMatches))\n",
    "    \n",
    "    SimulatedSampling2014Par <- SimulatedSampling2014 %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% NGenOffs2014$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSampling2014_2 <- anti_join((SimulatedSampling2014 %>% ungroup()), SimulatedSampling2014Par, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSampling2014_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSampling2014Par3 <- bind_rows(SimulatedSampling2014Par, SimulatedSampling2014_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSamp2014 <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSamp2014$destination <- PropSamp2014$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSampling2014Par3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in all surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSamp2014, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSampling2014Par3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummary2014 <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finally, join all of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for all sites\n",
    "                PropSamp2014 <- PropSamp2014 %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSamp2014$destination <- PropSamp2014$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSamp2014, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% NGenOffs2014$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummary2014 %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFull2014 <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFull2014) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFull2014\n",
    "    \n",
    "    #NOW FIT THE KERNEL\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "Sim2014Fit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "\n",
    "BestK2014 <- as.numeric(coef(Sim2014Fit)[1])\n",
    "BestTheta2014 <- as.numeric(coef(Sim2014Fit)[2])\n",
    "MDD2014 <- as.numeric(cubintegrate(integrate_kernel_sum1, lower = 0, upper = Inf, k=BestK2014, theta=BestTheta2014, , method = \"pcubature\")$integral)\n",
    "    \n",
    "    #store the info in this df\n",
    "    SimulatedKernels2014_beta <- as.data.frame(matrix(nrow=1, ncol=5), stringsAsFactors = FALSE)\n",
    "    colnames(SimulatedKernels2014_beta) <- col\n",
    "    \n",
    "    SimulatedKernels2014_beta$year <- 2014\n",
    "    SimulatedKernels2014_beta$k <- BestK2014\n",
    "    SimulatedKernels2014_beta$theta <- BestTheta2014\n",
    "    SimulatedKernels2014_beta$mdd <- MDD2014\n",
    "    SimulatedKernels2014_beta$iteration <- n\n",
    "    \n",
    "    \n",
    "#join results into larger df\n",
    "SimulatedKernels2014 <- bind_rows(SimulatedKernels2014, SimulatedKernels2014_beta)\n",
    "    \n",
    "setTxtProgressBar(pb, n)\n",
    "\n",
    "\n",
    "}\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "options(warn=0) #turn warnings back on\n",
    "\n",
    "\n",
    "write.csv(SimulatedKernels2014, file=\"~/oceanography/script_output/KernelFits/100SimulatedKernels2014SurvGrowth.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>year</th><th scope=col>k</th><th scope=col>theta</th><th scope=col>mdd</th><th scope=col>iteration</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2013       </td><td>-1.75242260</td><td>0.8150254  </td><td> 8.149302  </td><td> 1         </td></tr>\n",
       "\t<tr><td>2013       </td><td>-2.46055533</td><td>1.5157726  </td><td> 7.667053  </td><td> 2         </td></tr>\n",
       "\t<tr><td>2013       </td><td>-1.61370039</td><td>0.8604449  </td><td> 6.399401  </td><td> 3         </td></tr>\n",
       "\t<tr><td>2013       </td><td>-0.77216649</td><td>0.5660587  </td><td> 8.086022  </td><td> 4         </td></tr>\n",
       "\t<tr><td>2013       </td><td>-1.78315142</td><td>0.9203920  </td><td> 6.750547  </td><td> 5         </td></tr>\n",
       "\t<tr><td>2013       </td><td> 0.06071795</td><td>0.4412328  </td><td>10.017367  </td><td> 6         </td></tr>\n",
       "\t<tr><td>2013       </td><td>-1.94185411</td><td>0.9975514  </td><td> 6.996075  </td><td> 7         </td></tr>\n",
       "\t<tr><td>2013       </td><td>-2.00325164</td><td>0.9535903  </td><td> 7.953306  </td><td> 8         </td></tr>\n",
       "\t<tr><td>2013       </td><td>-2.44105780</td><td>1.3508791  </td><td> 8.213368  </td><td> 9         </td></tr>\n",
       "\t<tr><td>2013       </td><td>-1.63934690</td><td>0.8389209  </td><td> 6.881654  </td><td>10         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " year & k & theta & mdd & iteration\\\\\n",
       "\\hline\n",
       "\t 2013        & -1.75242260 & 0.8150254   &  8.149302   &  1         \\\\\n",
       "\t 2013        & -2.46055533 & 1.5157726   &  7.667053   &  2         \\\\\n",
       "\t 2013        & -1.61370039 & 0.8604449   &  6.399401   &  3         \\\\\n",
       "\t 2013        & -0.77216649 & 0.5660587   &  8.086022   &  4         \\\\\n",
       "\t 2013        & -1.78315142 & 0.9203920   &  6.750547   &  5         \\\\\n",
       "\t 2013        &  0.06071795 & 0.4412328   & 10.017367   &  6         \\\\\n",
       "\t 2013        & -1.94185411 & 0.9975514   &  6.996075   &  7         \\\\\n",
       "\t 2013        & -2.00325164 & 0.9535903   &  7.953306   &  8         \\\\\n",
       "\t 2013        & -2.44105780 & 1.3508791   &  8.213368   &  9         \\\\\n",
       "\t 2013        & -1.63934690 & 0.8389209   &  6.881654   & 10         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| year | k | theta | mdd | iteration |\n",
       "|---|---|---|---|---|\n",
       "| 2013        | -1.75242260 | 0.8150254   |  8.149302   |  1          |\n",
       "| 2013        | -2.46055533 | 1.5157726   |  7.667053   |  2          |\n",
       "| 2013        | -1.61370039 | 0.8604449   |  6.399401   |  3          |\n",
       "| 2013        | -0.77216649 | 0.5660587   |  8.086022   |  4          |\n",
       "| 2013        | -1.78315142 | 0.9203920   |  6.750547   |  5          |\n",
       "| 2013        |  0.06071795 | 0.4412328   | 10.017367   |  6          |\n",
       "| 2013        | -1.94185411 | 0.9975514   |  6.996075   |  7          |\n",
       "| 2013        | -2.00325164 | 0.9535903   |  7.953306   |  8          |\n",
       "| 2013        | -2.44105780 | 1.3508791   |  8.213368   |  9          |\n",
       "| 2013        | -1.63934690 | 0.8389209   |  6.881654   | 10          |\n",
       "\n"
      ],
      "text/plain": [
       "   year k           theta     mdd       iteration\n",
       "1  2013 -1.75242260 0.8150254  8.149302  1       \n",
       "2  2013 -2.46055533 1.5157726  7.667053  2       \n",
       "3  2013 -1.61370039 0.8604449  6.399401  3       \n",
       "4  2013 -0.77216649 0.5660587  8.086022  4       \n",
       "5  2013 -1.78315142 0.9203920  6.750547  5       \n",
       "6  2013  0.06071795 0.4412328 10.017367  6       \n",
       "7  2013 -1.94185411 0.9975514  6.996075  7       \n",
       "8  2013 -2.00325164 0.9535903  7.953306  8       \n",
       "9  2013 -2.44105780 1.3508791  8.213368  9       \n",
       "10 2013 -1.63934690 0.8389209  6.881654 10       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SimulatedKernels2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "394"
      ],
      "text/latex": [
       "394"
      ],
      "text/markdown": [
       "394"
      ],
      "text/plain": [
       "[1] 394"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#combine simulations\n",
    "SimulationAll <- bind_rows(Simulation2012, Simulation2013, Simulation2014)\n",
    "\n",
    "#make a DF of all of the sampled fish over 2012-2014\n",
    "AllYearsRecruits <- AnnualRecsSamp %>% distinct(site, .keep_all = T)\n",
    "sum(AllYearsRecruits$n_offs_gen_all_years) #should be 394 for 2012-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "34"
      ],
      "text/latex": [
       "34"
      ],
      "text/markdown": [
       "34"
      ],
      "text/plain": [
       "[1] 34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16"
      ],
      "text/latex": [
       "16"
      ],
      "text/markdown": [
       "16"
      ],
      "text/plain": [
       "[1] 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get together kernel fitting components for all years/seasonal\n",
    "\n",
    "#assemble all of the components for annual kernel fitting\n",
    "centroids <- read.csv(\"~/oceanography/empirical_data/site_centroids_simulation_kernels.csv\", header=TRUE)\n",
    "\n",
    "Area <- read.csv(\"~/oceanography/empirical_data/site_area_header_nonsurveyed_simulation_kernels.csv\", header=TRUE) %>%\n",
    "    arrange(site) %>%\n",
    "    filter(site %!in% c(\"near_north_full1\", \"near_north_full2\", \"near_north_full3\", \"near_south_full1\", \"near_south_full2\", \"near_south_full3\")) %>%\n",
    "    mutate(kmsq=msq*10^-6) %>%\n",
    "    select(kmsq)\n",
    "Reef_sizes <- as.matrix(Area)\n",
    "\n",
    "#give every site in the distance matrix of the simulation (even if we didn't sample there) an index number\n",
    "AllSites <- centroids %>%\n",
    "    select(site) %>%\n",
    "    arrange(site)\n",
    "nrow(AllSites) #should be 34x1\n",
    "AllSites$index <- seq(from=1, to=34, by=1)\n",
    "\n",
    "PropSampAll <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "            filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "            rename(source=\"site\") %>%\n",
    "            select(-end_year, -PropSamp)\n",
    "\n",
    "SampledSitesAll <- inner_join(PropSampAll %>% select(source), AllSites, by=c(source=\"site\")) \n",
    "\n",
    "#check for correct number of rows\n",
    "nrow(SampledSitesAll)==nrow(PropSampAll) #should be true\n",
    "SampledSitesAllIndex <- t(as.matrix(SampledSitesAll$index))\n",
    "ncol(SampledSitesAllIndex)\n",
    "\n",
    "Sampled_reefs <- SampledSitesAllIndex\n",
    "\n",
    "#proportion sampled matrix for kernel fitting\n",
    "\n",
    "Adult_sample_proportions <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                filter(end_year ==\"2014\" & PropSamp > 0) \n",
    "\n",
    "Adult_sample_proportions <- as.matrix(Adult_sample_proportions$PropSamp)\n",
    "nrow(Adult_sample_proportions) \n",
    "\n",
    "#distance matrix using the centroids with combined Magbangon\n",
    "### List of source locations\n",
    "sites_source <- centroids\n",
    "\n",
    "### List of destination locations\n",
    "sites_dest <- centroids\n",
    "\n",
    "dist_mat_m <- distm(sites_source[,c('lon','lat')], sites_source[,c('lon','lat')], fun=distVincentyEllipsoid)\n",
    "Distances <- dist_mat_m*10^-3\n",
    "\n",
    "Centroids <- centroids %>%\n",
    "    select(-site)\n",
    "\n",
    "#for the all years sites sampled in the simulation, it's a total of 16. That's lower than the all year used in kernel fitting because we didn't sample Sitio Tugas or Gabas until after 2014. We also combined the Magbangons, so 19-16=3 accounted for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%"
     ]
    }
   ],
   "source": [
    "#All of the corresponding simulation years combined (2011-14)\n",
    "\n",
    "col <- c(\"year\", \"k\", \"theta\", \"iteration\")\n",
    "SimulatedKernelsAll <- as.data.frame(matrix(nrow=0, ncol=4), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernelsAll) <- col\n",
    "\n",
    "#don't print warnings for this loop, they are only for setting row names in a tibble which is depracated. But it works. \n",
    "options(warn=-1)\n",
    "\n",
    "pb <- txtProgressBar(min = 0, max = 1000, style = 3)#7 years in each interation\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "\n",
    "for(n in 1:1000){\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    SimulatedSamplingAll = SimulationAll[FALSE,]\n",
    "    \n",
    "    for(i in 1:nrow(AllYearsRecruits)){ \n",
    "        \n",
    "        destination_eval <- as.character(AllYearsRecruits$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- SimulationAll %>%\n",
    "                                    filter(destination==destination_eval) %>%\n",
    "                                    sample_n(as.numeric(AllYearsRecruits$n_offs_gen_all_years[i]), replace=F) #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "        \n",
    "        SimulatedSamplingAll <- bind_rows(SimulatedSamplingAll, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "\n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSamplingAll <- SimulatedSamplingAll %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSamplingAll)==sum(NGenOffsAll$n_offs_gen) #should be TRUE\n",
    "    \n",
    "    #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>% #should be 37 for 2012-2014\n",
    "        filter(Year %in% c(\"2012\", \"2013\", \"2014\")) %>%\n",
    "        select(NumParentageMatches) %>%\n",
    "        summarise(NumParentageMatches=sum(NumParentageMatches)))\n",
    "    \n",
    "    SimulatedSamplingAllPar <- SimulatedSamplingAll %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% NGenOffsAll$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSamplingAll_2 <- anti_join((SimulatedSamplingAll %>% ungroup()), SimulatedSamplingAllPar, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSamplingAll_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSamplingAllPar3 <- bind_rows(SimulatedSamplingAllPar, SimulatedSamplingAll_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSampAll <- PropSamp %>%  #add in all sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSampAll$destination <- PropSampAll$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSamplingAllPar3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in all surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSampAll, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSamplingAllPar3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum all the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummaryAll <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum all the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finally, join all of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for all sites\n",
    "                PropSampAll <- PropSampAll %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSampAll$destination <- PropSampAll$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSampAll, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% NGenOffsAll$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummaryAll %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFullAll <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFullAll) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFullAll\n",
    "    \n",
    "    #NOW FIT THE KERNEL\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "SimAllFit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "\n",
    "BestKAll <- as.numeric(coef(SimAllFit)[1])\n",
    "BestThetaAll <- as.numeric(coef(SimAllFit)[2])\n",
    "\n",
    "    #store the info in this df\n",
    "    SimulatedKernelsAll_beta <- as.data.frame(matrix(nrow=1, ncol=4), stringsAsFactors = FALSE)\n",
    "    colnames(SimulatedKernelsAll_beta) <- col\n",
    "    \n",
    "    SimulatedKernelsAll_beta$year <- NA\n",
    "    SimulatedKernelsAll_beta$k <- BestKAll\n",
    "    SimulatedKernelsAll_beta$theta <- BestThetaAll\n",
    "    SimulatedKernelsAll_beta$iteration <- n\n",
    "    \n",
    "    \n",
    "#join results into larger df\n",
    "SimulatedKernelsAll <- bind_rows(SimulatedKernelsAll, SimulatedKernelsAll_beta)\n",
    "    \n",
    "setTxtProgressBar(pb, n)\n",
    "\n",
    "\n",
    "}\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "options(warn=0) #turn warnings back on\n",
    "\n",
    "\n",
    "#write.csv(SimulatedKernelsAll, file=\"~/oceanography/script_output/KernelFits/1000SimulatedKernelsAll.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>year</th><th scope=col>k</th><th scope=col>theta</th><th scope=col>iteration</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>NA        </td><td>-2.4892253</td><td>1.2961845 </td><td>1         </td></tr>\n",
       "\t<tr><td>NA        </td><td>-2.6294572</td><td>1.4870832 </td><td>2         </td></tr>\n",
       "\t<tr><td>NA        </td><td>-0.4079566</td><td>0.4582810 </td><td>3         </td></tr>\n",
       "\t<tr><td>NA        </td><td>-2.7906454</td><td>1.8402302 </td><td>4         </td></tr>\n",
       "\t<tr><td>NA        </td><td>-2.0461538</td><td>0.8930063 </td><td>5         </td></tr>\n",
       "\t<tr><td>NA        </td><td>-2.2127169</td><td>1.0304831 </td><td>6         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " year & k & theta & iteration\\\\\n",
       "\\hline\n",
       "\t NA         & -2.4892253 & 1.2961845  & 1         \\\\\n",
       "\t NA         & -2.6294572 & 1.4870832  & 2         \\\\\n",
       "\t NA         & -0.4079566 & 0.4582810  & 3         \\\\\n",
       "\t NA         & -2.7906454 & 1.8402302  & 4         \\\\\n",
       "\t NA         & -2.0461538 & 0.8930063  & 5         \\\\\n",
       "\t NA         & -2.2127169 & 1.0304831  & 6         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| year | k | theta | iteration |\n",
       "|---|---|---|---|\n",
       "| NA         | -2.4892253 | 1.2961845  | 1          |\n",
       "| NA         | -2.6294572 | 1.4870832  | 2          |\n",
       "| NA         | -0.4079566 | 0.4582810  | 3          |\n",
       "| NA         | -2.7906454 | 1.8402302  | 4          |\n",
       "| NA         | -2.0461538 | 0.8930063  | 5          |\n",
       "| NA         | -2.2127169 | 1.0304831  | 6          |\n",
       "\n"
      ],
      "text/plain": [
       "  year k          theta     iteration\n",
       "1 NA   -2.4892253 1.2961845 1        \n",
       "2 NA   -2.6294572 1.4870832 2        \n",
       "3 NA   -0.4079566 0.4582810 3        \n",
       "4 NA   -2.7906454 1.8402302 4        \n",
       "5 NA   -2.0461538 0.8930063 5        \n",
       "6 NA   -2.2127169 1.0304831 6        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(SimulatedKernelsAll)\n",
    "#write.csv(SimulatedKernelsAll, file=\"~/oceanography/script_output/KernelFits/1000SimulatedKernelsAllStoppedEarly.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Seasonal kernel fits__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimulationSWM <- SimulationAll %>%\n",
    "    filter(SimMonsoon==\"SWM\")\n",
    "SimulationNEM <- SimulationAll %>%\n",
    "    filter(SimMonsoon==\"NEM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time difference of 46.53561 mins"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NEM of the corresponding simulation years combined (2011-NEM)\n",
    "\n",
    "col <- c(\"season\", \"k\", \"theta\", \"iteration\")\n",
    "SimulatedKernelsNEM <- as.data.frame(matrix(nrow=0, ncol=4), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernelsNEM) <- col\n",
    "\n",
    "#don't print warnings for this loop, they are only for setting row names in a tibble which is depracated. But it works. \n",
    "options(warn=-1)\n",
    "\n",
    "pb <- txtProgressBar(min = 0, max = 100, style = 3)#7 years in each interation\n",
    "\n",
    "StartTime <- Sys.time()\n",
    "\n",
    "#define the bounds to search over for the MLE\n",
    "a=-10\n",
    "b=10\n",
    "\n",
    "for(n in 1:100){\n",
    "        \n",
    "    #SAMPLE THE SIMULATION DATA, then fit a kernel\n",
    "    \n",
    "    SimulatedSamplingNEM = SimulationNEM[FALSE,]\n",
    "    \n",
    "    for(i in 1:nrow(AllYearsRecruits)){ \n",
    "        \n",
    "        destination_eval <- as.character(AllYearsRecruits$site[i]) #pick out a destination site\n",
    "        \n",
    "        SimSampDestination <- SimulationNEM %>%\n",
    "                                    filter(destination==destination_eval) %>%\n",
    "                                    sample_n(as.numeric(AllYearsRecruits$n_offs_gen_all_years[i]), replace=F) #sample particles that landed at that destination, number corresponding to the actual number sampled at that site in this year\n",
    "        \n",
    "        SimulatedSamplingNEM <- bind_rows(SimulatedSamplingNEM, SimSampDestination) #build into a sampled particle df\n",
    "    }\n",
    "\n",
    "    #assign a numeric ID for each row (which is a sampled particle)\n",
    "    SimulatedSamplingNEM <- SimulatedSamplingNEM %>%\n",
    "        mutate(ParticleSampID=paste (\"P\", row_number(), sep = \"\", collapse = NULL))\n",
    "    \n",
    "    #nrow(SimulatedSamplingNEM)==sum(NGenOffsNEM$n_offs_gen) #should be TRUE\n",
    "    \n",
    "   #now randomly assign parentage match status to some of these rows\n",
    "    NumPar <- as.numeric(kernels %>% #should be 37 for 2012-2014\n",
    "        filter(Year %in% c(\"2012\", \"2013\", \"2014\")) %>%\n",
    "        select(NumParentageMatches) %>%\n",
    "        summarise(NumParentageMatches=sum(NumParentageMatches)))\n",
    "    \n",
    "    SimulatedSamplingNEMPar <- SimulatedSamplingNEM %>%\n",
    "        ungroup() %>%\n",
    "        filter(source %in% AllYearsRecruits$site) %>% #we can only assign parentage if we sampled the source site, we've already ensured that we sampled the destination site in the for loop by indexing destination sites to evaluate \n",
    "        sample_n(NumPar, replace=F) %>% #sample number of rows consitent with numbers of parentage matches\n",
    "        mutate(Parentage=1) #%>% #assign these rows a positive match value\n",
    "        #arrange(date, source, destination) %>%#arrange by the same order as the orginal df, then bind columns together to avoid unexpected repeats from a join\n",
    "        #select(date, source, destination, Parentage) #drop columns that will result in repeats \n",
    "    \n",
    "    #find the rows that haven't been assigned parentage\n",
    "    SimulatedSamplingNEM_2 <- anti_join((SimulatedSamplingNEM %>% ungroup()), SimulatedSamplingNEMPar, by=c(\"ParticleSampID\")) \n",
    "    \n",
    "    SimulatedSamplingNEM_2$Parentage <- 0 #add in the column for parentage\n",
    "    \n",
    "    #combine parentage and non-parentage dfs\n",
    "    SimulatedSamplingNEMPar3 <- bind_rows(SimulatedSamplingNEMPar, SimulatedSamplingNEM_2) %>%\n",
    "        mutate(YearSampled=as.character(YearSampled))\n",
    "    \n",
    "    \n",
    "    #NOW FORMAT INTO PARENTAGE MATRIX\n",
    "    \n",
    "                PropSampNEM <- PropSamp %>%  #add in NEM sampled sites as possible parent sites\n",
    "                            filter(end_year ==\"2014\" & PropSamp > 0) %>%\n",
    "                            #rename(source=\"site\") %>%\n",
    "                            select(-end_year, -PropSamp)\n",
    "\n",
    "                #PropSampNEM$destination <- PropSampNEM$source #make another column for destination\n",
    "                \n",
    "                #make a table with the total number of particles sampled at each site\n",
    "                TotalSimSamp <- SimulatedSamplingNEMPar3 %>% \n",
    "                            select(source, destination) %>%\n",
    "                            group_by(destination) %>%\n",
    "                            summarise(NumSimSampRec=n()) %>%\n",
    "                            ungroup()\n",
    "               \n",
    "                \n",
    "                #add in NEM surveyed sites\n",
    "                TotalSimSamp2 <- left_join(PropSampNEM, TotalSimSamp, by=c(site=\"destination\")) %>% #join sites to destination, which will add a row for the surveyed sites with no samples\n",
    "                    mutate(NumSimSampRec=ifelse(is.na(NumSimSampRec), 0, NumSimSampRec)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    rename(destination=\"site\")#rename sites to destination after joining\n",
    "                \n",
    "                \n",
    "                \n",
    "                #make a table with the total number of parentage matches found in the simulated loop\n",
    "                TotalSimPar <- SimulatedSamplingNEMPar3 %>% \n",
    "                            select(source, destination, Parentage) %>%\n",
    "                            group_by(source,destination) %>%\n",
    "                            mutate(NumPar=sum(Parentage)) %>% #sum NEM the parentage observations along each ROUTE\n",
    "                            select(-Parentage) %>%\n",
    "                            ungroup() %>%\n",
    "                            distinct(source, destination, .keep_all = T)\n",
    "                \n",
    "                \n",
    "                #combine for a summary table BY DESTINATION, this below will be for UNASSIGNED ROWS\n",
    "                SimSampSummaryNEM <- left_join(TotalSimSamp2, TotalSimPar, by=\"destination\") %>%\n",
    "                    distinct(source, destination, .keep_all = T) %>%\n",
    "                    group_by(destination) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar)) %>% #change the Na's that result to 0s, because we didn't get samples there\n",
    "                    mutate(NumPar=sum(NumPar)) %>% #sum NEM the parentage observations at each DESTINATION\n",
    "                    distinct(destination, .keep_all = T) %>%\n",
    "                    select(-source) %>%\n",
    "                    mutate(NumUnassigned=NumSimSampRec-NumPar)\n",
    "                                \n",
    "                \n",
    "                #finNEMy, join NEM of the sites surveyed for a complete parentage matrix\n",
    "                #for this, need to have a source/destination column for NEM sites\n",
    "                PropSampNEM <- PropSampNEM %>%\n",
    "                                rename(source=\"site\")\n",
    "                \n",
    "                PropSampNEM$destination <- PropSampNEM$source #make another column for destination\n",
    "                \n",
    "                #this below will become parentage matrix! \n",
    "                TotalSimPar2 <- full_join(TotalSimPar,PropSampNEM, by=c(\"source\", \"destination\")) %>%\n",
    "                    mutate(NumPar=ifelse(is.na(NumPar), 0, NumPar))\n",
    "        \n",
    "                \n",
    "                #spread into matrix format\n",
    "                SimDispMat <- TotalSimPar2 %>%\n",
    "                    filter(source %in% AllYearsRecruits$site) %>%\n",
    "                    arrange(source, destination)  %>%\n",
    "                    spread(destination, NumPar) %>%\n",
    "                    select(-source)\n",
    "                SimDispMat[is.na(SimDispMat)] <- 0\n",
    "                \n",
    "                #add in unassigned row\n",
    "                unassigned <- t(as.matrix(SimSampSummaryNEM %>% arrange(destination) %>% ungroup() %>% select(NumUnassigned)))\n",
    "                rownames(unassigned)<-NULL\n",
    "                colnames(unassigned)<-names(SimDispMat)\n",
    "                \n",
    "                SimDispMatFullNEM <- rbind(SimDispMat, unassigned)\n",
    "                colnames(SimDispMatFullNEM) <- NULL\n",
    "\n",
    "        #The full remade parentage matrix\n",
    "        Assignments <- SimDispMatFullNEM\n",
    "    \n",
    "    #NOW FIT THE KERNEL\n",
    "\n",
    "\n",
    "x <- list(Distances=Distances, Assignments=Assignments, Sampled_reefs=Sampled_reefs, Reef_sizes=Reef_sizes, Adult_sample_proportions=Adult_sample_proportions) #put inputs into a list because that's the bbmle format\n",
    "\n",
    "SimNEMFit <- suppressWarnings(mle2(LL_kt_bbmle, start=list(k=-3, theta=1), lower=c(-10, 0.15), upper=c(10, 8), method=\"L-BFGS-B\", data=x, control=list(maxit=500)))\n",
    "\n",
    "BestKNEM <- as.numeric(coef(SimNEMFit)[1])\n",
    "BestThetaNEM <- as.numeric(coef(SimNEMFit)[2])\n",
    "\n",
    "    #store the info in this df\n",
    "    SimulatedKernelsNEM_beta <- as.data.frame(matrix(nrow=1, ncol=4), stringsAsFactors = FALSE)\n",
    "    colnames(SimulatedKernelsNEM_beta) <- col\n",
    "    \n",
    "    SimulatedKernelsNEM_beta$season <- NA\n",
    "    SimulatedKernelsNEM_beta$k <- BestKNEM\n",
    "    SimulatedKernelsNEM_beta$theta <- BestThetaNEM\n",
    "    SimulatedKernelsNEM_beta$iteration <- n\n",
    "    \n",
    "    \n",
    "#join results into larger df\n",
    "SimulatedKernelsNEM <- bind_rows(SimulatedKernelsNEM, SimulatedKernelsNEM_beta) %>%\n",
    "    mutate(season=\"NEM\")\n",
    "    \n",
    "setTxtProgressBar(pb, n)\n",
    "\n",
    "\n",
    "}\n",
    "close(pb)\n",
    "EndTime <- Sys.time()\n",
    "EndTime-StartTime\n",
    "options(warn=0) #turn warnings back on\n",
    "\n",
    "\n",
    "write.csv(SimulatedKernelsNEM, file=\"~/oceanography/script_output/KernelFits/100SimulatedKernelsNEM.csv\", row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>season</th><th scope=col>k</th><th scope=col>theta</th><th scope=col>iteration</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>SWM      </td><td>-2.672153</td><td>1.5020215</td><td>1        </td></tr>\n",
       "\t<tr><td>SWM      </td><td>-2.669852</td><td>1.5671385</td><td>2        </td></tr>\n",
       "\t<tr><td>SWM      </td><td>-1.548480</td><td>0.7110467</td><td>3        </td></tr>\n",
       "\t<tr><td>SWM      </td><td>-2.410050</td><td>1.3637183</td><td>4        </td></tr>\n",
       "\t<tr><td>SWM      </td><td>-2.158540</td><td>1.0557653</td><td>5        </td></tr>\n",
       "\t<tr><td>SWM      </td><td>-2.052900</td><td>0.9908733</td><td>6        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " season & k & theta & iteration\\\\\n",
       "\\hline\n",
       "\t SWM       & -2.672153 & 1.5020215 & 1        \\\\\n",
       "\t SWM       & -2.669852 & 1.5671385 & 2        \\\\\n",
       "\t SWM       & -1.548480 & 0.7110467 & 3        \\\\\n",
       "\t SWM       & -2.410050 & 1.3637183 & 4        \\\\\n",
       "\t SWM       & -2.158540 & 1.0557653 & 5        \\\\\n",
       "\t SWM       & -2.052900 & 0.9908733 & 6        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| season | k | theta | iteration |\n",
       "|---|---|---|---|\n",
       "| SWM       | -2.672153 | 1.5020215 | 1         |\n",
       "| SWM       | -2.669852 | 1.5671385 | 2         |\n",
       "| SWM       | -1.548480 | 0.7110467 | 3         |\n",
       "| SWM       | -2.410050 | 1.3637183 | 4         |\n",
       "| SWM       | -2.158540 | 1.0557653 | 5         |\n",
       "| SWM       | -2.052900 | 0.9908733 | 6         |\n",
       "\n"
      ],
      "text/plain": [
       "  season k         theta     iteration\n",
       "1 SWM    -2.672153 1.5020215 1        \n",
       "2 SWM    -2.669852 1.5671385 2        \n",
       "3 SWM    -1.548480 0.7110467 3        \n",
       "4 SWM    -2.410050 1.3637183 4        \n",
       "5 SWM    -2.158540 1.0557653 5        \n",
       "6 SWM    -2.052900 0.9908733 6        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(SimulatedKernelsSWM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "SimulatedKernels2012_beta <- as.data.frame(matrix(nrow=1, ncol=4), stringsAsFactors = FALSE)\n",
    "colnames(SimulatedKernels2012_beta) <- col\n",
    "\n",
    "    SimulatedKernels2012_beta$year <- 2012\n",
    "    SimulatedKernels2012_beta$k <- BestK2012\n",
    "    SimulatedKernels2012_beta$theta <- BestTheta2012\n",
    "    SimulatedKernels2012_beta$iteration <- n\n",
    "SimulatedKernels2012 <- bind_rows(SimulatedKernels2012, SimulatedKernels2012_beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monsoon season prep\n",
    "NEM_months <- c(11, 12, 1, 2, 3, 4)\n",
    "SWM_months <- c(5, 6, 7, 8, 9, 10)\n",
    "\n",
    "NEM <- conn_mat_full4 %>%\n",
    "    filter(month %in% NEM_months) %>%\n",
    "    group_by(source, destination) %>%\n",
    "    summarise(conn=max(fraction))\n",
    "\n",
    "SWM <- conn_mat_full4 %>%\n",
    "    filter(month %in% SWM_months) %>%\n",
    "    group_by(source, destination) %>%\n",
    "    summarise(conn=max(fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CELL BELOW IS WORKING FOR GLM OF OBSERVED DATA BY SIMULATED DATA__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(GenSimConn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(is.na(GenSimConn)==T) #should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__run GLM observed genetic dispersal predicted by simulations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(GenSimConn$obs_disp) #should be 0.024\n",
    "var(GenSimConn$obs_disp) #should be 0.054\n",
    "#overdispersion?\n",
    "#no, because residual deviance of the model is not greater than the df\n",
    "#Residual deviance:  38.221  on 948  degrees of freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plan:\n",
    "#fit 3 successive log-linear models starting with main efects only(fit1), main effects plus all 2-way interactions (fit2), and added in all 3 way interactions (fit3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NullMod <- glm(obs_disp ~ dist_km , data=GenSimConn, family=\"poisson\")\n",
    "summary(NullMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObsModExpYearFit1 <- glm(obs_disp ~ AnnRecPart + YearSampled + direction + dist_km +SourcePropSamp +DestPropSamp, data=GenSimConn, family=\"poisson\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(ObsModExpYearFit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#only main effects, first find worthwhile predictors with AIC\n",
    "#the intercept is very significant but I think that just means 0s are more common in the data. totally true!\n",
    "\n",
    "ObsModExpYearFit1 <- glm(obs_disp ~ AnnRecPart + YearSampled + direction + dist_km +SourcePropSamp +DestPropSamp, data=GenSimConn, family=\"poisson\")\n",
    "MainEff_AnnRecPart <- update(ObsModExpYearFit1, . ~ . -AnnRecPart)\n",
    "MainEff_YearSampled <- update(ObsModExpYearFit1, . ~ . -YearSampled)\n",
    "MainEff_direction <- update(ObsModExpYearFit1, . ~ . -direction)\n",
    "MainEff_dist_km <- update(ObsModExpYearFit1, . ~ . -dist_km)\n",
    "MainEff_SourcePropSamp <- update(ObsModExpYearFit1, . ~ . -SourcePropSamp)\n",
    "MainEff_DestPropSamp <- update(ObsModExpYearFit1, . ~ . -DestPropSamp)\n",
    "#drop the 3 terms AIC doesn't support? maybe not though, because when there's an interaction that's the best model\n",
    "MainEff_ARP_DPrp_Dist <- glm(obs_disp ~ YearSampled + direction +SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "#add the interaction between year and simulations\n",
    "ObsModExpYearFit2IntYear <- glm(obs_disp ~ AnnRecPart*YearSampled + direction+SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "ObsModExpYearFit2IntDir <- glm(obs_disp ~ AnnRecPart*YearSampled + direction+SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "ObsModExpYearFit2IntDirNoROMS <- glm(obs_disp ~ AnnRecPart+YearSampled*direction+SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "ObsModExpYearFit3Int <- glm(obs_disp ~ AnnRecPart*YearSampled*direction+SourcePropSamp, data=GenSimConn, family=\"poisson\")\n",
    "\n",
    "FullModNoROMSDestPropSamp <- glm(obs_disp ~  YearSampled + direction + dist_km +SourcePropSamp , data=GenSimConn, family=\"poisson\")\n",
    "FullModNoROMSDestPropSampInt <- glm(obs_disp ~  YearSampled* direction + dist_km +SourcePropSamp , data=GenSimConn, family=\"poisson\")\n",
    "\n",
    "MainEffAIC <- as.data.frame(AIC(NullMod, FullModNoROMSDestPropSampInt, FullModNoROMSDestPropSamp, ObsModExpYearFit1, MainEff_AnnRecPart, MainEff_YearSampled, MainEff_direction, MainEff_dist_km, MainEff_SourcePropSamp, MainEff_DestPropSamp, ObsModExpYearFit2IntDir, ObsModExpYearFit2IntYear, ObsModExpYearFit2IntDirNoROMS, ObsModExpYearFit3Int))\n",
    "MainEffAIC$model <- row.names(MainEffAIC)\n",
    "MainEffAIC <- MainEffAIC %>% arrange(AIC)\n",
    "MainEffAIC\n",
    "#/write.csv(MainEffAIC, file=\"~/oceanography/script_output/GLM/GLMObsDispAIC.csv\",row.names=F,  quote=F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullModNoROMSDestPropSampInt <- glm(obs_disp ~  YearSampled* direction+direction+YearSampled + dist_km +SourcePropSamp , data=GenSimConn, family=\"poisson\")\n",
    "\n",
    "summary(FullModNoROMSDestPropSampInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC(test, MainEff_AnnRecPart,MainEff_DestPropSamp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(ObsModExpYearFit2Int ) #judging by the significant intercept (which should be AnnRecPart:Year2012?) when there's more particles expected from the ROMS model, there's actually less in the observed data.\n",
    "ObsModExpYearFit2Int_Sum <- tidy(ObsModExpYearFit2Int)\n",
    "#write.csv(ObsModExpYearFit2Int_Sum, file=\"~/oceanography/script_output/GLM/YearDispIntBestModSum.csv\",row.names=F,  quote=F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROMSFull <- glm(AnnRecPart ~ as.factor(SimYear) + direction + dist_km + source + destination, data=GenSimConn, family=\"poisson\")\n",
    "#MainEff_AnnRecPart <- update(ObsModExpYearFit1, . ~ . -AnnRecPart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary(ROMSFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(SimConnDFDir$NormSourceMonsoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what are the routes that create these peaks in direction annually?\n",
    "\n",
    "#are there similar patterns seasonally?\n",
    "\n",
    "#plot the connectivity matrix with of the roms model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head(SimConnDFMeta %>% dplyr::select(AnnRecPart, direction, SimYear, source, destination))\n",
    "SimConnDFMeta %>%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(SimConnDFMeta$direction, breaks=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(SimConnDFMeta$direction)\n",
    "(SimConnDFMeta$direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this isn't significant, which means the residual difference is small enough here to say the model fits reasonably well\n",
    "with(test_mod, cbind(res.deviance = deviance, df = df.residual,\n",
    "  p = pchisq(deviance, df.residual, lower.tail=FALSE)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how much devience is explained here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(obs_disp ~ ExpDisp, data=SimPlusGenWithDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot(test_mod_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot predicted model\n",
    "range(SimPlusGenWithDist$ExpDisp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_disp_range <- seq(0, 66114, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_disp_pred <- predict(test_mod_int,type=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot( SimPlusGenWithDist$ExpDisp, SimPlusGenWithDist$obs_disp, pch = 16)#, xlab = \"WEIGHT (g)\", ylab = \"VS\")\n",
    "\n",
    "lines(obs_disp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
